{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp\n",
    "from IPython.core.display import display\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 2000)\n",
    "pd.set_option(\"display.max_colwidth\", 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import LinearSVC, libsvm, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリデータのダミー変数化\n",
    "def dummies(df, cols):\n",
    "    df_droped  = copy.deepcopy(df.drop(cols, axis=1)).reset_index(drop=True)\n",
    "    df_dummies = df.reset_index(drop=True)\n",
    "    df_dummies = pd.get_dummies(df_dummies[cols], drop_first=True)\n",
    "    return pd.merge(df_droped, df_dummies, left_index=True, right_index=True)\n",
    "\n",
    "# 数値データの標準化\n",
    "def standardization(df, cols, df_test=None):\n",
    "    mean   = df[cols].mean()\n",
    "    std    = df[cols].std()\n",
    "    df_std = copy.deepcopy(df)\n",
    "    df_std[cols] = df_std[cols].apply(lambda x: (x - mean[x.name]) / std[x.name])\n",
    "    df_test_std  = copy.deepcopy(df_test)\n",
    "    if df_test is not None:\n",
    "        df_test_std[cols] = df_test_std[cols].apply(lambda x: (x - mean[x.name]) / std[x.name])\n",
    "    return df_std, df_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スタッキングする関数\n",
    "def calc_proba(proba):\n",
    "    return 1 - proba[:,0]\n",
    "\n",
    "def stacking(df_train, df_test, clf, name, seed=15, cv=4):\n",
    "    statime = datetime.now()\n",
    "    df_auc  = df_train_pred = pd.DataFrame()\n",
    "    x, y    = df_train.drop(\"y\", axis=1), df_train.y\n",
    "    # train\n",
    "    k   = 1\n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=seed)\n",
    "    for train, valid in skf.split(x, y):\n",
    "        clf.fit(x.iloc[train,:], y[train])\n",
    "        train_pred, valid_pred = clf.predict_proba(x.iloc[train,:]), clf.predict_proba(x.iloc[valid,:])\n",
    "        train_pred, valid_pred = calc_proba(train_pred),             calc_proba(valid_pred)\n",
    "        auc     = pd.DataFrame({\"k\" : [k],\n",
    "                                \"train_\"+name : roc_auc_score(y[train], train_pred),\n",
    "                                \"valid_\"+name : roc_auc_score(y[valid], valid_pred)})\n",
    "        df_auc  = df_auc.append(auc, ignore_index=True)\n",
    "        df_pred = pd.DataFrame({\"idx\" : valid, name : valid_pred, \"y\" : y[valid]})\n",
    "        df_train_pred = df_train_pred.append(df_pred, ignore_index=True)\n",
    "        k += 1\n",
    "    # test\n",
    "    clf.fit(x, y)\n",
    "    all_pred, test_pred = clf.predict_proba(x), clf.predict_proba(df_test)\n",
    "    all_pred, test_pred = calc_proba(all_pred), calc_proba(test_pred)\n",
    "    auc    = pd.DataFrame({\"k\" : [\"all\"],\n",
    "                           \"train_\"+name : roc_auc_score(y, all_pred)})\n",
    "    df_auc = df_auc.append(auc, ignore_index=True)\n",
    "    df_test_pred = pd.DataFrame({\"idx\" : df_test.index, name : test_pred})\n",
    "    print(\"clf:%s time:%s end\" % (name, datetime.now() - statime))\n",
    "    return df_train_pred, df_test_pred, df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path    = \"../../../../Users/tenni/Documents/kaggle/HomeCredditDefaultRisk/data/\"\n",
    "dict_df = {}\n",
    "for file in os.listdir(path):\n",
    "    if file.find(\".csv\")==-1 or -1 < file.find(\"sample\"): continue\n",
    "    filename = os.path.splitext(file)[0]\n",
    "    enc      = \"utf-8\"\n",
    "    if filename==\"HomeCredit_columns_description\":\n",
    "        enc  = \"ISO-8859-1\"\n",
    "    print(filename)\n",
    "    dict_df[filename] = pd.read_csv(path + file, encoding=enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols_description = dict_df[\"HomeCredit_columns_description\"]\n",
    "del dict_df[\"HomeCredit_columns_description\"]\n",
    "df_cols_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, df in dict_df.items():\n",
    "    print(key)\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, df in dict_df.items():\n",
    "    print(key)\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naを含む列を削除する\n",
    "dict_df_droped_na = {}\n",
    "for key, df in dict_df.items():\n",
    "    if -1 < key.find(\"test\"): continue\n",
    "    if -1 < key.find(\"train\"):\n",
    "        df_droped_na = df.dropna(axis=1)\n",
    "        keep_cols    = df_droped_na.columns.drop(\"TARGET\")\n",
    "        key_test     = key.replace(\"train\",\"test\")\n",
    "        dict_df_droped_na[key]      = df_droped_na\n",
    "        dict_df_droped_na[key_test] = dict_df[key_test][keep_cols]        \n",
    "    else:\n",
    "        dict_df_droped_na[key] = df.dropna(axis=1)\n",
    "for key, df in dict_df.items():\n",
    "    print(key)\n",
    "    print(df.shape, dict_df_droped_na[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_edited = {}\n",
    "# 標準化\n",
    "for key, df in dict_df_droped_na.items():\n",
    "    std_cols = df.select_dtypes(include=[\"int\",\"float\"]).columns\n",
    "    std_cols = [col for col in std_cols if col not in [\"SK_ID_CURR\",\"SK_ID_BUREAU\",\"SK_ID_PREV\",\"TARGET\"]]\n",
    "    if -1 < key.find(\"test\") or len(std_cols)==0: continue\n",
    "    if -1 < key.find(\"train\"):\n",
    "        key_test = key.replace(\"train\",\"test\")\n",
    "        dict_df_edited[key], dict_df_edited[key_test] = standardization(df, std_cols, dict_df_droped_na[key_test])\n",
    "    else:\n",
    "        dict_df_edited[key], _ = standardization(df, std_cols)\n",
    "# ダミー変数化\n",
    "for key, df in dict_df_edited.items():\n",
    "    dummy_cols = df.select_dtypes(include=\"object\").columns\n",
    "    if -1 < key.find(\"test\") or len(dummy_cols)==0: continue    \n",
    "    if -1 < key.find(\"train\"):\n",
    "        key_test   = key.replace(\"train\",\"test\")\n",
    "        df_dummy = pd.concat([df, dict_df_edited[key_test]])\n",
    "        df_dummy = dummies(df_dummy, dummy_cols)\n",
    "        dict_df_edited[key], dict_df_edited[key_test] = df_dummy[df_dummy.TARGET.notnull()], df_dummy[df_dummy.TARGET.isnull()]\n",
    "        dict_df_edited[key].TARGET = dict_df_edited[key].TARGET.astype(int)\n",
    "        dict_df_edited[key_test].drop(\"TARGET\", axis=1, inplace=True)\n",
    "    else:\n",
    "        dict_df_edited[key] = dummies(df, dummy_cols)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_df_edited['application_train'].shape)\n",
    "dict_df_edited['application_train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict_df_edited['application_train']\n",
    "drop_cols = []\n",
    "for col in df:\n",
    "    col_sum = df[col].sum()\n",
    "    if type(col_sum) is np.int64:\n",
    "        if col_sum / df.shape[0] < 0.01:\n",
    "            drop_cols.append(col)\n",
    "\n",
    "seed = 15\n",
    "x = dict_df_edited['application_train'].drop(drop_cols + [\"SK_ID_CURR\",\"TARGET\"], axis=1)\n",
    "y = dict_df_edited['application_train'].TARGET\n",
    "train_X, test_X, train_y, test_y = train_test_split(x, y, \n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "statime = datetime.now()\n",
    "classifier = xgb.XGBClassifier(gamma=3, learning_rate=0.1, max_depth=6, min_child_weight=4, n_estimators=1000, random_state=seed)\n",
    "classifier.fit(x, y, verbose=10)\n",
    "datetime.now() - statime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = calc_proba(classifier.predict_proba(test_X))\n",
    "print(\"best model auc:\", roc_auc_score(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dict_df_edited['application_test'].drop(drop_cols + [\"SK_ID_CURR\"], axis=1)\n",
    "test_pred = calc_proba(classifier.predict_proba(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({\"SK_ID_CURR\" : dict_df_edited['application_test'].SK_ID_CURR,\n",
    "                          \"TARGET\"     : test_pred})\n",
    "path    = \"../../../../Users/tenni/Documents/kaggle/HomeCredditDefaultRisk/submit/\"\n",
    "df_result.to_csv(path + \"result_20180705.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
