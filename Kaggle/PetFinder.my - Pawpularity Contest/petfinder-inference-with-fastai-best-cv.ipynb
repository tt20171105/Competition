{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c872ad",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:28.130378Z",
     "iopub.status.busy": "2022-01-14T12:35:28.128652Z",
     "iopub.status.idle": "2022-01-14T12:35:28.142575Z",
     "shell.execute_reply": "2022-01-14T12:35:28.143791Z",
     "shell.execute_reply.started": "2022-01-13T12:39:43.235511Z"
    },
    "papermill": {
     "duration": 0.044204,
     "end_time": "2022-01-14T12:35:28.144166",
     "exception": false,
     "start_time": "2022-01-14T12:35:28.099962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-optimizers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802d1708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:28.230822Z",
     "iopub.status.busy": "2022-01-14T12:35:28.229912Z",
     "iopub.status.idle": "2022-01-14T12:35:37.482746Z",
     "shell.execute_reply": "2022-01-14T12:35:37.483218Z",
     "shell.execute_reply.started": "2022-01-13T12:39:46.104958Z"
    },
    "papermill": {
     "duration": 9.296791,
     "end_time": "2022-01-14T12:35:37.483426",
     "exception": false,
     "start_time": "2022-01-14T12:35:28.186635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from shutil import copyfile\n",
    "from IPython.core.display import Video, display\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import Resize as albResize\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Transpose, RandomResizedCrop, CenterCrop, \n",
    "    Rotate, RandomRotate90, ShiftScaleRotate, Flip, HorizontalFlip, VerticalFlip,\n",
    "    HueSaturationValue, RandomBrightnessContrast, RGBShift, ChannelShuffle,\n",
    "    Normalize, Blur, MotionBlur, Cutout, CoarseDropout)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option(\"max_columns\", 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf65dd",
   "metadata": {
    "papermill": {
     "duration": 0.020872,
     "end_time": "2022-01-14T12:35:37.525363",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.504491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488aab8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:37.593201Z",
     "iopub.status.busy": "2022-01-14T12:35:37.575494Z",
     "iopub.status.idle": "2022-01-14T12:35:37.598087Z",
     "shell.execute_reply": "2022-01-14T12:35:37.598676Z",
     "shell.execute_reply.started": "2022-01-13T12:51:16.798949Z"
    },
    "papermill": {
     "duration": 0.052766,
     "end_time": "2022-01-14T12:35:37.598849",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.546083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of models is 7 with fold 4 and tta 2.\n",
      "Total of inference will be 56.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'submit': True,\n",
       " 'stacking': True,\n",
       " 'seed': 42,\n",
       " 'device': 'cuda:0',\n",
       " 'input_trimg': '../input/petfinder-pawpularity-score/train/',\n",
       " 'input_trpath': '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
       " 'input_teimg': '../input/petfinder-pawpularity-score/test/',\n",
       " 'input_tepath': '../input/petfinder-pawpularity-score/test.csv',\n",
       " 'output_path': './',\n",
       " 'db_model': 'swin_large_patch4_window7_224_in22k',\n",
       " 'db_size': 224,\n",
       " 'models': [[False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_0.pt'],\n",
       "  [False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_1.pt'],\n",
       "  [False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_2.pt'],\n",
       "  [False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_3.pt'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_0.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_1.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_2.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_3.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_0.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_1.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_2.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_3.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_0.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_1.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_2.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_3.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_0.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_1.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_2.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_3.pth']],\n",
       " 'tta': 2,\n",
       " 'batch_size': 1,\n",
       " 'num_workers': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG = {\n",
    "    \"submit\"      : True,\n",
    "    \"stacking\"    : True,\n",
    "    \"seed\"        : 42,\n",
    "    'device'      : \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"input_trimg\" : '../input/petfinder-pawpularity-score/train/',\n",
    "    \"input_trpath\": '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
    "    \"input_teimg\" : '../input/petfinder-pawpularity-score/test/',\n",
    "    \"input_tepath\": '../input/petfinder-pawpularity-score/test.csv',\n",
    "    \"output_path\" : './',\n",
    "    \"db_model\"    : \"swin_large_patch4_window7_224_in22k\",\n",
    "    \"db_size\"     : 224,\n",
    "    \"models\"      : [[False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_0.pt\"],\n",
    "                     [False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_1.pt\"],\n",
    "                     [False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_2.pt\"],\n",
    "                     [False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_3.pt\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_0.pth\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_1.pth\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_2.pth\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_3.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_0.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_1.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_2.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_3.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_0.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_1.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_2.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_3.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_0.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_1.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_2.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_3.pth\"],\n",
    "                     [True,  384,   0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_0.pth\"],\n",
    "                     [True,  384,   0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_1.pth\"],\n",
    "                     [True,  384,   0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_2.pth\"],\n",
    "                     [True,  384,   0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_3.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_0.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_1.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_2.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_3.pth\"]],\n",
    "    \"tta\"         : 2,  # If set over 2, tta will run\n",
    "    \"batch_size\"  : 1,\n",
    "    \"num_workers\" : 4\n",
    "}\n",
    "\n",
    "print(f\"# of models is {int(len(CFG['models'])/4)} with fold 4 and tta {CFG['tta']}.\")\n",
    "print(f\"Total of inference will be {len(CFG['models']) * CFG['tta']}.\")\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9f383a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:37.650347Z",
     "iopub.status.busy": "2022-01-14T12:35:37.649502Z",
     "iopub.status.idle": "2022-01-14T12:35:37.652387Z",
     "shell.execute_reply": "2022-01-14T12:35:37.651954Z",
     "shell.execute_reply.started": "2022-01-13T12:39:54.745486Z"
    },
    "papermill": {
     "duration": 0.031686,
     "end_time": "2022-01-14T12:35:37.652510",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.620824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def my_sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "def softmax(x):\n",
    "    max = np.max(x,axis=1,keepdims=True)\n",
    "    e_x = np.exp(x - max)\n",
    "    sum = np.sum(e_x,axis=1,keepdims=True)\n",
    "    return e_x / sum \n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f0422",
   "metadata": {
    "papermill": {
     "duration": 0.021455,
     "end_time": "2022-01-14T12:35:37.695374",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.673919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a2d0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:37.745940Z",
     "iopub.status.busy": "2022-01-14T12:35:37.745403Z",
     "iopub.status.idle": "2022-01-14T12:35:37.812200Z",
     "shell.execute_reply": "2022-01-14T12:35:37.812627Z",
     "shell.execute_reply.started": "2022-01-13T12:51:24.068399Z"
    },
    "papermill": {
     "duration": 0.095576,
     "end_time": "2022-01-14T12:35:37.812770",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.717194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
      "(8, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          1      1        0      0          1     0     1   \n",
       "1          0      1        1      0          0     0     0   \n",
       "\n",
       "                                                                             path  \n",
       "0  ../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg  \n",
       "1  ../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(CFG['input_trpath'])\n",
    "df_train[\"path\"] = [f\"{CFG['input_trimg']}{i}.jpg\" for i in df_train.Id]\n",
    "df_train[\"Pawclass\"] = df_train.Pawpularity / 100\n",
    "\n",
    "if CFG[\"submit\"]:\n",
    "    df_test = pd.read_csv(CFG['input_tepath'])\n",
    "    df_test[\"path\"] = [f\"{CFG['input_teimg']}{i}.jpg\" for i in df_test.Id]\n",
    "else:\n",
    "    df_test = pd.read_csv(CFG['input_trpath'])\n",
    "    df_test[\"path\"] = [f\"{CFG['input_trimg']}{i}.jpg\" for i in df_test.Id]\n",
    "\n",
    "meta_features = [c for c in df_test.columns if c not in [\"Id\",\"path\", \"Pawpularity\"]]\n",
    "\n",
    "print(meta_features)\n",
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19cdab5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:37.864737Z",
     "iopub.status.busy": "2022-01-14T12:35:37.864179Z",
     "iopub.status.idle": "2022-01-14T12:35:37.900441Z",
     "shell.execute_reply": "2022-01-14T12:35:37.900865Z",
     "shell.execute_reply.started": "2022-01-13T12:51:25.193956Z"
    },
    "papermill": {
     "duration": 0.065624,
     "end_time": "2022-01-14T12:35:37.901016",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.835392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject Focus     Eyes      Face     Near    Action  Accessory  \\\n",
       "count       8.000000  8.00000  8.000000  8.00000  8.000000   8.000000   \n",
       "mean        0.625000  0.25000  0.625000  0.25000  0.375000   0.625000   \n",
       "std         0.517549  0.46291  0.517549  0.46291  0.517549   0.517549   \n",
       "min         0.000000  0.00000  0.000000  0.00000  0.000000   0.000000   \n",
       "25%         0.000000  0.00000  0.000000  0.00000  0.000000   0.000000   \n",
       "50%         1.000000  0.00000  1.000000  0.00000  0.000000   1.000000   \n",
       "75%         1.000000  0.25000  1.000000  0.25000  1.000000   1.000000   \n",
       "max         1.000000  1.00000  1.000000  1.00000  1.000000   1.000000   \n",
       "\n",
       "          Group   Collage    Human  Occlusion      Info      Blur  \n",
       "count  8.000000  8.000000  8.00000   8.000000  8.000000  8.000000  \n",
       "mean   0.500000  0.625000  0.25000   0.500000  0.625000  0.500000  \n",
       "std    0.534522  0.517549  0.46291   0.534522  0.517549  0.534522  \n",
       "min    0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  \n",
       "25%    0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  \n",
       "50%    0.500000  1.000000  0.00000   0.500000  1.000000  0.500000  \n",
       "75%    1.000000  1.000000  0.25000   1.000000  1.000000  1.000000  \n",
       "max    1.000000  1.000000  1.00000   1.000000  1.000000  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18edc8",
   "metadata": {
    "papermill": {
     "duration": 0.022783,
     "end_time": "2022-01-14T12:35:37.947402",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.924619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog and cat labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8ec9d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:38.000837Z",
     "iopub.status.busy": "2022-01-14T12:35:37.999766Z",
     "iopub.status.idle": "2022-01-14T12:35:38.001589Z",
     "shell.execute_reply": "2022-01-14T12:35:38.002020Z",
     "shell.execute_reply.started": "2022-01-13T12:51:26.014801Z"
    },
    "papermill": {
     "duration": 0.031815,
     "end_time": "2022-01-14T12:35:38.002158",
     "exception": false,
     "start_time": "2022-01-14T12:35:37.970343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    try:\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None\n",
    "    model = models.densenet121(pretrained=False)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 2)\n",
    "    )\n",
    "    model.parameters = checkpoint['parameters']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffa7821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:38.054650Z",
     "iopub.status.busy": "2022-01-14T12:35:38.053887Z",
     "iopub.status.idle": "2022-01-14T12:35:38.055840Z",
     "shell.execute_reply": "2022-01-14T12:35:38.056296Z",
     "shell.execute_reply.started": "2022-01-13T12:51:26.627004Z"
    },
    "papermill": {
     "duration": 0.031659,
     "end_time": "2022-01-14T12:35:38.056437",
     "exception": false,
     "start_time": "2022-01-14T12:35:38.024778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_transform(imagepath):\n",
    "    test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(imagepath)\n",
    "    imagetensor = test_transforms(image)\n",
    "    return imagetensor\n",
    "\n",
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img = image_transform(self.df.loc[index].path)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7810d247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:38.107437Z",
     "iopub.status.busy": "2022-01-14T12:35:38.106638Z",
     "iopub.status.idle": "2022-01-14T12:35:38.108637Z",
     "shell.execute_reply": "2022-01-14T12:35:38.109055Z",
     "shell.execute_reply.started": "2022-01-13T12:51:27.458561Z"
    },
    "papermill": {
     "duration": 0.03016,
     "end_time": "2022-01-14T12:35:38.109176",
     "exception": false,
     "start_time": "2022-01-14T12:35:38.079016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    img_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        img_preds = model(imgs)\n",
    "        img_preds_all += [img_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    img_preds_all = np.concatenate(img_preds_all, axis=0)\n",
    "    return img_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfdcd7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:38.161103Z",
     "iopub.status.busy": "2022-01-14T12:35:38.160575Z",
     "iopub.status.idle": "2022-01-14T12:35:50.265360Z",
     "shell.execute_reply": "2022-01-14T12:35:50.265974Z",
     "shell.execute_reply.started": "2022-01-13T12:51:28.26607Z"
    },
    "papermill": {
     "duration": 12.134079,
     "end_time": "2022-01-14T12:35:50.266151",
     "exception": false,
     "start_time": "2022-01-14T12:35:38.132072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "inference_ds = PetFinderDataset(df_test)\n",
    "data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                           batch_size=CFG['batch_size'],\n",
    "                                           drop_last=False,\n",
    "                                           pin_memory=False,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=CFG['num_workers'])\n",
    "model = load_model(\"../input/cat-vs-dog-model/cat-v-dog-classifier-pytorch-master/models/catvdog.pth\")\n",
    "model.to(CFG[\"device\"])\n",
    "with torch.no_grad():\n",
    "    res_cat_dog = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "del model, inference_ds, data_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "263250d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:50.339483Z",
     "iopub.status.busy": "2022-01-14T12:35:50.338866Z",
     "iopub.status.idle": "2022-01-14T12:35:50.345965Z",
     "shell.execute_reply": "2022-01-14T12:35:50.346537Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.732794Z"
    },
    "papermill": {
     "duration": 0.052622,
     "end_time": "2022-01-14T12:35:50.346709",
     "exception": false,
     "start_time": "2022-01-14T12:35:50.294087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>path</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>0.478612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg</td>\n",
       "      <td>0.576748</td>\n",
       "      <td>0.423252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          1      1        0      0          1     0     1   \n",
       "1          0      1        1      0          0     0     0   \n",
       "\n",
       "                                                                             path  \\\n",
       "0  ../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg   \n",
       "1  ../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg   \n",
       "\n",
       "        cat       dog  \n",
       "0  0.521388  0.478612  \n",
       "1  0.576748  0.423252  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[[\"cat\",\"dog\"]] = softmax(res_cat_dog)\n",
    "meta_features += [\"cat\",\"dog\"]\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf8411",
   "metadata": {
    "papermill": {
     "duration": 0.040678,
     "end_time": "2022-01-14T12:35:50.429659",
     "exception": false,
     "start_time": "2022-01-14T12:35:50.388981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog breed for dog label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf85339d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:50.493967Z",
     "iopub.status.busy": "2022-01-14T12:35:50.493011Z",
     "iopub.status.idle": "2022-01-14T12:35:50.495915Z",
     "shell.execute_reply": "2022-01-14T12:35:50.495337Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.755896Z"
    },
    "papermill": {
     "duration": 0.037482,
     "end_time": "2022-01-14T12:35:50.496039",
     "exception": false,
     "start_time": "2022-01-14T12:35:50.458557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 120)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a93f4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:50.561891Z",
     "iopub.status.busy": "2022-01-14T12:35:50.561118Z",
     "iopub.status.idle": "2022-01-14T12:35:50.563136Z",
     "shell.execute_reply": "2022-01-14T12:35:50.563687Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.765738Z"
    },
    "papermill": {
     "duration": 0.039075,
     "end_time": "2022-01-14T12:35:50.563824",
     "exception": false,
     "start_time": "2022-01-14T12:35:50.524749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms  = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img  = get_img(self.df.loc[index].path).copy()\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        return img\n",
    "    \n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "        albResize(CFG[\"db_size\"], CFG[\"db_size\"], p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ea8afa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:50.626737Z",
     "iopub.status.busy": "2022-01-14T12:35:50.625842Z",
     "iopub.status.idle": "2022-01-14T12:35:50.628622Z",
     "shell.execute_reply": "2022-01-14T12:35:50.628118Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.779022Z"
    },
    "papermill": {
     "duration": 0.036966,
     "end_time": "2022-01-14T12:35:50.628738",
     "exception": false,
     "start_time": "2022-01-14T12:35:50.591772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [image_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc5c9936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:35:50.696537Z",
     "iopub.status.busy": "2022-01-14T12:35:50.688417Z",
     "iopub.status.idle": "2022-01-14T12:36:02.731107Z",
     "shell.execute_reply": "2022-01-14T12:36:02.731554Z",
     "shell.execute_reply.started": "2022-01-13T12:57:27.081687Z"
    },
    "papermill": {
     "duration": 12.075006,
     "end_time": "2022-01-14T12:36:02.731709",
     "exception": false,
     "start_time": "2022-01-14T12:35:50.656703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  9.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dog_ids = list(df_test[df_test.dog > 0.5].Id)\n",
    "print(f\"Dog num: {len(dog_ids)}\")\n",
    "inference_ds = PetFinderDataset(df_test[df_test.Id.isin(dog_ids)].reset_index(drop=True),\n",
    "                                        transforms=get_inference_transforms())\n",
    "data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                           batch_size=CFG['batch_size'],\n",
    "                                           drop_last=False,\n",
    "                                           pin_memory=False,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=CFG['num_workers'])\n",
    "model = SwinModel(CFG['db_model'], pretrained=False)\n",
    "model.load_state_dict(torch.load(\"../input/petfinder-dogbreed-cnn-models/dogbreed_swin_ce.pt\"))\n",
    "model.to(CFG[\"device\"])\n",
    "with torch.no_grad():\n",
    "    res_dogbreed = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "del model, inference_ds, data_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbc91dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:02.826470Z",
     "iopub.status.busy": "2022-01-14T12:36:02.816090Z",
     "iopub.status.idle": "2022-01-14T12:36:02.979532Z",
     "shell.execute_reply": "2022-01-14T12:36:02.979953Z",
     "shell.execute_reply.started": "2022-01-13T12:59:55.764668Z"
    },
    "papermill": {
     "duration": 0.221541,
     "end_time": "2022-01-14T12:36:02.980106",
     "exception": false,
     "start_time": "2022-01-14T12:36:02.758565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 134)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>db0</th>\n",
       "      <th>db1</th>\n",
       "      <th>db2</th>\n",
       "      <th>db3</th>\n",
       "      <th>db4</th>\n",
       "      <th>db5</th>\n",
       "      <th>db6</th>\n",
       "      <th>db7</th>\n",
       "      <th>db8</th>\n",
       "      <th>db9</th>\n",
       "      <th>db10</th>\n",
       "      <th>db11</th>\n",
       "      <th>db12</th>\n",
       "      <th>db13</th>\n",
       "      <th>db14</th>\n",
       "      <th>db15</th>\n",
       "      <th>db16</th>\n",
       "      <th>db17</th>\n",
       "      <th>db18</th>\n",
       "      <th>db19</th>\n",
       "      <th>db20</th>\n",
       "      <th>db21</th>\n",
       "      <th>db22</th>\n",
       "      <th>db23</th>\n",
       "      <th>db24</th>\n",
       "      <th>db25</th>\n",
       "      <th>db26</th>\n",
       "      <th>db27</th>\n",
       "      <th>db28</th>\n",
       "      <th>db29</th>\n",
       "      <th>db30</th>\n",
       "      <th>db31</th>\n",
       "      <th>db32</th>\n",
       "      <th>db33</th>\n",
       "      <th>db34</th>\n",
       "      <th>db35</th>\n",
       "      <th>db36</th>\n",
       "      <th>db37</th>\n",
       "      <th>db38</th>\n",
       "      <th>db39</th>\n",
       "      <th>db40</th>\n",
       "      <th>db41</th>\n",
       "      <th>db42</th>\n",
       "      <th>db43</th>\n",
       "      <th>db44</th>\n",
       "      <th>db45</th>\n",
       "      <th>db46</th>\n",
       "      <th>db47</th>\n",
       "      <th>db48</th>\n",
       "      <th>db49</th>\n",
       "      <th>db50</th>\n",
       "      <th>db51</th>\n",
       "      <th>db52</th>\n",
       "      <th>db53</th>\n",
       "      <th>db54</th>\n",
       "      <th>db55</th>\n",
       "      <th>db56</th>\n",
       "      <th>db57</th>\n",
       "      <th>db58</th>\n",
       "      <th>db59</th>\n",
       "      <th>db60</th>\n",
       "      <th>db61</th>\n",
       "      <th>db62</th>\n",
       "      <th>db63</th>\n",
       "      <th>db64</th>\n",
       "      <th>db65</th>\n",
       "      <th>db66</th>\n",
       "      <th>db67</th>\n",
       "      <th>db68</th>\n",
       "      <th>db69</th>\n",
       "      <th>db70</th>\n",
       "      <th>db71</th>\n",
       "      <th>db72</th>\n",
       "      <th>db73</th>\n",
       "      <th>db74</th>\n",
       "      <th>db75</th>\n",
       "      <th>db76</th>\n",
       "      <th>db77</th>\n",
       "      <th>db78</th>\n",
       "      <th>db79</th>\n",
       "      <th>db80</th>\n",
       "      <th>db81</th>\n",
       "      <th>db82</th>\n",
       "      <th>db83</th>\n",
       "      <th>db84</th>\n",
       "      <th>db85</th>\n",
       "      <th>db86</th>\n",
       "      <th>db87</th>\n",
       "      <th>db88</th>\n",
       "      <th>db89</th>\n",
       "      <th>db90</th>\n",
       "      <th>db91</th>\n",
       "      <th>db92</th>\n",
       "      <th>db93</th>\n",
       "      <th>db94</th>\n",
       "      <th>db95</th>\n",
       "      <th>db96</th>\n",
       "      <th>db97</th>\n",
       "      <th>db98</th>\n",
       "      <th>db99</th>\n",
       "      <th>db100</th>\n",
       "      <th>db101</th>\n",
       "      <th>db102</th>\n",
       "      <th>db103</th>\n",
       "      <th>db104</th>\n",
       "      <th>db105</th>\n",
       "      <th>db106</th>\n",
       "      <th>db107</th>\n",
       "      <th>db108</th>\n",
       "      <th>db109</th>\n",
       "      <th>db110</th>\n",
       "      <th>db111</th>\n",
       "      <th>db112</th>\n",
       "      <th>db113</th>\n",
       "      <th>db114</th>\n",
       "      <th>db115</th>\n",
       "      <th>db116</th>\n",
       "      <th>db117</th>\n",
       "      <th>db118</th>\n",
       "      <th>db119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>0.478612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576748</td>\n",
       "      <td>0.423252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject Focus  Eyes  Face  Near  Action  Accessory  Group  Collage  Human  \\\n",
       "0              1     0     1     0       0          1      1        0      0   \n",
       "1              0     1     0     0       0          0      1        1      0   \n",
       "\n",
       "   Occlusion  Info  Blur       cat       dog  db0  db1  db2  db3  db4  db5  \\\n",
       "0          1     0     1  0.521388  0.478612  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1          0     0     0  0.576748  0.423252  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   db6  db7  db8  db9  db10  db11  db12  db13  db14  db15  db16  db17  db18  \\\n",
       "0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db19  db20  db21  db22  db23  db24  db25  db26  db27  db28  db29  db30  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db31  db32  db33  db34  db35  db36  db37  db38  db39  db40  db41  db42  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db43  db44  db45  db46  db47  db48  db49  db50  db51  db52  db53  db54  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db55  db56  db57  db58  db59  db60  db61  db62  db63  db64  db65  db66  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db67  db68  db69  db70  db71  db72  db73  db74  db75  db76  db77  db78  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db79  db80  db81  db82  db83  db84  db85  db86  db87  db88  db89  db90  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db91  db92  db93  db94  db95  db96  db97  db98  db99  db100  db101  db102  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   \n",
       "\n",
       "   db103  db104  db105  db106  db107  db108  db109  db110  db111  db112  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   db113  db114  db115  db116  db117  db118  db119  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogbreed_cols = [f\"db{i}\" for i in range(res_dogbreed.shape[1])]\n",
    "\n",
    "df_meta = df_test[meta_features].copy()\n",
    "df_meta[dogbreed_cols] = 0\n",
    "df_meta.loc[df_meta.dog > 0.5, dogbreed_cols] = softmax(res_dogbreed)\n",
    "\n",
    "print(df_meta.shape)\n",
    "df_meta.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0923406",
   "metadata": {
    "papermill": {
     "duration": 0.027275,
     "end_time": "2022-01-14T12:36:03.034958",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.007683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586d3ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:03.110140Z",
     "iopub.status.busy": "2022-01-14T12:36:03.109244Z",
     "iopub.status.idle": "2022-01-14T12:36:03.111089Z",
     "shell.execute_reply": "2022-01-14T12:36:03.111521Z",
     "shell.execute_reply.started": "2022-01-13T13:00:17.882737Z"
    },
    "papermill": {
     "duration": 0.049233,
     "end_time": "2022-01-14T12:36:03.111663",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.062430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "class ModelwithMetadata(nn.Module):\n",
    "    def __init__(self, model_name, size=512, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=4)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        # Exclude the top layer\n",
    "        self.model.reset_classifier(0)\n",
    "        self.linear1 = nn.Linear(134, size*size)        \n",
    "        self.linear2 = nn.Linear(134, self.n_features)\n",
    "        self.linear3 = nn.Linear(self.n_features, 256)\n",
    "        self.linear4 = nn.Linear(256, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Metadata first\n",
    "        x = self.linear1(x2)\n",
    "        x = torch.reshape(x, (x2.shape[0], 1, self.size, self.size))\n",
    "        x = torch.cat((x1, x), dim=1)\n",
    "        x = self.model(x)\n",
    "        # Metadata Last\n",
    "        x2 = self.linear2(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear3(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear4(x)\n",
    "        return output\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "    \n",
    "class TransformerModelwithMetadataLast(nn.Module):\n",
    "    def __init__(self, model_name, size=224, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.backbone = TransformerModel(model_name, False)\n",
    "        num_features  = self.backbone.model.num_features\n",
    "        self.backbone.linear = nn.Linear(num_features, 256)\n",
    "        self.linear1 = nn.Linear(134, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x  = self.backbone(x1)\n",
    "        # Metadata Last\n",
    "        x2 = self.linear1(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear2(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "892d6b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:03.175264Z",
     "iopub.status.busy": "2022-01-14T12:36:03.169010Z",
     "iopub.status.idle": "2022-01-14T12:36:03.177655Z",
     "shell.execute_reply": "2022-01-14T12:36:03.177158Z",
     "shell.execute_reply.started": "2022-01-13T13:00:18.195705Z"
    },
    "papermill": {
     "duration": 0.039015,
     "end_time": "2022-01-14T12:36:03.177774",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.138759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df_img, df_meta, size, transforms=None, output_meta=True):\n",
    "        super().__init__()\n",
    "        self.df_img  = df_img.reset_index(drop=True).copy()\n",
    "        self.df_meta = df_meta.reset_index(drop=True).copy()\n",
    "        self.size    = size\n",
    "        self.transforms  = transforms\n",
    "        self.output_meta = output_meta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df_img.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img  = get_img(self.df_img.loc[index].path)\n",
    "        meta = torch.from_numpy(np.array(self.df_meta.loc[index], dtype=float))\n",
    "        if self.transforms:\n",
    "            h, w, _ = img.shape\n",
    "            trans = self.transforms(self.size, h, w)\n",
    "            img   = trans(image=img)['image']\n",
    "        if self.output_meta:\n",
    "            return img, meta\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c1fa335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:03.250341Z",
     "iopub.status.busy": "2022-01-14T12:36:03.249457Z",
     "iopub.status.idle": "2022-01-14T12:36:03.251452Z",
     "shell.execute_reply": "2022-01-14T12:36:03.252013Z",
     "shell.execute_reply.started": "2022-01-13T13:00:18.600231Z"
    },
    "papermill": {
     "duration": 0.044736,
     "end_time": "2022-01-14T12:36:03.252152",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.207416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tta_inference_transforms_1(size, h, w):\n",
    "    return Compose([\n",
    "        RandomResizedCrop(size, size, scale=(0.7, 1.0), p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        MotionBlur(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_tta_inference_transforms_2(size, h, w):\n",
    "    return Compose([\n",
    "        albResize(size, size, p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_inference_transforms_1(size, h, w):\n",
    "    h = int(size*1.2) if int(size*1.2) < h else h\n",
    "    w = int(size*1.2) if int(size*1.2) < w else w\n",
    "    return Compose([\n",
    "        CenterCrop(h, w, p=1.0),\n",
    "        albResize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_inference_transforms_2(size, h, w):\n",
    "    return Compose([\n",
    "        albResize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08be7521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:03.316774Z",
     "iopub.status.busy": "2022-01-14T12:36:03.315995Z",
     "iopub.status.idle": "2022-01-14T12:36:03.319726Z",
     "shell.execute_reply": "2022-01-14T12:36:03.320166Z",
     "shell.execute_reply.started": "2022-01-13T13:00:18.721408Z"
    },
    "papermill": {
     "duration": 0.039206,
     "end_time": "2022-01-14T12:36:03.320290",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.281084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, use_meta, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    img_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs, metas) in pbar:\n",
    "        imgs  = imgs.to(device).float()\n",
    "        if use_meta != 0:\n",
    "            metas = metas[:,:use_meta].to(device).float()\n",
    "            img_preds = model(imgs, metas)\n",
    "        else:\n",
    "            img_preds = model(imgs)\n",
    "        img_preds_all += [img_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    img_preds_all = np.concatenate(img_preds_all, axis=0)\n",
    "    return img_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adc97002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:03.384873Z",
     "iopub.status.busy": "2022-01-14T12:36:03.384272Z",
     "iopub.status.idle": "2022-01-14T12:36:03.388240Z",
     "shell.execute_reply": "2022-01-14T12:36:03.387781Z",
     "shell.execute_reply.started": "2022-01-13T13:00:19.116757Z"
    },
    "papermill": {
     "duration": 0.039029,
     "end_time": "2022-01-14T12:36:03.388374",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.349345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, size):\n",
    "    df = df.copy()\n",
    "    label_col  = \"Pawclass\"\n",
    "    dataloader = ImageDataLoaders.from_df(\n",
    "        df,\n",
    "        valid_pct=0.2,  # Dummy\n",
    "        seed=CFG[\"seed\"],\n",
    "        fn_col='path',\n",
    "        label_col=label_col,\n",
    "        y_block=RegressionBlock,\n",
    "        bs=CFG['batch_size'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        item_tfms=Resize(size),\n",
    "        batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def petfinder_rmse(input,target):\n",
    "    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "562e9594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:03.455100Z",
     "iopub.status.busy": "2022-01-14T12:36:03.454444Z",
     "iopub.status.idle": "2022-01-14T12:36:03.457684Z",
     "shell.execute_reply": "2022-01-14T12:36:03.457189Z",
     "shell.execute_reply.started": "2022-01-13T13:00:19.525044Z"
    },
    "papermill": {
     "duration": 0.039848,
     "end_time": "2022-01-14T12:36:03.457801",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.417953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_learner(df, size, model, model_path):\n",
    "    dataloader = prepare_dataloader(df, size)\n",
    "    if -1 < max(model.find(\"swin\"), model.find(\"beit\"), model.find(\"vit\"), model.find(\"cait\")):\n",
    "        model = TransformerModel(model, pretrained=False)\n",
    "    else:\n",
    "        model = Model(model, pretrained=False)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    learner = Learner(\n",
    "        dataloader,\n",
    "        model,\n",
    "        loss_func=BCEWithLogitsLossFlat(),\n",
    "        metrics=petfinder_rmse).to_fp16()\n",
    "    return learner, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43727a5a",
   "metadata": {
    "papermill": {
     "duration": 0.028978,
     "end_time": "2022-01-14T12:36:03.516167",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.487189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5d0fdb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:36:03.592013Z",
     "iopub.status.busy": "2022-01-14T12:36:03.591155Z",
     "iopub.status.idle": "2022-01-14T12:41:07.866611Z",
     "shell.execute_reply": "2022-01-14T12:41:07.867052Z",
     "shell.execute_reply.started": "2022-01-13T13:00:21.364149Z"
    },
    "papermill": {
     "duration": 304.321601,
     "end_time": "2022-01-14T12:41:07.867233",
     "exception": false,
     "start_time": "2022-01-14T12:36:03.545632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 18.90it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 20.52it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 22.96it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 23.46it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 18.43it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 21.69it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 23.46it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 23.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_res = []\n",
    "for fastai, size, use_meta, dataset_type, model, model_path in CFG['models']:\n",
    "    \n",
    "    if fastai:\n",
    "        learn, data_loader = get_learner(df_train, size, model, model_path)\n",
    "        data_loader = data_loader.test_dl(df_test)\n",
    "        res, _ = learn.tta(dl=data_loader, n=CFG[\"tta\"], beta=0)\n",
    "        res    = res.detach().numpy()\n",
    "        if -1 < model_path.find(\"binary\"):\n",
    "            res = res*100\n",
    "        all_res.append(res)\n",
    "        \n",
    "        del learn, data_loader\n",
    "    else:\n",
    "        if 1 < CFG[\"tta\"]:\n",
    "            if dataset_type == 1:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_tta_inference_transforms_1)\n",
    "            else:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_tta_inference_transforms_2)\n",
    "        else:\n",
    "            if dataset_type == 1:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_inference_transforms_1)\n",
    "            else:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_inference_transforms_2)\n",
    "        data_loader = torch.utils.data.DataLoader(inference_ds,\n",
    "                                                  batch_size=CFG['batch_size'],\n",
    "                                                  drop_last=False,\n",
    "                                                  pin_memory=False,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=CFG['num_workers'])\n",
    "        if -1 < model_path.find(\"swin\"):\n",
    "            if use_meta == 0:\n",
    "                model = TransformerModel(model, pretrained=False)\n",
    "            else:\n",
    "                model = TransformerModelwithMetadataLast(model, size, pretrained=False)\n",
    "        else:\n",
    "            if use_meta == 0:\n",
    "                model = Model(model, pretrained=False)\n",
    "            else:\n",
    "                model = ModelwithMetadata(model, size, pretrained=False)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(CFG[\"device\"])\n",
    "\n",
    "        tta_res = []\n",
    "        for i in range(CFG[\"tta\"]):\n",
    "            with torch.no_grad():\n",
    "                res = inference_one_epoch(model, use_meta, data_loader, CFG[\"device\"])\n",
    "                if -1 < model_path.find(\"binary\"):\n",
    "                    res = my_sigmoid(res)*100\n",
    "                tta_res.append(res)\n",
    "        all_res.append(np.mean(tta_res, 0))\n",
    "\n",
    "        del model, inference_ds, data_loader\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5d3dbcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:41:07.987911Z",
     "iopub.status.busy": "2022-01-14T12:41:07.987054Z",
     "iopub.status.idle": "2022-01-14T12:41:07.993940Z",
     "shell.execute_reply": "2022-01-14T12:41:07.993515Z",
     "shell.execute_reply.started": "2022-01-04T02:38:13.021065Z"
    },
    "papermill": {
     "duration": 0.068915,
     "end_time": "2022-01-14T12:41:07.994056",
     "exception": false,
     "start_time": "2022-01-14T12:41:07.925141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(np.array(all_res).reshape(len(CFG[\"models\"]),-1)).T\n",
    "if not CFG[\"submit\"]:\n",
    "    df_pred[\"target\"] = df_test.Pawpularity\n",
    "    df_pred.to_csv(\"./inference_result_train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "706c1ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:41:08.114208Z",
     "iopub.status.busy": "2022-01-14T12:41:08.113677Z",
     "iopub.status.idle": "2022-01-14T12:41:08.131128Z",
     "shell.execute_reply": "2022-01-14T12:41:08.131625Z",
     "shell.execute_reply.started": "2022-01-04T02:38:13.040017Z"
    },
    "papermill": {
     "duration": 0.080574,
     "end_time": "2022-01-14T12:41:08.131768",
     "exception": false,
     "start_time": "2022-01-14T12:41:08.051194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.6363556  43.73438509 43.75105113 43.84289141 42.90526651 44.16642599\n",
      " 42.77383218 43.63160244]\n"
     ]
    }
   ],
   "source": [
    "if CFG[\"stacking\"]:\n",
    "    loaded_model = pickle.load(open(\"../input/petfinder-stacking-model/stacking_model.pickle\", 'rb'))\n",
    "    # Calculate mean every model type\n",
    "    sta = 0\n",
    "    mean_every_model = []\n",
    "    for i in range(4, len(CFG[\"models\"])+1, 4):  # 4 is fold num\n",
    "        mean_every_model.append(df_pred.iloc[:, sta:i].mean(1))\n",
    "        sta = i\n",
    "    df_mean_every_model = pd.concat(mean_every_model, axis=1)\n",
    "    # Predict with stacking model\n",
    "    ensembled = loaded_model.predict(df_mean_every_model)\n",
    "else:\n",
    "    ensembled = df_pred.mean(1)\n",
    "print(ensembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7f11742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T12:41:08.251774Z",
     "iopub.status.busy": "2022-01-14T12:41:08.250306Z",
     "iopub.status.idle": "2022-01-14T12:41:08.266846Z",
     "shell.execute_reply": "2022-01-14T12:41:08.266359Z",
     "shell.execute_reply.started": "2022-01-04T02:38:13.056344Z"
    },
    "papermill": {
     "duration": 0.077572,
     "end_time": "2022-01-14T12:41:08.266964",
     "exception": false,
     "start_time": "2022-01-14T12:41:08.189392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG[\"submit\"]:\n",
    "    ss = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n",
    "    ss[\"Pawpularity\"] = ensembled\n",
    "    ss.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 351.67985,
   "end_time": "2022-01-14T12:41:11.985884",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-14T12:35:20.306034",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
