{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2cc9e65",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-04T08:09:54.482071Z",
     "iopub.status.busy": "2022-01-04T08:09:54.481339Z",
     "iopub.status.idle": "2022-01-04T08:09:54.484157Z",
     "shell.execute_reply": "2022-01-04T08:09:54.484629Z",
     "shell.execute_reply.started": "2022-01-04T08:06:30.227511Z"
    },
    "papermill": {
     "duration": 0.034622,
     "end_time": "2022-01-04T08:09:54.484840",
     "exception": false,
     "start_time": "2022-01-04T08:09:54.450218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-optimizers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c728f94b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:09:54.532077Z",
     "iopub.status.busy": "2022-01-04T08:09:54.531238Z",
     "iopub.status.idle": "2022-01-04T08:10:03.110103Z",
     "shell.execute_reply": "2022-01-04T08:10:03.109621Z",
     "shell.execute_reply.started": "2022-01-04T08:06:30.351152Z"
    },
    "papermill": {
     "duration": 8.604482,
     "end_time": "2022-01-04T08:10:03.110232",
     "exception": false,
     "start_time": "2022-01-04T08:09:54.505750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from shutil import copyfile\n",
    "from IPython.core.display import Video, display\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torchvision import models, transforms\n",
    "from torch_optimizer.radam import RAdam\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n",
    "    ShiftScaleRotate, CenterCrop, Resize, Rotate, RandomRotate90, RGBShift, ChannelShuffle)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option(\"max_columns\", 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac6f3d",
   "metadata": {
    "papermill": {
     "duration": 0.01839,
     "end_time": "2022-01-04T08:10:03.147546",
     "exception": false,
     "start_time": "2022-01-04T08:10:03.129156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cbb2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:03.236846Z",
     "iopub.status.busy": "2022-01-04T08:10:03.236018Z",
     "iopub.status.idle": "2022-01-04T08:10:03.239360Z",
     "shell.execute_reply": "2022-01-04T08:10:03.239860Z",
     "shell.execute_reply.started": "2022-01-04T08:06:39.109065Z"
    },
    "papermill": {
     "duration": 0.07386,
     "end_time": "2022-01-04T08:10:03.240030",
     "exception": false,
     "start_time": "2022-01-04T08:10:03.166170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'save_prev': [True, ['petfinder_*.pt']],\n",
       " 'seed': 42,\n",
       " 'device': 'cuda:0',\n",
       " 'input_img': '../input/petfinder-pawpularity-score/train/',\n",
       " 'input_path': '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
       " 'output_path': './',\n",
       " 'db_model': 'swin_large_patch4_window7_224_in22k',\n",
       " 'db_size': 224,\n",
       " 'pretrain': '../input/petfinder-fastai-semisupervised-models/petfinder_swin_binary_ss_fastai_4.pth',\n",
       " 'save_name': 'petfinder_swin_binary_ed_ss2-2',\n",
       " 'model': 'swin_large_patch4_window7_224_in22k',\n",
       " 'loss': 'binary',\n",
       " 'size': 224,\n",
       " 'fold': 4,\n",
       " 'break_fold': 99,\n",
       " 'batch_size': 32,\n",
       " 'epochs': 4,\n",
       " 'mixup_ratio': 0,\n",
       " 'T_0': 20,\n",
       " 'lr': 2e-05,\n",
       " 'momentum': 0.9,\n",
       " 'weight_decay': 0.0001,\n",
       " 'accum_iter': 1,\n",
       " 'run_valid_in_training': 99,\n",
       " 'step_valid_in_training': 32,\n",
       " 'early_stopping': 10,\n",
       " 'verbose_step': 1,\n",
       " 'num_workers': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG = {\n",
    "    \"save_prev\"     : [True, [\"petfinder_*.pt\", ]],\n",
    "    \"seed\"          : 42,\n",
    "    'device'        : \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"input_img\"     : '../input/petfinder-pawpularity-score/train/',\n",
    "    \"input_path\"    : '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
    "    \"output_path\"   : './',\n",
    "    \"db_model\"      : 'swin_large_patch4_window7_224_in22k',\n",
    "    \"db_size\"       : 224,\n",
    "    \"pretrain\"      : \"../input/petfinder-fastai-semisupervised-models/petfinder_swin_binary_ss_fastai_4.pth\",\n",
    "    \"save_name\"     : \"petfinder_swin_binary_ed_ss2-2\",\n",
    "    \"model\"         : \"swin_large_patch4_window7_224_in22k\",\n",
    "    \"loss\"          : \"binary\",\n",
    "    \"size\"          : 224,\n",
    "    \"fold\"          : 4,\n",
    "    \"break_fold\"    : 99,\n",
    "    \"batch_size\"    : 32,\n",
    "    \"epochs\"        : 4,\n",
    "    \"mixup_ratio\"   : 0,\n",
    "    'T_0'           : 20,\n",
    "    \"lr\"            : 2e-5,\n",
    "    'momentum'      : 0.9,\n",
    "    'weight_decay'  : 1e-4,\n",
    "    \"accum_iter\"    : 1,\n",
    "    \"run_valid_in_training\" : 99,  # Epoch starts 0.\n",
    "    \"step_valid_in_training\": 32,  # Run valid every 32 steps.\n",
    "    'early_stopping': 10,\n",
    "    'verbose_step'  : 1,\n",
    "    \"num_workers\"   : 4\n",
    "}\n",
    "\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a837cb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:03.288446Z",
     "iopub.status.busy": "2022-01-04T08:10:03.287899Z",
     "iopub.status.idle": "2022-01-04T08:10:03.296733Z",
     "shell.execute_reply": "2022-01-04T08:10:03.296285Z",
     "shell.execute_reply.started": "2022-01-04T08:06:39.162229Z"
    },
    "papermill": {
     "duration": 0.036149,
     "end_time": "2022-01-04T08:10:03.296845",
     "exception": false,
     "start_time": "2022-01-04T08:10:03.260696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "def softmax(x):\n",
    "    max = np.max(x,axis=1,keepdims=True)\n",
    "    e_x = np.exp(x - max)\n",
    "    sum = np.sum(e_x,axis=1,keepdims=True)\n",
    "    return e_x / sum \n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c27e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:03.340091Z",
     "iopub.status.busy": "2022-01-04T08:10:03.339527Z",
     "iopub.status.idle": "2022-01-04T08:10:28.545994Z",
     "shell.execute_reply": "2022-01-04T08:10:28.546434Z",
     "shell.execute_reply.started": "2022-01-04T08:07:08.546610Z"
    },
    "papermill": {
     "duration": 25.230728,
     "end_time": "2022-01-04T08:10:28.546612",
     "exception": false,
     "start_time": "2022-01-04T08:10:03.315884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petfinder_swin_binary_ed_ss2-2_1.pt\n",
      "petfinder_swin_binary_ed_ss2-2_0.pt\n",
      "petfinder_swin_binary_ed_ss2-2_3.pt\n",
      "petfinder_swin_binary_ed_ss2-2_2.pt\n"
     ]
    }
   ],
   "source": [
    "if CFG['save_prev'][0]:\n",
    "    for file_pattern in CFG['save_prev'][1]:\n",
    "        for f in glob(f\"../input/petfinder-cnn-models-with-pretrained-edata/{file_pattern}\"):\n",
    "            filename = os.path.basename(f)\n",
    "            print(filename)\n",
    "            !cp {f} ./{filename.replace(\"ed_ss2-2\", \"ss2_meta\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704d564",
   "metadata": {
    "papermill": {
     "duration": 6.212214,
     "end_time": "2022-01-04T08:10:34.780080",
     "exception": false,
     "start_time": "2022-01-04T08:10:28.567866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8554dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:38.328509Z",
     "iopub.status.busy": "2022-01-04T08:10:38.327643Z",
     "iopub.status.idle": "2022-01-04T08:10:38.559954Z",
     "shell.execute_reply": "2022-01-04T08:10:38.560555Z",
     "shell.execute_reply.started": "2022-01-04T04:59:32.536335Z"
    },
    "papermill": {
     "duration": 2.054913,
     "end_time": "2022-01-04T08:10:38.560752",
     "exception": false,
     "start_time": "2022-01-04T08:10:36.505839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
      "(9860, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>path</th>\n",
       "      <th>Pawclass</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/000...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/000...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
       "0          0      1        0      0          0     0     0           63   \n",
       "1          0      0        0      0          0     0     0           42   \n",
       "\n",
       "                                                path  Pawclass  bins  \n",
       "0  ../input/petfinder-pawpularity-score/train/000...      0.63    26  \n",
       "1  ../input/petfinder-pawpularity-score/train/000...      0.42    17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(CFG['input_path'])\n",
    "df_train[\"path\"] = [f\"{CFG['input_img']}{i}.jpg\" for i in df_train.Id]\n",
    "df_train[\"Pawclass\"] = df_train.Pawpularity / 100\n",
    "\n",
    "num_bins = int(np.ceil(2*((len(df_train))**(1./3))))\n",
    "df_train['bins'] = pd.cut(df_train['Pawclass'], bins=num_bins, labels=False)\n",
    "\n",
    "meta_features = [c for c in df_train.columns if c not in [\"Id\",\"path\", \"Pawpularity\",\"Pawclass\",\"bins\"]]\n",
    "\n",
    "print(meta_features)\n",
    "print(df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ed1db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:40.198717Z",
     "iopub.status.busy": "2022-01-04T08:10:40.197737Z",
     "iopub.status.idle": "2022-01-04T08:10:40.824121Z",
     "shell.execute_reply": "2022-01-04T08:10:40.825305Z",
     "shell.execute_reply.started": "2022-01-04T04:59:32.606623Z"
    },
    "papermill": {
     "duration": 0.74205,
     "end_time": "2022-01-04T08:10:40.825528",
     "exception": false,
     "start_time": "2022-01-04T08:10:40.083478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.Pawpularity.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6fe57",
   "metadata": {
    "papermill": {
     "duration": 0.039425,
     "end_time": "2022-01-04T08:10:40.907976",
     "exception": false,
     "start_time": "2022-01-04T08:10:40.868551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog and cat labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0bbb7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:40.994657Z",
     "iopub.status.busy": "2022-01-04T08:10:40.993778Z",
     "iopub.status.idle": "2022-01-04T08:10:40.997936Z",
     "shell.execute_reply": "2022-01-04T08:10:40.998524Z",
     "shell.execute_reply.started": "2022-01-04T04:59:33.027937Z"
    },
    "papermill": {
     "duration": 0.051971,
     "end_time": "2022-01-04T08:10:40.998697",
     "exception": false,
     "start_time": "2022-01-04T08:10:40.946726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    try:\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None\n",
    "    model = models.densenet121(pretrained=False)\n",
    "    model.classifier = nn.Sequential(nn.Linear(1024, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 256),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.1),\n",
    "                                 nn.Linear(256, 2))\n",
    "    model.parameters = checkpoint['parameters']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deee4014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:41.084639Z",
     "iopub.status.busy": "2022-01-04T08:10:41.083833Z",
     "iopub.status.idle": "2022-01-04T08:10:41.087610Z",
     "shell.execute_reply": "2022-01-04T08:10:41.088765Z",
     "shell.execute_reply.started": "2022-01-04T04:59:33.036165Z"
    },
    "papermill": {
     "duration": 0.052299,
     "end_time": "2022-01-04T08:10:41.089044",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.036745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_transform(imagepath):\n",
    "    test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(imagepath)\n",
    "    imagetensor = test_transforms(image)\n",
    "    return imagetensor\n",
    "\n",
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img = image_transform(self.df.loc[index].path)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "317f2cfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:41.172898Z",
     "iopub.status.busy": "2022-01-04T08:10:41.172029Z",
     "iopub.status.idle": "2022-01-04T08:10:41.175706Z",
     "shell.execute_reply": "2022-01-04T08:10:41.176183Z",
     "shell.execute_reply.started": "2022-01-04T04:59:33.049338Z"
    },
    "papermill": {
     "duration": 0.049847,
     "end_time": "2022-01-04T08:10:41.176302",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.126455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [image_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb4dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:59:33.060997Z",
     "iopub.status.busy": "2022-01-04T04:59:33.06077Z",
     "iopub.status.idle": "2022-01-04T05:02:01.672942Z",
     "shell.execute_reply": "2022-01-04T05:02:01.672136Z",
     "shell.execute_reply.started": "2022-01-04T04:59:33.060966Z"
    },
    "papermill": {
     "duration": 0.023659,
     "end_time": "2022-01-04T08:10:41.222294",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.198635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "inference_ds = PetFinderDataset(df_train, transforms=None)\n",
    "data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                           batch_size=CFG['batch_size'],\n",
    "                                           drop_last=False,\n",
    "                                           pin_memory=False,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=CFG['num_workers'])\n",
    "\n",
    "model = load_model(\"../input/cat-vs-dog-model/cat-v-dog-classifier-pytorch-master/models/catvdog.pth\")\n",
    "model.to(CFG[\"device\"])\n",
    "\n",
    "with torch.no_grad():\n",
    "    res_cat_dog = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "del model, inference_ds, data_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e647ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T05:02:01.675302Z",
     "iopub.status.busy": "2022-01-04T05:02:01.674595Z",
     "iopub.status.idle": "2022-01-04T05:02:01.697425Z",
     "shell.execute_reply": "2022-01-04T05:02:01.696677Z",
     "shell.execute_reply.started": "2022-01-04T05:02:01.675256Z"
    },
    "papermill": {
     "duration": 0.021443,
     "end_time": "2022-01-04T08:10:41.265783",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.244340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "df_train[[\"cat\",\"dog\"]] = softmax(res_cat_dog)\n",
    "meta_features += [\"cat\",\"dog\"]\n",
    "\n",
    "print(df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219310c",
   "metadata": {
    "papermill": {
     "duration": 0.022066,
     "end_time": "2022-01-04T08:10:41.309592",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.287526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog breed for dog label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fdd44fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:41.358744Z",
     "iopub.status.busy": "2022-01-04T08:10:41.358022Z",
     "iopub.status.idle": "2022-01-04T08:10:41.360076Z",
     "shell.execute_reply": "2022-01-04T08:10:41.360488Z",
     "shell.execute_reply.started": "2022-01-04T05:02:01.699297Z"
    },
    "papermill": {
     "duration": 0.029323,
     "end_time": "2022-01-04T08:10:41.360611",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.331288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 120)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff4566fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:41.412230Z",
     "iopub.status.busy": "2022-01-04T08:10:41.411499Z",
     "iopub.status.idle": "2022-01-04T08:10:41.413592Z",
     "shell.execute_reply": "2022-01-04T08:10:41.414032Z",
     "shell.execute_reply.started": "2022-01-04T05:08:02.348971Z"
    },
    "papermill": {
     "duration": 0.031505,
     "end_time": "2022-01-04T08:10:41.414177",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.382672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms  = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img  = get_img(self.df.loc[index].path).copy()\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        return img\n",
    "    \n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "        Resize(CFG[\"db_size\"], CFG[\"db_size\"], p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b46339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:41.462319Z",
     "iopub.status.busy": "2022-01-04T08:10:41.460254Z",
     "iopub.status.idle": "2022-01-04T08:10:41.468052Z",
     "shell.execute_reply": "2022-01-04T08:10:41.467625Z",
     "shell.execute_reply.started": "2022-01-04T05:08:03.267433Z"
    },
    "papermill": {
     "duration": 0.032447,
     "end_time": "2022-01-04T08:10:41.468195",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.435748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [image_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d87830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T05:08:03.474329Z",
     "iopub.status.busy": "2022-01-04T05:08:03.473537Z",
     "iopub.status.idle": "2022-01-04T05:10:46.644765Z",
     "shell.execute_reply": "2022-01-04T05:10:46.643931Z",
     "shell.execute_reply.started": "2022-01-04T05:08:03.474281Z"
    },
    "papermill": {
     "duration": 7.357233,
     "end_time": "2022-01-04T08:10:48.849834",
     "exception": false,
     "start_time": "2022-01-04T08:10:41.492601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "inference_ds = PetFinderDataset(df_train, transforms=get_inference_transforms())\n",
    "data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                           batch_size=CFG['batch_size'],\n",
    "                                           drop_last=False,\n",
    "                                           pin_memory=False,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=CFG['num_workers'])\n",
    "\n",
    "model = SwinModel(CFG['db_model'], pretrained=False)\n",
    "model.load_state_dict(torch.load(\"../input/petfinder-dogbreed-cnn-models/dogbreed_swin_ce.pt\"))\n",
    "model.to(CFG[\"device\"])\n",
    "\n",
    "with torch.no_grad():\n",
    "    res_dogbreed = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "del model, inference_ds, data_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12f245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T05:10:46.647222Z",
     "iopub.status.busy": "2022-01-04T05:10:46.647011Z",
     "iopub.status.idle": "2022-01-04T05:10:46.807714Z",
     "shell.execute_reply": "2022-01-04T05:10:46.806885Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.647193Z"
    },
    "papermill": {
     "duration": 0.02182,
     "end_time": "2022-01-04T08:10:48.894880",
     "exception": false,
     "start_time": "2022-01-04T08:10:48.873060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "df_dogbreed = pd.DataFrame(softmax(res_dogbreed))\n",
    "df_dogbreed[\"dog\"] = softmax(res_cat_dog)[:,1] > 0.5\n",
    "df_dogbreed.loc[df_dogbreed.dog==False, :120] = 0\n",
    "df_dogbreed = df_dogbreed.drop(\"dog\", axis=1)\n",
    "df_dogbreed.columns = [f\"db{i}\" for i in df_dogbreed.columns]\n",
    "\n",
    "print(df_dogbreed.shape)\n",
    "df_dogbreed.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07dd66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T05:10:46.809932Z",
     "iopub.status.busy": "2022-01-04T05:10:46.809267Z",
     "iopub.status.idle": "2022-01-04T05:10:46.900596Z",
     "shell.execute_reply": "2022-01-04T05:10:46.899849Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.809891Z"
    },
    "papermill": {
     "duration": 0.021125,
     "end_time": "2022-01-04T08:10:48.937418",
     "exception": false,
     "start_time": "2022-01-04T08:10:48.916293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "df_meta = df_train[meta_features].join(df_dogbreed)\n",
    "\n",
    "print(df_meta.shape)\n",
    "df_meta.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0cdcf2",
   "metadata": {
    "papermill": {
     "duration": 0.021174,
     "end_time": "2022-01-04T08:10:48.980370",
     "exception": false,
     "start_time": "2022-01-04T08:10:48.959196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e329a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:49.034667Z",
     "iopub.status.busy": "2022-01-04T08:10:49.030835Z",
     "iopub.status.idle": "2022-01-04T08:10:49.036667Z",
     "shell.execute_reply": "2022-01-04T08:10:49.037057Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.903492Z"
    },
    "papermill": {
     "duration": 0.035454,
     "end_time": "2022-01-04T08:10:49.037198",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.001744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "    \n",
    "class SwinModelwithMetadataLast(nn.Module):\n",
    "    def __init__(self, model_name, size=CFG[\"size\"], pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.backbone = SwinModel(model_name, False)\n",
    "        self.backbone.load_state_dict(torch.load(CFG['pretrain']))\n",
    "        num_features  = self.backbone.model.num_features\n",
    "        self.backbone.linear = nn.Linear(num_features, 256)\n",
    "        self.linear1 = nn.Linear(134, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x  = self.backbone(x1)\n",
    "        # Metadata Last\n",
    "        x2 = self.linear1(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear2(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff44f99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:49.089247Z",
     "iopub.status.busy": "2022-01-04T08:10:49.088569Z",
     "iopub.status.idle": "2022-01-04T08:10:49.091119Z",
     "shell.execute_reply": "2022-01-04T08:10:49.090712Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.919491Z"
    },
    "papermill": {
     "duration": 0.032055,
     "end_time": "2022-01-04T08:10:49.091224",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.059169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df_img, df_meta, transforms=None, output_meta=True, output_label=True):\n",
    "        super().__init__()\n",
    "        self.df_img  = df_img.reset_index(drop=True).copy()\n",
    "        self.df_meta = df_meta.reset_index(drop=True).copy()\n",
    "        self.transforms   = transforms\n",
    "        self.output_meta  = output_meta\n",
    "        self.output_label = output_label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df_img.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img = get_img(self.df_img.loc[index].path)\n",
    "        y   = torch.from_numpy(np.array(self.df_img.loc[index].Pawclass))  # Pawpularity\n",
    "        if self.output_meta:\n",
    "            meta = torch.from_numpy(np.array(self.df_meta.loc[index], dtype=float))\n",
    "        if self.transforms:\n",
    "            img  = self.transforms(image=img)['image']\n",
    "        if self.output_label:\n",
    "            if self.output_meta:\n",
    "                return img, meta, y\n",
    "            else:\n",
    "                return img, y\n",
    "        if self.output_meta:\n",
    "            return img, meta\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d54e1658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:49.148031Z",
     "iopub.status.busy": "2022-01-04T08:10:49.147254Z",
     "iopub.status.idle": "2022-01-04T08:10:49.149512Z",
     "shell.execute_reply": "2022-01-04T08:10:49.149893Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.933836Z"
    },
    "papermill": {
     "duration": 0.037359,
     "end_time": "2022-01-04T08:10:49.150012",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.112653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "        Resize(CFG['size'], CFG['size'], p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "  \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "        Resize(CFG['size'], CFG['size'], p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "#https://www.kaggle.com/heyytanay/definitive-pytorch-trainer-mixup-kfolds-w-b\n",
    "def mixup_augmentation(x:torch.Tensor, y:torch.Tensor, alpha:float = 1.0):\n",
    "    \"\"\"\n",
    "    Function which performs Mixup augmentation\n",
    "    \"\"\"\n",
    "    assert alpha > 0, \"Alpha must be greater than 0\"\n",
    "    assert x.shape[0] > 1, \"Need more than 1 sample to apply mixup\"\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_idx = torch.randperm(x.shape[0])\n",
    "    mixed_x  = lam * x + (1 - lam) * x[rand_idx, :]\n",
    "    target_a, target_b = y, y[rand_idx]\n",
    "    return mixed_x, target_a, target_b, lam\n",
    "\n",
    "def prepare_dataloader(train, valid, train_meta=None, valid_meta=None):\n",
    "    if train_meta is None or valid_meta is None:\n",
    "        train_ds = PetFinderDataset(train, pd.DataFrame(), transforms=get_train_transforms(), output_meta=False)\n",
    "        valid_ds = PetFinderDataset(valid, pd.DataFrame(), transforms=get_valid_transforms(), output_meta=False)\n",
    "    else:\n",
    "        train_ds = PetFinderDataset(train, train_meta, transforms=get_train_transforms())\n",
    "        valid_ds = PetFinderDataset(valid, valid_meta, transforms=get_valid_transforms())\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds,\n",
    "                                               batch_size=CFG['batch_size'],\n",
    "                                               drop_last=False,\n",
    "                                               pin_memory=False,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=CFG['num_workers'])\n",
    "    val_loader = torch.utils.data.DataLoader(valid_ds,\n",
    "                                             batch_size=CFG['batch_size'],\n",
    "                                             pin_memory=False,\n",
    "                                             shuffle=False,\n",
    "                                             num_workers=CFG['num_workers'])\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae234ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:49.213977Z",
     "iopub.status.busy": "2022-01-04T08:10:49.211157Z",
     "iopub.status.idle": "2022-01-04T08:10:49.217056Z",
     "shell.execute_reply": "2022-01-04T08:10:49.216651Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.955392Z"
    },
    "papermill": {
     "duration": 0.045883,
     "end_time": "2022-01-04T08:10:49.217158",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.171275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, val_loader, device,\n",
    "                    scheduler=None, schd_batch_update=False, best_rmse=999):\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "    mean_loss    = 0\n",
    "    best_model   = None\n",
    "    best_hist    = None\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, metas, targets) in pbar:\n",
    "        model.train()\n",
    "\n",
    "        imgs    = imgs.to(device).float()\n",
    "        metas   = metas.to(device).float()\n",
    "        targets = targets.reshape(-1,1).to(device).float()\n",
    "\n",
    "        if torch.rand(1)[0] < CFG[\"mixup_ratio\"]:\n",
    "            mix_img, tar_a, tar_b, lam = mixup_augmentation(imgs, targets, alpha=0.5)\n",
    "            with autocast():\n",
    "                img_preds = model(mix_img, metas)\n",
    "                # Mixup loss calculation\n",
    "                loss_a = loss_fn(img_preds, tar_a)\n",
    "                loss_b = loss_fn(img_preds, tar_b)\n",
    "                loss = (loss_a * lam + (1 - lam) * loss_b) / CFG['accum_iter']\n",
    "        else:\n",
    "            with autocast():\n",
    "                img_preds = model(imgs, metas)\n",
    "                loss = loss_fn(img_preds, targets) / CFG['accum_iter']\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if running_loss is None:\n",
    "            running_loss = loss.item()\n",
    "        else:\n",
    "            running_loss = running_loss * .99 + loss.item() * .01\n",
    "        mean_loss += loss.item()\n",
    "\n",
    "        if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad() \n",
    "            if scheduler is not None and schd_batch_update:\n",
    "                scheduler.step()\n",
    "\n",
    "        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "            description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "            pbar.set_description(description)\n",
    "                \n",
    "        if CFG[\"run_valid_in_training\"] <= epoch and (step + 1) % CFG[\"step_valid_in_training\"] == 0:\n",
    "            with torch.no_grad():\n",
    "                valid_rmse, _, valid_hist = valid_one_epoch(epoch, model, loss_fn, val_loader, device)\n",
    "            if valid_rmse < best_rmse:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_rmse  = valid_rmse\n",
    "                best_hist  = valid_hist\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "        \n",
    "    return mean_loss/len(train_loader), best_rmse, best_model, best_hist\n",
    "        \n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device,\n",
    "                    scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum   = 0\n",
    "    sample_num = 0\n",
    "    img_preds_all = []\n",
    "    img_truth_all = []\n",
    "    \n",
    "    for step, (imgs, metas, targets) in enumerate(val_loader):\n",
    "        imgs    = imgs.to(device)\n",
    "        metas   = metas.to(device).float()\n",
    "        targets = targets.reshape(-1,1).to(device).float()\n",
    "        \n",
    "        img_preds = model(imgs, metas)\n",
    "        img_preds_all += [img_preds.detach().cpu().numpy()]\n",
    "        img_truth_all += [targets.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(img_preds, targets)\n",
    "        loss_sum   += loss.item()*targets.shape[0]\n",
    "        sample_num += targets.shape[0]  \n",
    "\n",
    "    if CFG[\"loss\"] == \"binary\":\n",
    "        img_preds_all = (sigmoid(np.concatenate(img_preds_all))*100).astype(int)\n",
    "        img_truth_all = (np.concatenate(img_truth_all)*100).astype(int)\n",
    "    else:\n",
    "        img_preds_all = np.concatenate(img_preds_all)\n",
    "        img_truth_all = np.concatenate(img_truth_all)\n",
    "    rmse = np.sqrt(mean_squared_error(img_preds_all, img_truth_all))\n",
    "    print('validation rmse = {:.6f}'.format(rmse))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "            \n",
    "    return loss_sum/sample_num, rmse,  [img_preds_all, img_truth_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0230f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T08:10:49.268878Z",
     "iopub.status.busy": "2022-01-04T08:10:49.268089Z",
     "iopub.status.idle": "2022-01-04T08:10:49.270528Z",
     "shell.execute_reply": "2022-01-04T08:10:49.270070Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.981652Z"
    },
    "papermill": {
     "duration": 0.031903,
     "end_time": "2022-01-04T08:10:49.270635",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.238732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sgd_optimizer(model, lr, momentum, weight_decay):\n",
    "    params = []\n",
    "    for key, value in model.named_parameters():\n",
    "        if not value.requires_grad:\n",
    "            continue\n",
    "        apply_weight_decay = weight_decay\n",
    "        apply_lr = lr\n",
    "        if 'bias' in key or 'bn' in key:\n",
    "            apply_weight_decay = 0\n",
    "        if 'bias' in key:\n",
    "            apply_lr = 2 * lr       # Just a Caffe-style common practice. Made no difference.\n",
    "        params += [{'params': [value], 'lr': apply_lr, 'weight_decay': apply_weight_decay}]\n",
    "    optimizer = torch.optim.SGD(params, lr, momentum=momentum)\n",
    "    return optimizer\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, yhat, y):\n",
    "        return torch.sqrt(self.mse(yhat, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2d8ca",
   "metadata": {
    "papermill": {
     "duration": 0.022104,
     "end_time": "2022-01-04T08:10:49.314437",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.292333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a003ab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T05:10:46.994342Z",
     "iopub.status.busy": "2022-01-04T05:10:46.994076Z",
     "iopub.status.idle": "2022-01-04T05:24:00.252532Z",
     "shell.execute_reply": "2022-01-04T05:24:00.251336Z",
     "shell.execute_reply.started": "2022-01-04T05:10:46.994309Z"
    },
    "papermill": {
     "duration": 0.021277,
     "end_time": "2022-01-04T08:10:49.356993",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.335716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "folds = StratifiedKFold(\n",
    "    n_splits=CFG['fold'],\n",
    "    shuffle=True,\n",
    "    random_state=CFG['seed']\n",
    ").split(np.arange(df_train.shape[0]), df_train.bins.values)\n",
    "    \n",
    "all_histories = {}\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    print(f'Training with fold {fold} started')\n",
    "    print(len(trn_idx), len(val_idx))\n",
    "    \n",
    "    train      = df_train.iloc[trn_idx].reset_index(drop=True)\n",
    "    valid      = df_train.iloc[val_idx].reset_index(drop=True)\n",
    "    train_meta = df_meta.iloc[trn_idx].reset_index(drop=True)\n",
    "    valid_meta = df_meta.iloc[val_idx].reset_index(drop=True)\n",
    "    train_loader, val_loader = prepare_dataloader(train, valid, train_meta, valid_meta)\n",
    "\n",
    "    not_improved_cnt = 0\n",
    "    best_rmse  = 999\n",
    "    best_epoch = 0\n",
    "    histories  = {}\n",
    "    device     = torch.device(CFG['device'])\n",
    "    \n",
    "    model = SwinModelwithMetadataLast(CFG[\"model\"], pretrained=False)\n",
    "    model.to(device)\n",
    "    scaler    = GradScaler()\n",
    "    #optimizer = sgd_optimizer(model, CFG['lr'], CFG['momentum'], CFG['weight_decay'])\n",
    "    #scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=CFG['T_0'])\n",
    "    optimizer = RAdam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "    scheduler = None\n",
    "    if CFG[\"loss\"] == \"binary\":\n",
    "        loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "    else:\n",
    "        loss_fn = RMSELoss().to(device)\n",
    "\n",
    "    for epoch in range(CFG['epochs']):\n",
    "        train_loss, train_best_rmse, train_best_model, train_best_hist = train_one_epoch(\n",
    "            epoch,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            device,\n",
    "            scheduler=scheduler,\n",
    "            best_rmse=best_rmse\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            valid_loss, valid_rmse, valid_hist = valid_one_epoch(\n",
    "                epoch,\n",
    "                model,\n",
    "                loss_fn,\n",
    "                val_loader,\n",
    "                device\n",
    "            )\n",
    "        if valid_rmse < train_best_rmse:\n",
    "            histories[epoch] = [train_loss, valid_loss, valid_rmse, valid_hist]\n",
    "        else:\n",
    "            histories[epoch] = [train_loss, valid_loss, train_best_rmse, train_best_hist]\n",
    "\n",
    "        if valid_rmse < best_rmse or train_best_rmse < best_rmse:\n",
    "            print('Best model will be saved to output path after completing this fold')\n",
    "            if valid_rmse < train_best_rmse:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_rmse  = valid_rmse\n",
    "            else:\n",
    "                best_model = copy.deepcopy(train_best_model)\n",
    "                best_rmse  = train_best_rmse\n",
    "            best_epoch = epoch\n",
    "            not_improved_cnt = 0\n",
    "        elif CFG['early_stopping'] == not_improved_cnt:\n",
    "            print(\"Met early stopping.\")\n",
    "            break\n",
    "        else:\n",
    "            not_improved_cnt += 1\n",
    "\n",
    "    torch.save(best_model.state_dict(), f\"{CFG['output_path']}{CFG['save_name']}_{fold}.pt\")\n",
    "    all_histories[fold] = [best_epoch, histories]\n",
    "    \n",
    "    del model, optimizer, train_loader, val_loader, scaler\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if CFG[\"break_fold\"] == fold+1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dda650",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-04T05:02:02.285363Z",
     "iopub.status.idle": "2022-01-04T05:02:02.285769Z",
     "shell.execute_reply": "2022-01-04T05:02:02.28557Z",
     "shell.execute_reply.started": "2022-01-04T05:02:02.285548Z"
    },
    "papermill": {
     "duration": 0.021294,
     "end_time": "2022-01-04T08:10:49.399504",
     "exception": false,
     "start_time": "2022-01-04T08:10:49.378210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "c, r, cnt = 2, 2, 0\n",
    "fig, axes = plt.subplots(nrows=r, ncols=c, figsize=(14, 10))\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        if cnt not in all_histories.keys():\n",
    "            continue\n",
    "        best_epoch, histories = all_histories[cnt]\n",
    "        rmse, (pred, gt) = histories[best_epoch][2:]\n",
    "        axes[i, j].scatter(x=pred, y=gt)\n",
    "        axes[i, j].set_xticks(np.arange(0,101,10))\n",
    "        axes[i, j].set_yticks(np.arange(0,101,10))\n",
    "        axes[i, j].set_title(f\"fold {cnt}: rmse {round(rmse,5)}\")\n",
    "        cnt += 1\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.401231,
   "end_time": "2022-01-04T08:10:52.315250",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-04T08:09:46.914019",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
