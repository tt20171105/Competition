{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121ff116",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:19.054010Z",
     "iopub.status.busy": "2022-01-13T13:01:19.052500Z",
     "iopub.status.idle": "2022-01-13T13:01:19.061342Z",
     "shell.execute_reply": "2022-01-13T13:01:19.060863Z",
     "shell.execute_reply.started": "2022-01-13T12:39:43.235511Z"
    },
    "papermill": {
     "duration": 0.03701,
     "end_time": "2022-01-13T13:01:19.061479",
     "exception": false,
     "start_time": "2022-01-13T13:01:19.024469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-optimizers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bc3def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:19.111626Z",
     "iopub.status.busy": "2022-01-13T13:01:19.107379Z",
     "iopub.status.idle": "2022-01-13T13:01:28.366183Z",
     "shell.execute_reply": "2022-01-13T13:01:28.366620Z",
     "shell.execute_reply.started": "2022-01-13T12:39:46.104958Z"
    },
    "papermill": {
     "duration": 9.28401,
     "end_time": "2022-01-13T13:01:28.366795",
     "exception": false,
     "start_time": "2022-01-13T13:01:19.082785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from shutil import copyfile\n",
    "from IPython.core.display import Video, display\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import Resize as albResize\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Transpose, RandomResizedCrop, CenterCrop, \n",
    "    Rotate, RandomRotate90, ShiftScaleRotate, Flip, HorizontalFlip, VerticalFlip,\n",
    "    HueSaturationValue, RandomBrightnessContrast, RGBShift, ChannelShuffle,\n",
    "    Normalize, Blur, MotionBlur, Cutout, CoarseDropout)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option(\"max_columns\", 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f99d5c",
   "metadata": {
    "papermill": {
     "duration": 0.02041,
     "end_time": "2022-01-13T13:01:28.408292",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.387882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775cc117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:28.474834Z",
     "iopub.status.busy": "2022-01-13T13:01:28.473786Z",
     "iopub.status.idle": "2022-01-13T13:01:28.479633Z",
     "shell.execute_reply": "2022-01-13T13:01:28.480209Z",
     "shell.execute_reply.started": "2022-01-13T12:51:16.798949Z"
    },
    "papermill": {
     "duration": 0.051293,
     "end_time": "2022-01-13T13:01:28.480368",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.429075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of models is 7 with fold 4 and tta 2.\n",
      "Total of inference will be 56.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'submit': True,\n",
       " 'stacking': False,\n",
       " 'seed': 42,\n",
       " 'device': 'cuda:0',\n",
       " 'input_trimg': '../input/petfinder-pawpularity-score/train/',\n",
       " 'input_trpath': '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
       " 'input_teimg': '../input/petfinder-pawpularity-score/test/',\n",
       " 'input_tepath': '../input/petfinder-pawpularity-score/test.csv',\n",
       " 'output_path': './',\n",
       " 'db_model': 'swin_large_patch4_window7_224_in22k',\n",
       " 'db_size': 224,\n",
       " 'models': [[False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_0.pt'],\n",
       "  [False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_1.pt'],\n",
       "  [False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_2.pt'],\n",
       "  [False,\n",
       "   224,\n",
       "   999,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_3.pt'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_0.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_1.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_2.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_3.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_0.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_1.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_2.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'vit_large_patch16_224',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_3.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_0.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_1.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_2.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'cait_s24_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_3.pth']],\n",
       " 'tta': 2,\n",
       " 'batch_size': 1,\n",
       " 'num_workers': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG = {\n",
    "    \"submit\"      : True,\n",
    "    \"stacking\"    : False,\n",
    "    \"seed\"        : 42,\n",
    "    'device'      : \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"input_trimg\" : '../input/petfinder-pawpularity-score/train/',\n",
    "    \"input_trpath\": '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
    "    \"input_teimg\" : '../input/petfinder-pawpularity-score/test/',\n",
    "    \"input_tepath\": '../input/petfinder-pawpularity-score/test.csv',\n",
    "    \"output_path\" : './',\n",
    "    \"db_model\"    : \"swin_large_patch4_window7_224_in22k\",\n",
    "    \"db_size\"     : 224,\n",
    "    \"models\"      : [[False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_0.pt\"],\n",
    "                     [False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_1.pt\"],\n",
    "                     [False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_2.pt\"],\n",
    "                     [False, 224, 999, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-cnn-models-with-pretrained-edata/petfinder_swin_binary_ss2_meta_3.pt\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_0.pth\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_1.pth\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_2.pth\"],\n",
    "                     [True,  512,   0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_ss_3.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_0.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_1.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_2.pth\"],\n",
    "                     [True,  384,   0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_beit_binary_fastai_ss_3.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_0.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_1.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_2.pth\"],\n",
    "                     [True,  224,   0, 1,                \"vit_large_patch16_224\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_vit_binary_fastai_mixup_3.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_0.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_1.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_2.pth\"],\n",
    "                     [True,  384,   0, 1,                         \"cait_s24_384\", \"../input/petfinder-fastai-models-pseudolabel-4/petfinder_cait_binary_fastai_mixup_3.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_0.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_1.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_2.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-5/petfinder_swin_binary_fastai_highlr_3.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_0.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_1.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_2.pth\"],\n",
    "                     [True,  224,   0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_3.pth\"]],\n",
    "    \"tta\"         : 2,  # If set over 2, tta will run\n",
    "    \"batch_size\"  : 1,\n",
    "    \"num_workers\" : 4\n",
    "}\n",
    "\n",
    "print(f\"# of models is {int(len(CFG['models'])/4)} with fold 4 and tta {CFG['tta']}.\")\n",
    "print(f\"Total of inference will be {len(CFG['models']) * CFG['tta']}.\")\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c2d3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:28.531684Z",
     "iopub.status.busy": "2022-01-13T13:01:28.530896Z",
     "iopub.status.idle": "2022-01-13T13:01:28.532819Z",
     "shell.execute_reply": "2022-01-13T13:01:28.533251Z",
     "shell.execute_reply.started": "2022-01-13T12:39:54.745486Z"
    },
    "papermill": {
     "duration": 0.031119,
     "end_time": "2022-01-13T13:01:28.533365",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.502246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def my_sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "def softmax(x):\n",
    "    max = np.max(x,axis=1,keepdims=True)\n",
    "    e_x = np.exp(x - max)\n",
    "    sum = np.sum(e_x,axis=1,keepdims=True)\n",
    "    return e_x / sum \n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7310082",
   "metadata": {
    "papermill": {
     "duration": 0.021258,
     "end_time": "2022-01-13T13:01:28.576081",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.554823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f68a839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:28.625792Z",
     "iopub.status.busy": "2022-01-13T13:01:28.625204Z",
     "iopub.status.idle": "2022-01-13T13:01:28.691273Z",
     "shell.execute_reply": "2022-01-13T13:01:28.691825Z",
     "shell.execute_reply.started": "2022-01-13T12:51:24.068399Z"
    },
    "papermill": {
     "duration": 0.094044,
     "end_time": "2022-01-13T13:01:28.692000",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.597956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
      "(8, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          1      1        0      0          1     0     1   \n",
       "1          0      1        1      0          0     0     0   \n",
       "\n",
       "                                                                             path  \n",
       "0  ../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg  \n",
       "1  ../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(CFG['input_trpath'])\n",
    "df_train[\"path\"] = [f\"{CFG['input_trimg']}{i}.jpg\" for i in df_train.Id]\n",
    "df_train[\"Pawclass\"] = df_train.Pawpularity / 100\n",
    "\n",
    "if CFG[\"submit\"]:\n",
    "    df_test = pd.read_csv(CFG['input_tepath'])\n",
    "    df_test[\"path\"] = [f\"{CFG['input_teimg']}{i}.jpg\" for i in df_test.Id]\n",
    "else:\n",
    "    df_test = pd.read_csv(CFG['input_trpath'])\n",
    "    df_test[\"path\"] = [f\"{CFG['input_trimg']}{i}.jpg\" for i in df_test.Id]\n",
    "\n",
    "meta_features = [c for c in df_test.columns if c not in [\"Id\",\"path\", \"Pawpularity\"]]\n",
    "\n",
    "print(meta_features)\n",
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9d6933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:28.745864Z",
     "iopub.status.busy": "2022-01-13T13:01:28.745284Z",
     "iopub.status.idle": "2022-01-13T13:01:28.786111Z",
     "shell.execute_reply": "2022-01-13T13:01:28.785580Z",
     "shell.execute_reply.started": "2022-01-13T12:51:25.193956Z"
    },
    "papermill": {
     "duration": 0.071072,
     "end_time": "2022-01-13T13:01:28.786222",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.715150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject Focus     Eyes      Face     Near    Action  Accessory  \\\n",
       "count       8.000000  8.00000  8.000000  8.00000  8.000000   8.000000   \n",
       "mean        0.625000  0.25000  0.625000  0.25000  0.375000   0.625000   \n",
       "std         0.517549  0.46291  0.517549  0.46291  0.517549   0.517549   \n",
       "min         0.000000  0.00000  0.000000  0.00000  0.000000   0.000000   \n",
       "25%         0.000000  0.00000  0.000000  0.00000  0.000000   0.000000   \n",
       "50%         1.000000  0.00000  1.000000  0.00000  0.000000   1.000000   \n",
       "75%         1.000000  0.25000  1.000000  0.25000  1.000000   1.000000   \n",
       "max         1.000000  1.00000  1.000000  1.00000  1.000000   1.000000   \n",
       "\n",
       "          Group   Collage    Human  Occlusion      Info      Blur  \n",
       "count  8.000000  8.000000  8.00000   8.000000  8.000000  8.000000  \n",
       "mean   0.500000  0.625000  0.25000   0.500000  0.625000  0.500000  \n",
       "std    0.534522  0.517549  0.46291   0.534522  0.517549  0.534522  \n",
       "min    0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  \n",
       "25%    0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  \n",
       "50%    0.500000  1.000000  0.00000   0.500000  1.000000  0.500000  \n",
       "75%    1.000000  1.000000  0.25000   1.000000  1.000000  1.000000  \n",
       "max    1.000000  1.000000  1.00000   1.000000  1.000000  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b025db",
   "metadata": {
    "papermill": {
     "duration": 0.02363,
     "end_time": "2022-01-13T13:01:28.835161",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.811531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog and cat labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be44bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:28.887923Z",
     "iopub.status.busy": "2022-01-13T13:01:28.887153Z",
     "iopub.status.idle": "2022-01-13T13:01:28.889110Z",
     "shell.execute_reply": "2022-01-13T13:01:28.889521Z",
     "shell.execute_reply.started": "2022-01-13T12:51:26.014801Z"
    },
    "papermill": {
     "duration": 0.030661,
     "end_time": "2022-01-13T13:01:28.889662",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.859001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    try:\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None\n",
    "    model = models.densenet121(pretrained=False)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 2)\n",
    "    )\n",
    "    model.parameters = checkpoint['parameters']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c702fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:28.937742Z",
     "iopub.status.busy": "2022-01-13T13:01:28.936950Z",
     "iopub.status.idle": "2022-01-13T13:01:28.944154Z",
     "shell.execute_reply": "2022-01-13T13:01:28.943723Z",
     "shell.execute_reply.started": "2022-01-13T12:51:26.627004Z"
    },
    "papermill": {
     "duration": 0.03207,
     "end_time": "2022-01-13T13:01:28.944252",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.912182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_transform(imagepath):\n",
    "    test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(imagepath)\n",
    "    imagetensor = test_transforms(image)\n",
    "    return imagetensor\n",
    "\n",
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img = image_transform(self.df.loc[index].path)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "962d22d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:28.995439Z",
     "iopub.status.busy": "2022-01-13T13:01:28.994592Z",
     "iopub.status.idle": "2022-01-13T13:01:28.996538Z",
     "shell.execute_reply": "2022-01-13T13:01:28.996980Z",
     "shell.execute_reply.started": "2022-01-13T12:51:27.458561Z"
    },
    "papermill": {
     "duration": 0.030338,
     "end_time": "2022-01-13T13:01:28.997096",
     "exception": false,
     "start_time": "2022-01-13T13:01:28.966758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    img_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        img_preds = model(imgs)\n",
    "        img_preds_all += [img_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    img_preds_all = np.concatenate(img_preds_all, axis=0)\n",
    "    return img_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d8baa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:29.047748Z",
     "iopub.status.busy": "2022-01-13T13:01:29.047225Z",
     "iopub.status.idle": "2022-01-13T13:01:40.864419Z",
     "shell.execute_reply": "2022-01-13T13:01:40.863652Z",
     "shell.execute_reply.started": "2022-01-13T12:51:28.266070Z"
    },
    "papermill": {
     "duration": 11.844977,
     "end_time": "2022-01-13T13:01:40.864598",
     "exception": false,
     "start_time": "2022-01-13T13:01:29.019621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "inference_ds = PetFinderDataset(df_test)\n",
    "data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                           batch_size=CFG['batch_size'],\n",
    "                                           drop_last=False,\n",
    "                                           pin_memory=False,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=CFG['num_workers'])\n",
    "model = load_model(\"../input/cat-vs-dog-model/cat-v-dog-classifier-pytorch-master/models/catvdog.pth\")\n",
    "model.to(CFG[\"device\"])\n",
    "with torch.no_grad():\n",
    "    res_cat_dog = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "del model, inference_ds, data_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e275147d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:40.945954Z",
     "iopub.status.busy": "2022-01-13T13:01:40.945224Z",
     "iopub.status.idle": "2022-01-13T13:01:40.950323Z",
     "shell.execute_reply": "2022-01-13T13:01:40.950892Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.732794Z"
    },
    "papermill": {
     "duration": 0.045772,
     "end_time": "2022-01-13T13:01:40.951070",
     "exception": false,
     "start_time": "2022-01-13T13:01:40.905298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>path</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>0.478612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg</td>\n",
       "      <td>0.576748</td>\n",
       "      <td>0.423252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          1      1        0      0          1     0     1   \n",
       "1          0      1        1      0          0     0     0   \n",
       "\n",
       "                                                                             path  \\\n",
       "0  ../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg   \n",
       "1  ../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg   \n",
       "\n",
       "        cat       dog  \n",
       "0  0.521388  0.478612  \n",
       "1  0.576748  0.423252  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[[\"cat\",\"dog\"]] = softmax(res_cat_dog)\n",
    "meta_features += [\"cat\",\"dog\"]\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00219f",
   "metadata": {
    "papermill": {
     "duration": 0.024566,
     "end_time": "2022-01-13T13:01:41.001052",
     "exception": false,
     "start_time": "2022-01-13T13:01:40.976486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog breed for dog label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee073c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:41.056406Z",
     "iopub.status.busy": "2022-01-13T13:01:41.055590Z",
     "iopub.status.idle": "2022-01-13T13:01:41.058123Z",
     "shell.execute_reply": "2022-01-13T13:01:41.057708Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.755896Z"
    },
    "papermill": {
     "duration": 0.032251,
     "end_time": "2022-01-13T13:01:41.058228",
     "exception": false,
     "start_time": "2022-01-13T13:01:41.025977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 120)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ee0938b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:41.115922Z",
     "iopub.status.busy": "2022-01-13T13:01:41.114380Z",
     "iopub.status.idle": "2022-01-13T13:01:41.116538Z",
     "shell.execute_reply": "2022-01-13T13:01:41.116984Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.765738Z"
    },
    "papermill": {
     "duration": 0.034306,
     "end_time": "2022-01-13T13:01:41.117102",
     "exception": false,
     "start_time": "2022-01-13T13:01:41.082796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms  = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img  = get_img(self.df.loc[index].path).copy()\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        return img\n",
    "    \n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "        albResize(CFG[\"db_size\"], CFG[\"db_size\"], p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "985fda7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:41.171808Z",
     "iopub.status.busy": "2022-01-13T13:01:41.171195Z",
     "iopub.status.idle": "2022-01-13T13:01:41.174623Z",
     "shell.execute_reply": "2022-01-13T13:01:41.174170Z",
     "shell.execute_reply.started": "2022-01-13T12:57:04.779022Z"
    },
    "papermill": {
     "duration": 0.033021,
     "end_time": "2022-01-13T13:01:41.174737",
     "exception": false,
     "start_time": "2022-01-13T13:01:41.141716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [image_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18b3a799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:41.231560Z",
     "iopub.status.busy": "2022-01-13T13:01:41.230658Z",
     "iopub.status.idle": "2022-01-13T13:01:53.785470Z",
     "shell.execute_reply": "2022-01-13T13:01:53.786130Z",
     "shell.execute_reply.started": "2022-01-13T12:57:27.081687Z"
    },
    "papermill": {
     "duration": 12.58691,
     "end_time": "2022-01-13T13:01:53.786334",
     "exception": false,
     "start_time": "2022-01-13T13:01:41.199424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog num: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  8.83it/s]\n"
     ]
    }
   ],
   "source": [
    "dog_ids = list(df_test[df_test.dog > 0.5].Id)\n",
    "print(f\"Dog num: {len(dog_ids)}\")\n",
    "inference_ds = PetFinderDataset(df_test[df_test.Id.isin(dog_ids)].reset_index(drop=True),\n",
    "                                        transforms=get_inference_transforms())\n",
    "data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                           batch_size=CFG['batch_size'],\n",
    "                                           drop_last=False,\n",
    "                                           pin_memory=False,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=CFG['num_workers'])\n",
    "model = SwinModel(CFG['db_model'], pretrained=False)\n",
    "model.load_state_dict(torch.load(\"../input/petfinder-dogbreed-cnn-models/dogbreed_swin_ce.pt\"))\n",
    "model.to(CFG[\"device\"])\n",
    "with torch.no_grad():\n",
    "    res_dogbreed = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "del model, inference_ds, data_loader\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a3c7ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:53.855074Z",
     "iopub.status.busy": "2022-01-13T13:01:53.854172Z",
     "iopub.status.idle": "2022-01-13T13:01:54.039385Z",
     "shell.execute_reply": "2022-01-13T13:01:54.039772Z",
     "shell.execute_reply.started": "2022-01-13T12:59:55.764668Z"
    },
    "papermill": {
     "duration": 0.224304,
     "end_time": "2022-01-13T13:01:54.039920",
     "exception": false,
     "start_time": "2022-01-13T13:01:53.815616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 134)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>db0</th>\n",
       "      <th>db1</th>\n",
       "      <th>db2</th>\n",
       "      <th>db3</th>\n",
       "      <th>db4</th>\n",
       "      <th>db5</th>\n",
       "      <th>db6</th>\n",
       "      <th>db7</th>\n",
       "      <th>db8</th>\n",
       "      <th>db9</th>\n",
       "      <th>db10</th>\n",
       "      <th>db11</th>\n",
       "      <th>db12</th>\n",
       "      <th>db13</th>\n",
       "      <th>db14</th>\n",
       "      <th>db15</th>\n",
       "      <th>db16</th>\n",
       "      <th>db17</th>\n",
       "      <th>db18</th>\n",
       "      <th>db19</th>\n",
       "      <th>db20</th>\n",
       "      <th>db21</th>\n",
       "      <th>db22</th>\n",
       "      <th>db23</th>\n",
       "      <th>db24</th>\n",
       "      <th>db25</th>\n",
       "      <th>db26</th>\n",
       "      <th>db27</th>\n",
       "      <th>db28</th>\n",
       "      <th>db29</th>\n",
       "      <th>db30</th>\n",
       "      <th>db31</th>\n",
       "      <th>db32</th>\n",
       "      <th>db33</th>\n",
       "      <th>db34</th>\n",
       "      <th>db35</th>\n",
       "      <th>db36</th>\n",
       "      <th>db37</th>\n",
       "      <th>db38</th>\n",
       "      <th>db39</th>\n",
       "      <th>db40</th>\n",
       "      <th>db41</th>\n",
       "      <th>db42</th>\n",
       "      <th>db43</th>\n",
       "      <th>db44</th>\n",
       "      <th>db45</th>\n",
       "      <th>db46</th>\n",
       "      <th>db47</th>\n",
       "      <th>db48</th>\n",
       "      <th>db49</th>\n",
       "      <th>db50</th>\n",
       "      <th>db51</th>\n",
       "      <th>db52</th>\n",
       "      <th>db53</th>\n",
       "      <th>db54</th>\n",
       "      <th>db55</th>\n",
       "      <th>db56</th>\n",
       "      <th>db57</th>\n",
       "      <th>db58</th>\n",
       "      <th>db59</th>\n",
       "      <th>db60</th>\n",
       "      <th>db61</th>\n",
       "      <th>db62</th>\n",
       "      <th>db63</th>\n",
       "      <th>db64</th>\n",
       "      <th>db65</th>\n",
       "      <th>db66</th>\n",
       "      <th>db67</th>\n",
       "      <th>db68</th>\n",
       "      <th>db69</th>\n",
       "      <th>db70</th>\n",
       "      <th>db71</th>\n",
       "      <th>db72</th>\n",
       "      <th>db73</th>\n",
       "      <th>db74</th>\n",
       "      <th>db75</th>\n",
       "      <th>db76</th>\n",
       "      <th>db77</th>\n",
       "      <th>db78</th>\n",
       "      <th>db79</th>\n",
       "      <th>db80</th>\n",
       "      <th>db81</th>\n",
       "      <th>db82</th>\n",
       "      <th>db83</th>\n",
       "      <th>db84</th>\n",
       "      <th>db85</th>\n",
       "      <th>db86</th>\n",
       "      <th>db87</th>\n",
       "      <th>db88</th>\n",
       "      <th>db89</th>\n",
       "      <th>db90</th>\n",
       "      <th>db91</th>\n",
       "      <th>db92</th>\n",
       "      <th>db93</th>\n",
       "      <th>db94</th>\n",
       "      <th>db95</th>\n",
       "      <th>db96</th>\n",
       "      <th>db97</th>\n",
       "      <th>db98</th>\n",
       "      <th>db99</th>\n",
       "      <th>db100</th>\n",
       "      <th>db101</th>\n",
       "      <th>db102</th>\n",
       "      <th>db103</th>\n",
       "      <th>db104</th>\n",
       "      <th>db105</th>\n",
       "      <th>db106</th>\n",
       "      <th>db107</th>\n",
       "      <th>db108</th>\n",
       "      <th>db109</th>\n",
       "      <th>db110</th>\n",
       "      <th>db111</th>\n",
       "      <th>db112</th>\n",
       "      <th>db113</th>\n",
       "      <th>db114</th>\n",
       "      <th>db115</th>\n",
       "      <th>db116</th>\n",
       "      <th>db117</th>\n",
       "      <th>db118</th>\n",
       "      <th>db119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521388</td>\n",
       "      <td>0.478612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576748</td>\n",
       "      <td>0.423252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject Focus  Eyes  Face  Near  Action  Accessory  Group  Collage  Human  \\\n",
       "0              1     0     1     0       0          1      1        0      0   \n",
       "1              0     1     0     0       0          0      1        1      0   \n",
       "\n",
       "   Occlusion  Info  Blur       cat       dog  db0  db1  db2  db3  db4  db5  \\\n",
       "0          1     0     1  0.521388  0.478612  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1          0     0     0  0.576748  0.423252  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   db6  db7  db8  db9  db10  db11  db12  db13  db14  db15  db16  db17  db18  \\\n",
       "0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db19  db20  db21  db22  db23  db24  db25  db26  db27  db28  db29  db30  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db31  db32  db33  db34  db35  db36  db37  db38  db39  db40  db41  db42  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db43  db44  db45  db46  db47  db48  db49  db50  db51  db52  db53  db54  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db55  db56  db57  db58  db59  db60  db61  db62  db63  db64  db65  db66  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db67  db68  db69  db70  db71  db72  db73  db74  db75  db76  db77  db78  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db79  db80  db81  db82  db83  db84  db85  db86  db87  db88  db89  db90  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   db91  db92  db93  db94  db95  db96  db97  db98  db99  db100  db101  db102  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0   \n",
       "\n",
       "   db103  db104  db105  db106  db107  db108  db109  db110  db111  db112  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   db113  db114  db115  db116  db117  db118  db119  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogbreed_cols = [f\"db{i}\" for i in range(res_dogbreed.shape[1])]\n",
    "\n",
    "df_meta = df_test[meta_features].copy()\n",
    "df_meta[dogbreed_cols] = 0\n",
    "df_meta.loc[df_meta.dog > 0.5, dogbreed_cols] = softmax(res_dogbreed)\n",
    "\n",
    "print(df_meta.shape)\n",
    "df_meta.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d3663e",
   "metadata": {
    "papermill": {
     "duration": 0.026657,
     "end_time": "2022-01-13T13:01:54.093864",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.067207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fa49ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:54.165309Z",
     "iopub.status.busy": "2022-01-13T13:01:54.154681Z",
     "iopub.status.idle": "2022-01-13T13:01:54.167250Z",
     "shell.execute_reply": "2022-01-13T13:01:54.167659Z",
     "shell.execute_reply.started": "2022-01-13T13:00:17.882737Z"
    },
    "papermill": {
     "duration": 0.04717,
     "end_time": "2022-01-13T13:01:54.167794",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.120624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "class ModelwithMetadata(nn.Module):\n",
    "    def __init__(self, model_name, size=512, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=4)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        # Exclude the top layer\n",
    "        self.model.reset_classifier(0)\n",
    "        self.linear1 = nn.Linear(134, size*size)        \n",
    "        self.linear2 = nn.Linear(134, self.n_features)\n",
    "        self.linear3 = nn.Linear(self.n_features, 256)\n",
    "        self.linear4 = nn.Linear(256, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Metadata first\n",
    "        x = self.linear1(x2)\n",
    "        x = torch.reshape(x, (x2.shape[0], 1, self.size, self.size))\n",
    "        x = torch.cat((x1, x), dim=1)\n",
    "        x = self.model(x)\n",
    "        # Metadata Last\n",
    "        x2 = self.linear2(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear3(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear4(x)\n",
    "        return output\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "    \n",
    "class TransformerModelwithMetadataLast(nn.Module):\n",
    "    def __init__(self, model_name, size=224, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.backbone = TransformerModel(model_name, False)\n",
    "        num_features  = self.backbone.model.num_features\n",
    "        self.backbone.linear = nn.Linear(num_features, 256)\n",
    "        self.linear1 = nn.Linear(134, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x  = self.backbone(x1)\n",
    "        # Metadata Last\n",
    "        x2 = self.linear1(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear2(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e9b8a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:54.230538Z",
     "iopub.status.busy": "2022-01-13T13:01:54.228977Z",
     "iopub.status.idle": "2022-01-13T13:01:54.231160Z",
     "shell.execute_reply": "2022-01-13T13:01:54.231566Z",
     "shell.execute_reply.started": "2022-01-13T13:00:18.195705Z"
    },
    "papermill": {
     "duration": 0.036895,
     "end_time": "2022-01-13T13:01:54.231709",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.194814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df_img, df_meta, size, transforms=None, output_meta=True):\n",
    "        super().__init__()\n",
    "        self.df_img  = df_img.reset_index(drop=True).copy()\n",
    "        self.df_meta = df_meta.reset_index(drop=True).copy()\n",
    "        self.size    = size\n",
    "        self.transforms  = transforms\n",
    "        self.output_meta = output_meta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df_img.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img  = get_img(self.df_img.loc[index].path)\n",
    "        meta = torch.from_numpy(np.array(self.df_meta.loc[index], dtype=float))\n",
    "        if self.transforms:\n",
    "            h, w, _ = img.shape\n",
    "            trans = self.transforms(self.size, h, w)\n",
    "            img   = trans(image=img)['image']\n",
    "        if self.output_meta:\n",
    "            return img, meta\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fed9746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:54.298621Z",
     "iopub.status.busy": "2022-01-13T13:01:54.297062Z",
     "iopub.status.idle": "2022-01-13T13:01:54.299212Z",
     "shell.execute_reply": "2022-01-13T13:01:54.299640Z",
     "shell.execute_reply.started": "2022-01-13T13:00:18.600231Z"
    },
    "papermill": {
     "duration": 0.041263,
     "end_time": "2022-01-13T13:01:54.299762",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.258499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tta_inference_transforms_1(size, h, w):\n",
    "    return Compose([\n",
    "        RandomResizedCrop(size, size, scale=(0.7, 1.0), p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        MotionBlur(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_tta_inference_transforms_2(size, h, w):\n",
    "    return Compose([\n",
    "        albResize(size, size, p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_inference_transforms_1(size, h, w):\n",
    "    h = int(size*1.2) if int(size*1.2) < h else h\n",
    "    w = int(size*1.2) if int(size*1.2) < w else w\n",
    "    return Compose([\n",
    "        CenterCrop(h, w, p=1.0),\n",
    "        albResize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_inference_transforms_2(size, h, w):\n",
    "    return Compose([\n",
    "        albResize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4803393f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:54.360081Z",
     "iopub.status.busy": "2022-01-13T13:01:54.359299Z",
     "iopub.status.idle": "2022-01-13T13:01:54.361272Z",
     "shell.execute_reply": "2022-01-13T13:01:54.361678Z",
     "shell.execute_reply.started": "2022-01-13T13:00:18.721408Z"
    },
    "papermill": {
     "duration": 0.035334,
     "end_time": "2022-01-13T13:01:54.361802",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.326468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, use_meta, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    img_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs, metas) in pbar:\n",
    "        imgs  = imgs.to(device).float()\n",
    "        if use_meta != 0:\n",
    "            metas = metas[:,:use_meta].to(device).float()\n",
    "            img_preds = model(imgs, metas)\n",
    "        else:\n",
    "            img_preds = model(imgs)\n",
    "        img_preds_all += [img_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    img_preds_all = np.concatenate(img_preds_all, axis=0)\n",
    "    return img_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c04eb584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:54.422996Z",
     "iopub.status.busy": "2022-01-13T13:01:54.421552Z",
     "iopub.status.idle": "2022-01-13T13:01:54.423682Z",
     "shell.execute_reply": "2022-01-13T13:01:54.424096Z",
     "shell.execute_reply.started": "2022-01-13T13:00:19.116757Z"
    },
    "papermill": {
     "duration": 0.035244,
     "end_time": "2022-01-13T13:01:54.424208",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.388964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, size):\n",
    "    df = df.copy()\n",
    "    label_col  = \"Pawclass\"\n",
    "    dataloader = ImageDataLoaders.from_df(\n",
    "        df,\n",
    "        valid_pct=0.2,  # Dummy\n",
    "        seed=CFG[\"seed\"],\n",
    "        fn_col='path',\n",
    "        label_col=label_col,\n",
    "        y_block=RegressionBlock,\n",
    "        bs=CFG['batch_size'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        item_tfms=Resize(size),\n",
    "        batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def petfinder_rmse(input,target):\n",
    "    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a6e4606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:54.484598Z",
     "iopub.status.busy": "2022-01-13T13:01:54.483793Z",
     "iopub.status.idle": "2022-01-13T13:01:54.486177Z",
     "shell.execute_reply": "2022-01-13T13:01:54.485747Z",
     "shell.execute_reply.started": "2022-01-13T13:00:19.525044Z"
    },
    "papermill": {
     "duration": 0.035241,
     "end_time": "2022-01-13T13:01:54.486275",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.451034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_learner(df, size, model, model_path):\n",
    "    dataloader = prepare_dataloader(df, size)\n",
    "    if -1 < max(model.find(\"swin\"), model.find(\"beit\"), model.find(\"vit\"), model.find(\"cait\")):\n",
    "        model = TransformerModel(model, pretrained=False)\n",
    "    else:\n",
    "        model = Model(model, pretrained=False)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    learner = Learner(\n",
    "        dataloader,\n",
    "        model,\n",
    "        loss_func=BCEWithLogitsLossFlat(),\n",
    "        metrics=petfinder_rmse).to_fp16()\n",
    "    return learner, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6442da9",
   "metadata": {
    "papermill": {
     "duration": 0.02715,
     "end_time": "2022-01-13T13:01:54.540119",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.512969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "868ef784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:01:54.610011Z",
     "iopub.status.busy": "2022-01-13T13:01:54.608081Z",
     "iopub.status.idle": "2022-01-13T13:07:09.399381Z",
     "shell.execute_reply": "2022-01-13T13:07:09.399825Z",
     "shell.execute_reply.started": "2022-01-13T13:00:21.364149Z"
    },
    "papermill": {
     "duration": 314.832903,
     "end_time": "2022-01-13T13:07:09.399999",
     "exception": false,
     "start_time": "2022-01-13T13:01:54.567096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 22.76it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 23.69it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 24.28it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 24.27it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 22.12it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 24.25it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 24.61it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 24.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_res = []\n",
    "for fastai, size, use_meta, dataset_type, model, model_path in CFG['models']:\n",
    "    \n",
    "    if fastai:\n",
    "        learn, data_loader = get_learner(df_train, size, model, model_path)\n",
    "        data_loader = data_loader.test_dl(df_test)\n",
    "        res, _ = learn.tta(dl=data_loader, n=CFG[\"tta\"], beta=0)\n",
    "        res    = res.detach().numpy()\n",
    "        if -1 < model_path.find(\"binary\"):\n",
    "            res = res*100\n",
    "        all_res.append(res)\n",
    "        \n",
    "        del learn, data_loader\n",
    "    else:\n",
    "        if 1 < CFG[\"tta\"]:\n",
    "            if dataset_type == 1:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_tta_inference_transforms_1)\n",
    "            else:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_tta_inference_transforms_2)\n",
    "        else:\n",
    "            if dataset_type == 1:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_inference_transforms_1)\n",
    "            else:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_inference_transforms_2)\n",
    "        data_loader = torch.utils.data.DataLoader(inference_ds,\n",
    "                                                  batch_size=CFG['batch_size'],\n",
    "                                                  drop_last=False,\n",
    "                                                  pin_memory=False,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=CFG['num_workers'])\n",
    "        if -1 < model_path.find(\"swin\"):\n",
    "            if use_meta == 0:\n",
    "                model = TransformerModel(model, pretrained=False)\n",
    "            else:\n",
    "                model = TransformerModelwithMetadataLast(model, size, pretrained=False)\n",
    "        else:\n",
    "            if use_meta == 0:\n",
    "                model = Model(model, pretrained=False)\n",
    "            else:\n",
    "                model = ModelwithMetadata(model, size, pretrained=False)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(CFG[\"device\"])\n",
    "\n",
    "        tta_res = []\n",
    "        for i in range(CFG[\"tta\"]):\n",
    "            with torch.no_grad():\n",
    "                res = inference_one_epoch(model, use_meta, data_loader, CFG[\"device\"])\n",
    "                if -1 < model_path.find(\"binary\"):\n",
    "                    res = my_sigmoid(res)*100\n",
    "                tta_res.append(res)\n",
    "        all_res.append(np.mean(tta_res, 0))\n",
    "\n",
    "        del model, inference_ds, data_loader\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eed652b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:07:09.522254Z",
     "iopub.status.busy": "2022-01-13T13:07:09.520632Z",
     "iopub.status.idle": "2022-01-13T13:07:09.524538Z",
     "shell.execute_reply": "2022-01-13T13:07:09.524099Z",
     "shell.execute_reply.started": "2022-01-04T02:38:13.021065Z"
    },
    "papermill": {
     "duration": 0.06727,
     "end_time": "2022-01-13T13:07:09.524681",
     "exception": false,
     "start_time": "2022-01-13T13:07:09.457411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(np.array(all_res).reshape(len(CFG[\"models\"]),-1)).T\n",
    "if not CFG[\"submit\"]:\n",
    "    df_pred[\"target\"] = df_test.Pawpularity\n",
    "    df_pred.to_csv(\"./inference_result_train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf44226e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:07:09.651739Z",
     "iopub.status.busy": "2022-01-13T13:07:09.650066Z",
     "iopub.status.idle": "2022-01-13T13:07:09.654044Z",
     "shell.execute_reply": "2022-01-13T13:07:09.653400Z",
     "shell.execute_reply.started": "2022-01-04T02:38:13.040017Z"
    },
    "papermill": {
     "duration": 0.071403,
     "end_time": "2022-01-13T13:07:09.654199",
     "exception": false,
     "start_time": "2022-01-13T13:07:09.582796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    42.951481\n",
      "1    43.533123\n",
      "2    43.402565\n",
      "3    43.323055\n",
      "4    43.445732\n",
      "5    43.033955\n",
      "6    42.682770\n",
      "7    43.069897\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "if CFG[\"stacking\"]:\n",
    "    loaded_model = pickle.load(open(\"../input/petfinder-stacking-model/stacking_model.pickle\", 'rb'))\n",
    "    # Calculate mean every model type\n",
    "    sta = 0\n",
    "    mean_every_model = []\n",
    "    for i in range(4, len(CFG[\"models\"])+1, 4):  # 4 is fold num\n",
    "        mean_every_model.append(df_pred.iloc[:, sta:i].mean(1))\n",
    "        sta = i\n",
    "    df_mean_every_model = pd.concat(mean_every_model, axis=1)\n",
    "    # Predict with stacking model\n",
    "    ensembled = loaded_model.predict(df_mean_every_model)\n",
    "else:\n",
    "    ensembled = df_pred.mean(1)\n",
    "print(ensembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e5a4111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-13T13:07:09.782161Z",
     "iopub.status.busy": "2022-01-13T13:07:09.781575Z",
     "iopub.status.idle": "2022-01-13T13:07:09.800575Z",
     "shell.execute_reply": "2022-01-13T13:07:09.801080Z",
     "shell.execute_reply.started": "2022-01-04T02:38:13.056344Z"
    },
    "papermill": {
     "duration": 0.086531,
     "end_time": "2022-01-13T13:07:09.801223",
     "exception": false,
     "start_time": "2022-01-13T13:07:09.714692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG[\"submit\"]:\n",
    "    ss = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n",
    "    ss[\"Pawpularity\"] = ensembled\n",
    "    ss.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 361.525364,
   "end_time": "2022-01-13T13:07:12.749377",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-13T13:01:11.224013",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
