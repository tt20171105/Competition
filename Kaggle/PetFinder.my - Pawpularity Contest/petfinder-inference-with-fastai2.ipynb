{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b403e6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:10.575188Z",
     "iopub.status.busy": "2022-01-03T14:42:10.573681Z",
     "iopub.status.idle": "2022-01-03T14:42:10.582972Z",
     "shell.execute_reply": "2022-01-03T14:42:10.582414Z",
     "shell.execute_reply.started": "2022-01-03T14:39:08.646437Z"
    },
    "papermill": {
     "duration": 0.036956,
     "end_time": "2022-01-03T14:42:10.583114",
     "exception": false,
     "start_time": "2022-01-03T14:42:10.546158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-optimizers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1150a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:10.638621Z",
     "iopub.status.busy": "2022-01-03T14:42:10.637975Z",
     "iopub.status.idle": "2022-01-03T14:42:20.144144Z",
     "shell.execute_reply": "2022-01-03T14:42:20.143145Z",
     "shell.execute_reply.started": "2022-01-03T14:39:11.899766Z"
    },
    "papermill": {
     "duration": 9.54012,
     "end_time": "2022-01-03T14:42:20.144288",
     "exception": false,
     "start_time": "2022-01-03T14:42:10.604168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from shutil import copyfile\n",
    "from IPython.core.display import Video, display\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import Resize as albResize\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Transpose, RandomResizedCrop, CenterCrop, \n",
    "    Rotate, RandomRotate90, ShiftScaleRotate, Flip, HorizontalFlip, VerticalFlip,\n",
    "    HueSaturationValue, RandomBrightnessContrast, RGBShift, ChannelShuffle,\n",
    "    Normalize, Blur, MotionBlur, Cutout, CoarseDropout)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option(\"max_columns\", 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33b4db",
   "metadata": {
    "papermill": {
     "duration": 0.020013,
     "end_time": "2022-01-03T14:42:20.184659",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.164646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b4660f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.248080Z",
     "iopub.status.busy": "2022-01-03T14:42:20.247287Z",
     "iopub.status.idle": "2022-01-03T14:42:20.250867Z",
     "shell.execute_reply": "2022-01-03T14:42:20.251266Z",
     "shell.execute_reply.started": "2022-01-03T14:39:20.775078Z"
    },
    "papermill": {
     "duration": 0.046591,
     "end_time": "2022-01-03T14:42:20.251407",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.204816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'submit': True,\n",
       " 'stacking': False,\n",
       " 'seed': 42,\n",
       " 'device': 'cuda:0',\n",
       " 'input_trimg': '../input/petfinder-pawpularity-score/train/',\n",
       " 'input_trpath': '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
       " 'input_teimg': '../input/petfinder-pawpularity-score/test/',\n",
       " 'input_tepath': '../input/petfinder-pawpularity-score/test.csv',\n",
       " 'output_path': './',\n",
       " 'db_model': 'swin_large_patch4_window7_224_in22k',\n",
       " 'db_size': 224,\n",
       " 'models': [[True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_0.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_1.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_2.pth'],\n",
       "  [True,\n",
       "   512,\n",
       "   0,\n",
       "   1,\n",
       "   'tf_efficientnet_b5_ns',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_3.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_0.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_1.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_2.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'beit_base_patch16_384',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_3.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_0.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_1.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_2.pth'],\n",
       "  [True,\n",
       "   384,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window12_384_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_3.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_0.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_1.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_2.pth'],\n",
       "  [True,\n",
       "   224,\n",
       "   0,\n",
       "   1,\n",
       "   'swin_large_patch4_window7_224_in22k',\n",
       "   '../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_3.pth']],\n",
       " 'tta': 3,\n",
       " 'batch_size': 1,\n",
       " 'num_workers': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG = {\n",
    "    \"submit\"      : True,\n",
    "    \"stacking\"    : False,\n",
    "    \"seed\"        : 42,\n",
    "    'device'      : \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"input_trimg\" : '../input/petfinder-pawpularity-score/train/',\n",
    "    \"input_trpath\": '../input/petfinder-smogn-dataset/train_drop_duplicated.csv',\n",
    "    \"input_teimg\" : '../input/petfinder-pawpularity-score/test/',\n",
    "    \"input_tepath\": '../input/petfinder-pawpularity-score/test.csv',\n",
    "    \"output_path\" : './',\n",
    "    \"db_model\"    : \"swin_large_patch4_window7_224_in22k\",\n",
    "    \"db_size\"     : 224,\n",
    "    \"models\"      : [[True, 512, 0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_0.pth\"],\n",
    "                     [True, 512, 0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_1.pth\"],\n",
    "                     [True, 512, 0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_2.pth\"],\n",
    "                     [True, 512, 0, 1,                \"tf_efficientnet_b5_ns\", \"../input/petfinder-fastai-models-pseudolabel-1/petfinder_effnet_binary_fastai_3.pth\"],\n",
    "                     [True, 384, 0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_0.pth\"],\n",
    "                     [True, 384, 0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_1.pth\"],\n",
    "                     [True, 384, 0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_2.pth\"],\n",
    "                     [True, 384, 0, 1,                \"beit_base_patch16_384\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_beit_binary_fastai_3.pth\"],\n",
    "                     [True, 384, 0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_0.pth\"],\n",
    "                     [True, 384, 0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_1.pth\"],\n",
    "                     [True, 384, 0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_2.pth\"],\n",
    "                     [True, 384, 0, 1, \"swin_large_patch4_window12_384_in22k\", \"../input/petfinder-fastai-models-pseudolabel-3/petfinder_swin384_binary_fastai_3.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_0.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_1.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_2.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_3.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_0.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_1.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_2.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_ss_smogn_3.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_0.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_1.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_2.pth\"],\n",
    "                     [True, 224, 0, 1,  \"swin_large_patch4_window7_224_in22k\", \"../input/petfinder-fastai-models-pseudolabel-2/petfinder_swin_binary_fastai_3.pth\"]],\n",
    "    \"tta\"         : 3,  # If set over 2, tta will run\n",
    "    \"batch_size\"  : 1,\n",
    "    \"num_workers\" : 4\n",
    "}\n",
    "\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011b8590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.302112Z",
     "iopub.status.busy": "2022-01-03T14:42:20.299540Z",
     "iopub.status.idle": "2022-01-03T14:42:20.304444Z",
     "shell.execute_reply": "2022-01-03T14:42:20.304045Z",
     "shell.execute_reply.started": "2022-01-03T14:39:20.810540Z"
    },
    "papermill": {
     "duration": 0.031859,
     "end_time": "2022-01-03T14:42:20.304568",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.272709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def my_sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "def softmax(x):\n",
    "    max = np.max(x,axis=1,keepdims=True)\n",
    "    e_x = np.exp(x - max)\n",
    "    sum = np.sum(e_x,axis=1,keepdims=True)\n",
    "    return e_x / sum \n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361de2f8",
   "metadata": {
    "papermill": {
     "duration": 0.020762,
     "end_time": "2022-01-03T14:42:20.346382",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.325620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57626077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.396294Z",
     "iopub.status.busy": "2022-01-03T14:42:20.395663Z",
     "iopub.status.idle": "2022-01-03T14:42:20.452612Z",
     "shell.execute_reply": "2022-01-03T14:42:20.453347Z",
     "shell.execute_reply.started": "2022-01-03T14:39:20.822980Z"
    },
    "papermill": {
     "duration": 0.086235,
     "end_time": "2022-01-03T14:42:20.453541",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.367306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
      "(8, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          1      1        0      0          1     0     1   \n",
       "1          0      1        1      0          0     0     0   \n",
       "\n",
       "                                                                             path  \n",
       "0  ../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg  \n",
       "1  ../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(CFG['input_trpath'])\n",
    "df_train[\"path\"] = [f\"{CFG['input_trimg']}{i}.jpg\" for i in df_train.Id]\n",
    "df_train[\"Pawclass\"] = df_train.Pawpularity / 100\n",
    "\n",
    "if CFG[\"submit\"]:\n",
    "    df_test = pd.read_csv(CFG['input_tepath'])\n",
    "    df_test[\"path\"] = [f\"{CFG['input_teimg']}{i}.jpg\" for i in df_test.Id]\n",
    "else:\n",
    "    df_test = pd.read_csv(CFG['input_trpath'])\n",
    "    df_test[\"path\"] = [f\"{CFG['input_trimg']}{i}.jpg\" for i in df_test.Id]\n",
    "\n",
    "meta_features = [c for c in df_test.columns if c not in [\"Id\",\"path\", \"Pawpularity\"]]\n",
    "\n",
    "print(meta_features)\n",
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3ed5ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.506816Z",
     "iopub.status.busy": "2022-01-03T14:42:20.503076Z",
     "iopub.status.idle": "2022-01-03T14:42:20.541502Z",
     "shell.execute_reply": "2022-01-03T14:42:20.541958Z",
     "shell.execute_reply.started": "2022-01-03T14:39:20.919207Z"
    },
    "papermill": {
     "duration": 0.066545,
     "end_time": "2022-01-03T14:42:20.542104",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.475559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.46291</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.534522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject Focus     Eyes      Face     Near    Action  Accessory  \\\n",
       "count       8.000000  8.00000  8.000000  8.00000  8.000000   8.000000   \n",
       "mean        0.625000  0.25000  0.625000  0.25000  0.375000   0.625000   \n",
       "std         0.517549  0.46291  0.517549  0.46291  0.517549   0.517549   \n",
       "min         0.000000  0.00000  0.000000  0.00000  0.000000   0.000000   \n",
       "25%         0.000000  0.00000  0.000000  0.00000  0.000000   0.000000   \n",
       "50%         1.000000  0.00000  1.000000  0.00000  0.000000   1.000000   \n",
       "75%         1.000000  0.25000  1.000000  0.25000  1.000000   1.000000   \n",
       "max         1.000000  1.00000  1.000000  1.00000  1.000000   1.000000   \n",
       "\n",
       "          Group   Collage    Human  Occlusion      Info      Blur  \n",
       "count  8.000000  8.000000  8.00000   8.000000  8.000000  8.000000  \n",
       "mean   0.500000  0.625000  0.25000   0.500000  0.625000  0.500000  \n",
       "std    0.534522  0.517549  0.46291   0.534522  0.517549  0.534522  \n",
       "min    0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  \n",
       "25%    0.000000  0.000000  0.00000   0.000000  0.000000  0.000000  \n",
       "50%    0.500000  1.000000  0.00000   0.500000  1.000000  0.500000  \n",
       "75%    1.000000  1.000000  0.25000   1.000000  1.000000  1.000000  \n",
       "max    1.000000  1.000000  1.00000   1.000000  1.000000  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df14a1",
   "metadata": {
    "papermill": {
     "duration": 0.023564,
     "end_time": "2022-01-03T14:42:20.589183",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.565619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog and cat labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae88aca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.650848Z",
     "iopub.status.busy": "2022-01-03T14:42:20.649995Z",
     "iopub.status.idle": "2022-01-03T14:42:20.651906Z",
     "shell.execute_reply": "2022-01-03T14:42:20.652334Z",
     "shell.execute_reply.started": "2022-01-03T14:39:20.997540Z"
    },
    "papermill": {
     "duration": 0.040741,
     "end_time": "2022-01-03T14:42:20.652474",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.611733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    try:\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None\n",
    "    model = models.densenet121(pretrained=False)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 2)\n",
    "    )\n",
    "    model.parameters = checkpoint['parameters']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b3487c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.703932Z",
     "iopub.status.busy": "2022-01-03T14:42:20.699596Z",
     "iopub.status.idle": "2022-01-03T14:42:20.706213Z",
     "shell.execute_reply": "2022-01-03T14:42:20.705792Z",
     "shell.execute_reply.started": "2022-01-03T14:39:21.015524Z"
    },
    "papermill": {
     "duration": 0.031749,
     "end_time": "2022-01-03T14:42:20.706323",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.674574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_transform(imagepath):\n",
    "    test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(imagepath)\n",
    "    imagetensor = test_transforms(image)\n",
    "    return imagetensor\n",
    "\n",
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img = image_transform(self.df.loc[index].path)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c021448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.757189Z",
     "iopub.status.busy": "2022-01-03T14:42:20.756424Z",
     "iopub.status.idle": "2022-01-03T14:42:20.758785Z",
     "shell.execute_reply": "2022-01-03T14:42:20.758250Z",
     "shell.execute_reply.started": "2022-01-03T14:39:21.029416Z"
    },
    "papermill": {
     "duration": 0.030407,
     "end_time": "2022-01-03T14:42:20.758904",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.728497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    img_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        img_preds = model(imgs)\n",
    "        img_preds_all += [img_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    img_preds_all = np.concatenate(img_preds_all, axis=0)\n",
    "    return img_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb455abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.811632Z",
     "iopub.status.busy": "2022-01-03T14:42:20.810791Z",
     "iopub.status.idle": "2022-01-03T14:42:20.812662Z",
     "shell.execute_reply": "2022-01-03T14:42:20.813088Z",
     "shell.execute_reply.started": "2022-01-03T14:39:21.055153Z"
    },
    "papermill": {
     "duration": 0.032112,
     "end_time": "2022-01-03T14:42:20.813210",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.781098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"False\" in list(np.array(CFG[\"models\"])[:,0]):\n",
    "    inference_ds = PetFinderDataset(df_test)\n",
    "    data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                               batch_size=CFG['batch_size'],\n",
    "                                               drop_last=False,\n",
    "                                               pin_memory=False,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=CFG['num_workers'])\n",
    "    model = load_model(\"../input/cat-vs-dog-model/cat-v-dog-classifier-pytorch-master/models/catvdog.pth\")\n",
    "    model.to(CFG[\"device\"])\n",
    "    with torch.no_grad():\n",
    "        res_cat_dog = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "    del model, inference_ds, data_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    df_test[[\"cat\",\"dog\"]] = softmax(res_cat_dog)\n",
    "    meta_features += [\"cat\",\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed2e0cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.861297Z",
     "iopub.status.busy": "2022-01-03T14:42:20.860508Z",
     "iopub.status.idle": "2022-01-03T14:42:20.873153Z",
     "shell.execute_reply": "2022-01-03T14:42:20.873883Z",
     "shell.execute_reply.started": "2022-01-03T14:39:21.072104Z"
    },
    "papermill": {
     "duration": 0.038885,
     "end_time": "2022-01-03T14:42:20.874083",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.835198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          1      1        0      0          1     0     1   \n",
       "1          0      1        1      0          0     0     0   \n",
       "\n",
       "                                                                             path  \n",
       "0  ../input/petfinder-pawpularity-score/test/4128bae22183829d2b5fea10effdb0c3.jpg  \n",
       "1  ../input/petfinder-pawpularity-score/test/43a2262d7738e3d420d453815151079e.jpg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bb56f",
   "metadata": {
    "papermill": {
     "duration": 0.022672,
     "end_time": "2022-01-03T14:42:20.920092",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.897420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make dog breed for dog label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10325e1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:20.969848Z",
     "iopub.status.busy": "2022-01-03T14:42:20.969040Z",
     "iopub.status.idle": "2022-01-03T14:42:20.975273Z",
     "shell.execute_reply": "2022-01-03T14:42:20.974857Z",
     "shell.execute_reply.started": "2022-01-03T14:39:34.938872Z"
    },
    "papermill": {
     "duration": 0.031539,
     "end_time": "2022-01-03T14:42:20.975394",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.943855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 120)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f579e92e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.031317Z",
     "iopub.status.busy": "2022-01-03T14:42:21.030395Z",
     "iopub.status.idle": "2022-01-03T14:42:21.032054Z",
     "shell.execute_reply": "2022-01-03T14:42:21.032455Z",
     "shell.execute_reply.started": "2022-01-03T14:39:35.244847Z"
    },
    "papermill": {
     "duration": 0.034463,
     "end_time": "2022-01-03T14:42:21.032580",
     "exception": false,
     "start_time": "2022-01-03T14:42:20.998117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df, size, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df   = df.reset_index(drop=True).copy()\n",
    "        self.size = size\n",
    "        self.transforms  = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img  = get_img(self.df.loc[index].path).copy()\n",
    "        if self.transforms:\n",
    "            h, w, _ = img.shape\n",
    "            trans = self.transforms(self.size, h, w)\n",
    "            img   = trans(image=img)['image']\n",
    "        return img\n",
    "    \n",
    "def get_inference_transforms(size, h, w):\n",
    "    h = int(size*1.2) if int(size*1.2) < h else h\n",
    "    w = int(size*1.2) if int(size*1.2) < w else w\n",
    "    return Compose([\n",
    "        CenterCrop(h, w, p=1.0),\n",
    "        albResize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821ed02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.083971Z",
     "iopub.status.busy": "2022-01-03T14:42:21.083236Z",
     "iopub.status.idle": "2022-01-03T14:42:21.085339Z",
     "shell.execute_reply": "2022-01-03T14:42:21.085703Z",
     "shell.execute_reply.started": "2022-01-03T14:39:35.678805Z"
    },
    "papermill": {
     "duration": 0.030803,
     "end_time": "2022-01-03T14:42:21.085856",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.055053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [image_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721e0877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.141053Z",
     "iopub.status.busy": "2022-01-03T14:42:21.140237Z",
     "iopub.status.idle": "2022-01-03T14:42:21.142854Z",
     "shell.execute_reply": "2022-01-03T14:42:21.142270Z",
     "shell.execute_reply.started": "2022-01-03T14:40:21.736949Z"
    },
    "papermill": {
     "duration": 0.034414,
     "end_time": "2022-01-03T14:42:21.142971",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.108557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"False\" in list(np.array(CFG[\"models\"])[:,0]):\n",
    "    inference_ds = PetFinderDataset(df_test, size=CFG[\"db_size\"], transforms=get_inference_transforms)\n",
    "    data_loader  = torch.utils.data.DataLoader(inference_ds,\n",
    "                                               batch_size=CFG['batch_size'],\n",
    "                                               drop_last=False,\n",
    "                                               pin_memory=False,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=CFG['num_workers'])\n",
    "    model = SwinModel(CFG['db_model'], pretrained=False)\n",
    "    model.load_state_dict(torch.load(\"../input/petfinder-dogbreed-cnn-models/dogbreed_swin_binary.pt\"))\n",
    "    model.to(CFG[\"device\"])\n",
    "    with torch.no_grad():\n",
    "        res_dogbreed = inference_one_epoch(model, data_loader, CFG[\"device\"])\n",
    "\n",
    "    del model, inference_ds, data_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    df_dogbreed = pd.DataFrame(softmax(res_dogbreed))\n",
    "    df_dogbreed[\"dog\"] = softmax(res_cat_dog)[:,1] > 0.5\n",
    "    df_dogbreed.loc[df_dogbreed.dog==False, :120] = 0\n",
    "    df_dogbreed = df_dogbreed.drop(\"dog\", axis=1)\n",
    "    df_dogbreed.columns = [f\"db{i}\" for i in df_dogbreed.columns]\n",
    "    print(df_dogbreed.shape)\n",
    "    \n",
    "    df_meta = df_test[meta_features].join(df_dogbreed)\n",
    "    print(df_meta.shape)\n",
    "    display(df_meta.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc2919",
   "metadata": {
    "papermill": {
     "duration": 0.022306,
     "end_time": "2022-01-03T14:42:21.187876",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.165570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de6b8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.257200Z",
     "iopub.status.busy": "2022-01-03T14:42:21.256236Z",
     "iopub.status.idle": "2022-01-03T14:42:21.257947Z",
     "shell.execute_reply": "2022-01-03T14:42:21.258450Z",
     "shell.execute_reply.started": "2022-01-03T14:40:29.724948Z"
    },
    "papermill": {
     "duration": 0.047984,
     "end_time": "2022-01-03T14:42:21.258583",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.210599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "    \n",
    "class ModelwithMetadata(nn.Module):\n",
    "    def __init__(self, model_name, size=512, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=4)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        # Exclude the top layer\n",
    "        self.model.reset_classifier(0)\n",
    "        self.linear1 = nn.Linear(134, size*size)        \n",
    "        self.linear2 = nn.Linear(134, self.n_features)\n",
    "        self.linear3 = nn.Linear(self.n_features, 256)\n",
    "        self.linear4 = nn.Linear(256, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Metadata first\n",
    "        x = self.linear1(x2)\n",
    "        x = torch.reshape(x, (x2.shape[0], 1, self.size, self.size))\n",
    "        x = torch.cat((x1, x), dim=1)\n",
    "        x = self.model(x)\n",
    "        # Metadata Last\n",
    "        x2 = self.linear2(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear3(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear4(x)\n",
    "        return output\n",
    "\n",
    "class SwinModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "    \n",
    "class SwinModelwithMetadata(nn.Module):\n",
    "    def __init__(self, model_name, size=224, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=4)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear1 = nn.Linear(134, size*size)\n",
    "        self.linear2 = nn.Linear(134, num_features)\n",
    "        self.linear3 = nn.Linear(num_features, 256)\n",
    "        self.linear4 = nn.Linear(256, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Metadata first\n",
    "        x  = self.linear1(x2)\n",
    "        x  = torch.reshape(x, (x2.shape[0], 1, self.size, self.size))\n",
    "        x  = torch.cat((x1, x), dim=1)\n",
    "        x  = self.model(x)\n",
    "        x2 = self.linear2(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear3(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear4(x)\n",
    "        return output\n",
    "    \n",
    "class SwinModelwithMetadataLast(nn.Module):\n",
    "    def __init__(self, model_name, size=224, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.size  = size\n",
    "        self.backbone = SwinModel(model_name, False)\n",
    "        num_features  = self.backbone.model.num_features\n",
    "        self.backbone.linear = nn.Linear(num_features, 256)\n",
    "        self.linear1 = nn.Linear(134, 256)\n",
    "        self.linear2 = nn.Linear(256, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x  = self.backbone(x1)\n",
    "        # Metadata Last\n",
    "        x2 = self.linear1(x2)\n",
    "        x  = torch.add(x, x2)\n",
    "        x  = self.relu(self.linear2(x))\n",
    "        x  = self.dropout(x)\n",
    "        output = self.linear3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6243c834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.317708Z",
     "iopub.status.busy": "2022-01-03T14:42:21.316745Z",
     "iopub.status.idle": "2022-01-03T14:42:21.318748Z",
     "shell.execute_reply": "2022-01-03T14:42:21.319286Z",
     "shell.execute_reply.started": "2022-01-03T14:40:30.141974Z"
    },
    "papermill": {
     "duration": 0.038226,
     "end_time": "2022-01-03T14:42:21.319440",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.281214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df_img, df_meta, size, transforms=None, output_meta=True):\n",
    "        super().__init__()\n",
    "        self.df_img  = df_img.reset_index(drop=True).copy()\n",
    "        self.df_meta = df_meta.reset_index(drop=True).copy()\n",
    "        self.size    = size\n",
    "        self.transforms  = transforms\n",
    "        self.output_meta = output_meta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df_img.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img  = get_img(self.df_img.loc[index].path)\n",
    "        meta = torch.from_numpy(np.array(self.df_meta.loc[index], dtype=float))\n",
    "        if self.transforms:\n",
    "            h, w, _ = img.shape\n",
    "            trans = self.transforms(self.size, h, w)\n",
    "            img   = trans(image=img)['image']\n",
    "        if self.output_meta:\n",
    "            return img, meta\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80769bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.384186Z",
     "iopub.status.busy": "2022-01-03T14:42:21.378573Z",
     "iopub.status.idle": "2022-01-03T14:42:21.386611Z",
     "shell.execute_reply": "2022-01-03T14:42:21.386182Z",
     "shell.execute_reply.started": "2022-01-03T14:40:30.541830Z"
    },
    "papermill": {
     "duration": 0.040629,
     "end_time": "2022-01-03T14:42:21.386724",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.346095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tta_inference_transforms_1(size, h, w):\n",
    "    return Compose([\n",
    "        RandomResizedCrop(size, size, scale=(0.7, 1.0), p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        MotionBlur(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_tta_inference_transforms_2(size, h, w):\n",
    "    return Compose([\n",
    "        albResize(size, size, p=1.0),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_inference_transforms_1(size, h, w):\n",
    "    h = int(size*1.2) if int(size*1.2) < h else h\n",
    "    w = int(size*1.2) if int(size*1.2) < w else w\n",
    "    return Compose([\n",
    "        CenterCrop(h, w, p=1.0),\n",
    "        albResize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def get_inference_transforms_2(size, h, w):\n",
    "    return Compose([\n",
    "        albResize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbdfe5a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.447245Z",
     "iopub.status.busy": "2022-01-03T14:42:21.446213Z",
     "iopub.status.idle": "2022-01-03T14:42:21.448199Z",
     "shell.execute_reply": "2022-01-03T14:42:21.448712Z",
     "shell.execute_reply.started": "2022-01-03T14:40:30.746568Z"
    },
    "papermill": {
     "duration": 0.035816,
     "end_time": "2022-01-03T14:42:21.448908",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.413092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, use_meta, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    img_preds_all = []\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs, metas) in pbar:\n",
    "        imgs  = imgs.to(device).float()\n",
    "        if use_meta != 0:\n",
    "            metas = metas[:,:use_meta].to(device).float()\n",
    "            img_preds = model(imgs, metas)\n",
    "        else:\n",
    "            img_preds = model(imgs)\n",
    "        img_preds_all += [img_preds.detach().cpu().numpy()]\n",
    "        \n",
    "    img_preds_all = np.concatenate(img_preds_all, axis=0)\n",
    "    return img_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f754bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.507184Z",
     "iopub.status.busy": "2022-01-03T14:42:21.506268Z",
     "iopub.status.idle": "2022-01-03T14:42:21.508069Z",
     "shell.execute_reply": "2022-01-03T14:42:21.508516Z",
     "shell.execute_reply.started": "2022-01-03T14:40:31.265519Z"
    },
    "papermill": {
     "duration": 0.033059,
     "end_time": "2022-01-03T14:42:21.508655",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.475596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, size):\n",
    "    df = df.copy()\n",
    "    label_col  = \"Pawclass\"\n",
    "    dataloader = ImageDataLoaders.from_df(\n",
    "        df,\n",
    "        valid_pct=0.2,  # Dummy\n",
    "        seed=CFG[\"seed\"],\n",
    "        fn_col='path',\n",
    "        label_col=label_col,\n",
    "        y_block=RegressionBlock,\n",
    "        bs=CFG['batch_size'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        item_tfms=Resize(size),\n",
    "        batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def petfinder_rmse(input,target):\n",
    "    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e5703f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.558571Z",
     "iopub.status.busy": "2022-01-03T14:42:21.557787Z",
     "iopub.status.idle": "2022-01-03T14:42:21.563647Z",
     "shell.execute_reply": "2022-01-03T14:42:21.564153Z",
     "shell.execute_reply.started": "2022-01-03T14:40:31.564977Z"
    },
    "papermill": {
     "duration": 0.032953,
     "end_time": "2022-01-03T14:42:21.564289",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.531336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_learner(df, size, model, model_path):\n",
    "    dataloader = prepare_dataloader(df, size)\n",
    "    if -1 < model.find(\"swin\") or -1 < model.find(\"beit\"):\n",
    "        model = SwinModel(model, pretrained=False)\n",
    "    else:\n",
    "        model = Model(model, pretrained=False)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    learner = Learner(\n",
    "        dataloader,\n",
    "        model,\n",
    "        loss_func=BCEWithLogitsLossFlat(),\n",
    "        metrics=petfinder_rmse).to_fp16()\n",
    "    return learner, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716d4ef",
   "metadata": {
    "papermill": {
     "duration": 0.024142,
     "end_time": "2022-01-03T14:42:21.612910",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.588768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15c1712e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:42:21.672611Z",
     "iopub.status.busy": "2022-01-03T14:42:21.671641Z",
     "iopub.status.idle": "2022-01-03T14:47:42.315666Z",
     "shell.execute_reply": "2022-01-03T14:47:42.316139Z",
     "shell.execute_reply.started": "2022-01-03T14:40:32.693107Z"
    },
    "papermill": {
     "duration": 320.680802,
     "end_time": "2022-01-03T14:47:42.316306",
     "exception": false,
     "start_time": "2022-01-03T14:42:21.635504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_res = []\n",
    "for fastai, size, use_meta, dataset_type, model, model_path in CFG['models']:\n",
    "    \n",
    "    if fastai:\n",
    "        learn, data_loader = get_learner(df_train, size, model, model_path)\n",
    "        data_loader = data_loader.test_dl(df_test)\n",
    "        res, _ = learn.tta(dl=data_loader, n=CFG[\"tta\"], beta=0)\n",
    "        res    = res.detach().numpy()\n",
    "        if -1 < model_path.find(\"binary\"):\n",
    "            res = res*100\n",
    "        all_res.append(res)\n",
    "        \n",
    "        del learn, data_loader\n",
    "    else:\n",
    "        if 1 < CFG[\"tta\"]:\n",
    "            if dataset_type == 1:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_tta_inference_transforms_1)\n",
    "            else:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_tta_inference_transforms_2)\n",
    "        else:\n",
    "            if dataset_type == 1:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_inference_transforms_1)\n",
    "            else:\n",
    "                inference_ds = PetFinderDataset(df_test, df_meta, size, transforms=get_inference_transforms_2)\n",
    "        data_loader = torch.utils.data.DataLoader(inference_ds,\n",
    "                                                  batch_size=CFG['batch_size'],\n",
    "                                                  drop_last=False,\n",
    "                                                  pin_memory=False,\n",
    "                                                  shuffle=False,\n",
    "                                                  num_workers=CFG['num_workers'])\n",
    "        if -1 < model_path.find(\"swin\"):\n",
    "            if use_meta == 0:\n",
    "                model = SwinModel(model, pretrained=False)\n",
    "            else:\n",
    "                if -1 < model_path.find(\"ed\"):\n",
    "                    model = SwinModelwithMetadataLast(model, size, pretrained=False)\n",
    "                else:\n",
    "                    model = SwinModelwithMetadata(model, size, pretrained=False)\n",
    "        else:\n",
    "            if use_meta == 0:\n",
    "                model = Model(model, pretrained=False)\n",
    "            else:\n",
    "                model = ModelwithMetadata(model, size, pretrained=False)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(CFG[\"device\"])\n",
    "\n",
    "        tta_res = []\n",
    "        for i in range(CFG[\"tta\"]):\n",
    "            with torch.no_grad():\n",
    "                res = inference_one_epoch(model, use_meta, data_loader, CFG[\"device\"])\n",
    "                if -1 < model_path.find(\"binary\"):\n",
    "                    res = my_sigmoid(res)*100\n",
    "                tta_res.append(res)\n",
    "        all_res.append(np.mean(tta_res, 0))\n",
    "\n",
    "        del model, inference_ds, data_loader\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "367f273e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:47:42.409221Z",
     "iopub.status.busy": "2022-01-03T14:47:42.408429Z",
     "iopub.status.idle": "2022-01-03T14:47:42.410991Z",
     "shell.execute_reply": "2022-01-03T14:47:42.410545Z",
     "shell.execute_reply.started": "2021-12-28T14:19:47.766845Z"
    },
    "papermill": {
     "duration": 0.052158,
     "end_time": "2022-01-03T14:47:42.411101",
     "exception": false,
     "start_time": "2022-01-03T14:47:42.358943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(np.array(all_res).reshape(len(CFG[\"models\"]),-1)).T\n",
    "if not CFG[\"submit\"]:\n",
    "    df_pred[\"target\"] = df_test.Pawpularity\n",
    "    df_pred.to_csv(\"./inference_result_train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d238467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:47:42.505842Z",
     "iopub.status.busy": "2022-01-03T14:47:42.505223Z",
     "iopub.status.idle": "2022-01-03T14:47:42.509642Z",
     "shell.execute_reply": "2022-01-03T14:47:42.509243Z",
     "shell.execute_reply.started": "2021-12-28T14:19:50.531805Z"
    },
    "papermill": {
     "duration": 0.055672,
     "end_time": "2022-01-03T14:47:42.509750",
     "exception": false,
     "start_time": "2022-01-03T14:47:42.454078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    42.323219\n",
      "1    42.695087\n",
      "2    42.507626\n",
      "3    41.956696\n",
      "4    42.644741\n",
      "5    42.529846\n",
      "6    42.671551\n",
      "7    42.430286\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "if CFG[\"stacking\"]:\n",
    "    loaded_model = pickle.load(open(\"../input/petfinder-stacking-model/stacking_model.pickle\", 'rb'))\n",
    "    # Calculate mean every model type\n",
    "    sta = 0\n",
    "    mean_every_model = []\n",
    "    for i in range(4, len(CFG[\"models\"])+1, 4):  # 4 is fold num\n",
    "        mean_every_model.append(df_pred.iloc[:, sta:i].mean(1))\n",
    "        sta = i\n",
    "    df_mean_every_model = pd.concat(mean_every_model, axis=1)\n",
    "    # Predict with stacking model\n",
    "    ensembled = loaded_model.predict(df_mean_every_model)\n",
    "else:\n",
    "    ensembled = df_pred.mean(1)\n",
    "print(ensembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2e06de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T14:47:42.602372Z",
     "iopub.status.busy": "2022-01-03T14:47:42.601531Z",
     "iopub.status.idle": "2022-01-03T14:47:42.617655Z",
     "shell.execute_reply": "2022-01-03T14:47:42.617202Z",
     "shell.execute_reply.started": "2021-12-28T14:12:30.666203Z"
    },
    "papermill": {
     "duration": 0.063751,
     "end_time": "2022-01-03T14:47:42.617810",
     "exception": false,
     "start_time": "2022-01-03T14:47:42.554059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG[\"submit\"]:\n",
    "    ss = pd.read_csv(\"../input/petfinder-pawpularity-score/sample_submission.csv\")\n",
    "    ss[\"Pawpularity\"] = ensembled\n",
    "    ss.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 343.497033,
   "end_time": "2022-01-03T14:47:46.446109",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-03T14:42:02.949076",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
