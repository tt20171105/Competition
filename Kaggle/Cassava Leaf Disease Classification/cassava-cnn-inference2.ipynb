{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:21:14.749465Z",
     "iopub.status.busy": "2021-02-17T01:21:14.748665Z",
     "iopub.status.idle": "2021-02-17T01:23:08.221441Z",
     "shell.execute_reply": "2021-02-17T01:23:08.220568Z"
    },
    "papermill": {
     "duration": 113.491714,
     "end_time": "2021-02-17T01:23:08.221577",
     "exception": false,
     "start_time": "2021-02-17T01:21:14.729863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: fastai 2.0.19\r\n",
      "Uninstalling fastai-2.0.19:\r\n",
      "  Successfully uninstalled fastai-2.0.19\r\n",
      "Processing /kaggle/input/packages/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1) (1.18.5)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1) (3.7.4.1)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.6.0\r\n",
      "    Uninstalling torch-1.6.0:\r\n",
      "      Successfully uninstalled torch-1.6.0\r\n",
      "Successfully installed torch-1.7.1\r\n",
      "Processing /kaggle/input/packages/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: torch==1.7.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.2) (1.7.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.2) (1.18.5)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.2) (8.0.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1->torchvision==0.8.2) (3.7.4.1)\r\n",
      "Installing collected packages: torchvision\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.7.0\r\n",
      "    Uninstalling torchvision-0.7.0:\r\n",
      "      Successfully uninstalled torchvision-0.7.0\r\n",
      "Successfully installed torchvision-0.8.2\r\n"
     ]
    }
   ],
   "source": [
    "# Uninstall fastai for solving dependence problems\n",
    "!pip uninstall fastai -y\n",
    "# Install packages without internet\n",
    "!pip install ../input/packages/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install ../input/packages/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:08.259869Z",
     "iopub.status.busy": "2021-02-17T01:23:08.254503Z",
     "iopub.status.idle": "2021-02-17T01:23:08.748523Z",
     "shell.execute_reply": "2021-02-17T01:23:08.747562Z"
    },
    "papermill": {
     "duration": 0.512817,
     "end_time": "2021-02-17T01:23:08.748658",
     "exception": false,
     "start_time": "2021-02-17T01:23:08.235841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/repvggmodels/')\n",
    "sys.path.append('../input/vision-transformer-pytorch/VisionTransformer-Pytorch')\n",
    "\n",
    "from repvgg import RepVGG, create_RepVGG_B3, create_RepVGG_B3g4, repvgg_model_convert\n",
    "from vision_transformer_pytorch import VisionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:08.788487Z",
     "iopub.status.busy": "2021-02-17T01:23:08.787707Z",
     "iopub.status.idle": "2021-02-17T01:23:17.917811Z",
     "shell.execute_reply": "2021-02-17T01:23:17.916590Z"
    },
    "papermill": {
     "duration": 9.155017,
     "end_time": "2021-02-17T01:23:17.917945",
     "exception": false,
     "start_time": "2021-02-17T01:23:08.762928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "import sklearn\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from IPython.display import display\n",
    "from catalyst.data.sampler import BalanceClassSampler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from albumentations.pytorch import ToTensor, ToTensorV2\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n",
    "    ShiftScaleRotate, CenterCrop, Resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:17.955926Z",
     "iopub.status.busy": "2021-02-17T01:23:17.954571Z",
     "iopub.status.idle": "2021-02-17T01:23:17.958885Z",
     "shell.execute_reply": "2021-02-17T01:23:17.958445Z"
    },
    "papermill": {
     "duration": 0.025489,
     "end_time": "2021-02-17T01:23:17.958982",
     "exception": false,
     "start_time": "2021-02-17T01:23:17.933493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:17.993991Z",
     "iopub.status.busy": "2021-02-17T01:23:17.993453Z",
     "iopub.status.idle": "2021-02-17T01:23:18.004071Z",
     "shell.execute_reply": "2021-02-17T01:23:18.003587Z"
    },
    "papermill": {
     "duration": 0.030146,
     "end_time": "2021-02-17T01:23:18.004158",
     "exception": false,
     "start_time": "2021-02-17T01:23:17.974012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'seed'       : 42,\n",
    "    'fold'       : 0 if len(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))==1 else 99,\n",
    "    'tta'        : 1 if len(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))==1 else 4,\n",
    "    'img_size'   : 400,\n",
    "    'valid_bs'   : 32,\n",
    "    'num_workers': multiprocessing.cpu_count(),\n",
    "    'device'     : 'cuda:0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:18.038919Z",
     "iopub.status.busy": "2021-02-17T01:23:18.038248Z",
     "iopub.status.idle": "2021-02-17T01:23:18.041340Z",
     "shell.execute_reply": "2021-02-17T01:23:18.040904Z"
    },
    "papermill": {
     "duration": 0.022178,
     "end_time": "2021-02-17T01:23:18.041438",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.019260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014716,
     "end_time": "2021-02-17T01:23:18.071111",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.056395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:18.109988Z",
     "iopub.status.busy": "2021-02-17T01:23:18.109456Z",
     "iopub.status.idle": "2021-02-17T01:23:18.113564Z",
     "shell.execute_reply": "2021-02-17T01:23:18.113097Z"
    },
    "papermill": {
     "duration": 0.027534,
     "end_time": "2021-02-17T01:23:18.113660",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.086126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                 one_hot_label=False):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms  = transforms\n",
    "        self.data_root   = data_root\n",
    "        self.output_label  = output_label\n",
    "        self.one_hot_label = one_hot_label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img = get_img(f\"{self.data_root}/{self.df.loc[index]['image_id']}\")\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:18.151689Z",
     "iopub.status.busy": "2021-02-17T01:23:18.150950Z",
     "iopub.status.idle": "2021-02-17T01:23:18.153599Z",
     "shell.execute_reply": "2021-02-17T01:23:18.153119Z"
    },
    "papermill": {
     "duration": 0.024773,
     "end_time": "2021-02-17T01:23:18.153682",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.128909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:18.191960Z",
     "iopub.status.busy": "2021-02-17T01:23:18.189941Z",
     "iopub.status.idle": "2021-02-17T01:23:18.194806Z",
     "shell.execute_reply": "2021-02-17T01:23:18.194393Z"
    },
    "papermill": {
     "duration": 0.026878,
     "end_time": "2021-02-17T01:23:18.194892",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.168014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, backbone=None):\n",
    "        super(FFN, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.lr1      = nn.Linear(1000, 256)\n",
    "        self.relu     = nn.ReLU()\n",
    "        self.dropout  = nn.Dropout(0.5)\n",
    "        self.lr2      = nn.Linear(256, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.relu(self.lr1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.lr2(x)\n",
    "        return x\n",
    "    \n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, backbone=None):\n",
    "        super(ViT, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:18.231207Z",
     "iopub.status.busy": "2021-02-17T01:23:18.230445Z",
     "iopub.status.idle": "2021-02-17T01:23:18.233141Z",
     "shell.execute_reply": "2021-02-17T01:23:18.232739Z"
    },
    "papermill": {
     "duration": 0.023581,
     "end_time": "2021-02-17T01:23:18.233243",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.209662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:18.270856Z",
     "iopub.status.busy": "2021-02-17T01:23:18.270031Z",
     "iopub.status.idle": "2021-02-17T01:23:18.277153Z",
     "shell.execute_reply": "2021-02-17T01:23:18.277685Z"
    },
    "papermill": {
     "duration": 0.030008,
     "end_time": "2021-02-17T01:23:18.277812",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.247804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(df, data_path, model_name, model_path, backbone, load=True):\n",
    "    results = np.zeros((len(os.listdir(data_path)), 5))\n",
    "    models  = [m for m in os.listdir(model_path) if m.find(\"csv\")==-1]\n",
    "    for model_file in models:\n",
    "        print(model_file)\n",
    "        device  = torch.device(CFG['device'])\n",
    "        dataset = CassavaDataset(df, data_path, transforms=get_inference_transforms(), output_label=False)\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, \n",
    "            batch_size =CFG['valid_bs'],\n",
    "            num_workers=CFG['num_workers'],\n",
    "            shuffle=False,\n",
    "            pin_memory=False)\n",
    "\n",
    "        model = model_name(backbone)\n",
    "        if load:\n",
    "            if CFG['device'] == \"cpu\":\n",
    "                model.load_state_dict(torch.load(f\"{model_path}{model_file}\", map_location=\"cpu\"))\n",
    "            else:\n",
    "                model.load_state_dict(torch.load(f\"{model_path}{model_file}\"))\n",
    "        backbone.to(device)\n",
    "        model.to(device)\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(CFG['tta']):\n",
    "                preds += [(1/CFG['tta'])*inference_one_epoch(model, data_loader, device)]\n",
    "        preds    = np.sum(preds, 0)\n",
    "        results += preds\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if CFG['fold'] == 0:\n",
    "            return results\n",
    "        \n",
    "    return results / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:18.312676Z",
     "iopub.status.busy": "2021-02-17T01:23:18.312137Z",
     "iopub.status.idle": "2021-02-17T01:23:28.033208Z",
     "shell.execute_reply": "2021-02-17T01:23:28.032753Z"
    },
    "papermill": {
     "duration": 9.740622,
     "end_time": "2021-02-17T01:23:28.033331",
     "exception": false,
     "start_time": "2021-02-17T01:23:18.292709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_with_noise_label_fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path  = '../input/cassava-leaf-disease-classification/test_images/'\n",
    "test = pd.DataFrame()\n",
    "test['image_id'] = list(os.listdir(test_path))\n",
    "model_path = '../input/cassava-models-trained-with-noise-labels/'\n",
    "backbone   = create_RepVGG_B3g4(deploy=True)\n",
    "\n",
    "results_from_noise_model = predict(test, test_path, FFN, model_path, backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:28.071565Z",
     "iopub.status.busy": "2021-02-17T01:23:28.070847Z",
     "iopub.status.idle": "2021-02-17T01:23:33.563973Z",
     "shell.execute_reply": "2021-02-17T01:23:33.562479Z"
    },
    "papermill": {
     "duration": 5.514149,
     "end_time": "2021-02-17T01:23:33.564108",
     "exception": false,
     "start_time": "2021-02-17T01:23:28.049959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_cnn_fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = '../input/cassava-noised-label-data/'\n",
    "backbone   = create_RepVGG_B3g4(deploy=True)\n",
    "\n",
    "results_from_clean_model = predict(test, test_path, FFN, model_path, backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:33.608324Z",
     "iopub.status.busy": "2021-02-17T01:23:33.607615Z",
     "iopub.status.idle": "2021-02-17T01:23:37.933339Z",
     "shell.execute_reply": "2021-02-17T01:23:37.933990Z"
    },
    "papermill": {
     "duration": 4.350489,
     "end_time": "2021-02-17T01:23:37.934151",
     "exception": false,
     "start_time": "2021-02-17T01:23:33.583662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT-B_16.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = '../input/vit-model-1/'\n",
    "backbone   = VisionTransformer.from_name('ViT-B_16', num_classes=5)\n",
    "backbone.load_state_dict(torch.load(model_path+\"/ViT-B_16.pt\"))\n",
    "\n",
    "CFG[\"img_size\"] = 384\n",
    "\n",
    "results_from_vit = predict(test, test_path, ViT, model_path, backbone, load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:37.977462Z",
     "iopub.status.busy": "2021-02-17T01:23:37.976891Z",
     "iopub.status.idle": "2021-02-17T01:23:37.980837Z",
     "shell.execute_reply": "2021-02-17T01:23:37.980404Z"
    },
    "papermill": {
     "duration": 0.026825,
     "end_time": "2021-02-17T01:23:37.980922",
     "exception": false,
     "start_time": "2021-02-17T01:23:37.954097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = 0.4*results_from_noise_model + 0.2*results_from_clean_model + 0.4*results_from_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:38.032127Z",
     "iopub.status.busy": "2021-02-17T01:23:38.031395Z",
     "iopub.status.idle": "2021-02-17T01:23:38.038673Z",
     "shell.execute_reply": "2021-02-17T01:23:38.039082Z"
    },
    "papermill": {
     "duration": 0.038785,
     "end_time": "2021-02-17T01:23:38.039200",
     "exception": false,
     "start_time": "2021-02-17T01:23:38.000415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = np.argmax(results,1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T01:23:38.082106Z",
     "iopub.status.busy": "2021-02-17T01:23:38.081613Z",
     "iopub.status.idle": "2021-02-17T01:23:38.253556Z",
     "shell.execute_reply": "2021-02-17T01:23:38.252908Z"
    },
    "papermill": {
     "duration": 0.194834,
     "end_time": "2021-02-17T01:23:38.253666",
     "exception": false,
     "start_time": "2021-02-17T01:23:38.058832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 148.826265,
   "end_time": "2021-02-17T01:23:39.708314",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-17T01:21:10.882049",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
