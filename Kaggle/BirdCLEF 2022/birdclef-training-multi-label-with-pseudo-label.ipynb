{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T11:04:40.324221Z","iopub.execute_input":"2022-05-12T11:04:40.324556Z","iopub.status.idle":"2022-05-12T11:04:40.360146Z","shell.execute_reply.started":"2022-05-12T11:04:40.324475Z","shell.execute_reply":"2022-05-12T11:04:40.359374Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport ast\nimport cv2\nimport copy\nimport time\nimport yaml\nimport random\nimport shutil\nimport warnings\nimport torchaudio\nimport subprocess\nimport numpy as np\nimport pandas as pd\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nfrom glob import glob as glob_file\nfrom tqdm import tqdm\nfrom PIL import Image, ImageDraw\nfrom shutil import copyfile\nfrom IPython.core.display import Video, display\nfrom sklearn.metrics import mean_squared_error, f1_score\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\n\nimport timm\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom torchvision import models, transforms\nfrom fastai.vision.all import *\nfrom huggingface_hub import snapshot_download\nfrom transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2FeatureExtractor\n\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize,\n    Flip, HorizontalFlip, VerticalFlip, CenterCrop, RandomResizedCrop,\n    Rotate, ShiftScaleRotate, RandomRotate90, Transpose,\n    RGBShift, ChannelShuffle, HueSaturationValue, RandomBrightnessContrast,\n    Blur, MotionBlur, MedianBlur, GaussNoise, Cutout, CoarseDropout\n)\n\nwarnings.simplefilter('ignore')\npd.set_option(\"max_columns\", 150)\npd.set_option('display.max_rows', 150)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:00:20.222771Z","iopub.execute_input":"2022-05-07T08:00:20.223502Z","iopub.status.idle":"2022-05-07T08:00:26.043795Z","shell.execute_reply.started":"2022-05-07T08:00:20.223459Z","shell.execute_reply":"2022-05-07T08:00:26.043087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    \"save_prev\"     : [True, [\"*.pth\"]],\n    \"seed\"          : 42,\n    'device'        : \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n    \"base_path\"     : \"../input/birdclef-2022/\",\n    \"img_fl_path\"   : \"../input/birdclef-spectrograms-dataset/\",\n    \"img_all_path\"  : \"../input/birdclef-spectrograms-scoredbird-dataset/\",\n    \"output_path\"   : './',\n    \"n_sample\"      : [200],\n    \"pretrain\"      : \"../input/birdclef-models/birdclef_effnet_wav2vec.pth\",\n    \"save_name\"     : \"birdclef_effnet_n200\",\n    \"class_num\"     : 22,\n    \"model\"         : \"tf_efficientnet_b5_ns\", #\"swin_large_patch4_window7_224\",\n    \"size\"          : 224,\n    \"fold\"          : 1,\n    \"test_max\"      : 250,\n    \"batch_size\"    : 8,\n    \"epochs\"        : 5,\n    \"n_data\"        : None,  # Batch * step\n    \"mixup_ratio\"   : 1.0,\n    \"lr\"            : 1e-4,\n    \"early_stopping\": 3,\n    \"num_workers\"   : 4\n}\n\nCFG","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:00:26.045628Z","iopub.execute_input":"2022-05-07T08:00:26.045962Z","iopub.status.idle":"2022-05-07T08:00:26.0573Z","shell.execute_reply.started":"2022-05-07T08:00:26.045925Z","shell.execute_reply":"2022-05-07T08:00:26.056624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb\n\ndef seed_everything(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nseed_everything(CFG[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:00:26.058426Z","iopub.execute_input":"2022-05-07T08:00:26.059082Z","iopub.status.idle":"2022-05-07T08:00:26.074193Z","shell.execute_reply.started":"2022-05-07T08:00:26.059045Z","shell.execute_reply":"2022-05-07T08:00:26.073307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG['save_prev'][0]:\n    for file_pattern in CFG['save_prev'][1]:\n        for f in glob_file(f\"../input/birdclef-trained-models-with-scored-bird/models/{file_pattern}\"):\n            filename = os.path.basename(f)\n            print(filename)\n            os.makedirs(\"./models\", exist_ok=True)\n            !cp {f} ./models/{filename}\n    print(os.listdir(\"./models\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:00:26.075934Z","iopub.execute_input":"2022-05-07T08:00:26.076422Z","iopub.status.idle":"2022-05-07T08:01:06.187466Z","shell.execute_reply.started":"2022-05-07T08:00:26.076383Z","shell.execute_reply":"2022-05-07T08:01:06.186584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define functions","metadata":{}},{"cell_type":"code","source":"# Scored bird names\nscored_birds = pd.read_json(f\"{CFG['base_path']}scored_birds.json\").values.flatten().tolist()\nbird2label   = {}\nfor i, b in enumerate(scored_birds):\n    bird2label[b] = i\n    \n# Define labels for other cases\nlabel_other_birds = max(bird2label.values()) + 1\nlabel_no_birds    = label_other_birds + 1","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:06.189297Z","iopub.execute_input":"2022-05-07T08:01:06.189517Z","iopub.status.idle":"2022-05-07T08:01:06.213204Z","shell.execute_reply.started":"2022-05-07T08:01:06.189492Z","shell.execute_reply":"2022-05-07T08:01:06.212478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_files(path, only_scored_bird=True):\n    file_num = []\n    for d in os.listdir(path):\n        file_num.append([d, len(os.listdir(f\"{path}{d}\")), f\"{path}{d}/\"])\n    df_file_num = pd.DataFrame(file_num, columns=[\"bird\", \"file_num\", \"path\"])\n    print(\"Before Max,Min:\", df_file_num.file_num.max(), df_file_num.file_num.min())\n    if only_scored_bird:\n        df_file_num = df_file_num[df_file_num.bird.isin(scored_birds)].sort_values(\"file_num\").reset_index(drop=True)\n    else:\n        df_file_num = df_file_num[~df_file_num.bird.isin(scored_birds)].sort_values(\"file_num\").reset_index(drop=True)\n    print(\"After  Max,Min:\", df_file_num.file_num.max(), df_file_num.file_num.min())\n    print(\"Result shape:\", df_file_num.shape)\n    print(\"----------------------------\")\n    return df_file_num\n\ndef get_exclusion_files(df_all):\n    exclusion_files = []\n    for p in df_all.path:\n        df = pd.DataFrame(os.listdir(p), columns=[\"filename\"])\n        df[\"audio_name\"] = df.filename.apply(lambda x: x[:x.find(\".ogg\")])\n        df[\"img_num\"]    = df.filename.apply(lambda x: x[-7:-4]).astype(int)\n        df[\"key\"] = df[\"audio_name\"] + df[\"img_num\"].astype(str)\n        df_remove_key = df.groupby(\"audio_name\", as_index=False).img_num.max()\n        df_remove_key[\"key\"] = df_remove_key[\"audio_name\"] + df_remove_key[\"img_num\"].astype(str)\n        df = df[(df.img_num == 0)|(df.key.isin(df_remove_key.key))]\n        exclusion_files += df.filename.tolist()\n    return exclusion_files","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:06.214734Z","iopub.execute_input":"2022-05-07T08:01:06.215239Z","iopub.status.idle":"2022-05-07T08:01:06.227377Z","shell.execute_reply.started":"2022-05-07T08:01:06.215201Z","shell.execute_reply":"2022-05-07T08:01:06.226591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trans2label(birds):\n    if birds == []:\n        return [label_no_birds]\n    new_labels = []\n    for b in birds:\n        if b in bird2label.keys():\n            new_labels.append(bird2label[b])\n        else:\n            new_labels.append(label_other_birds)\n    return list(set(new_labels))\n\ndef make_train_df(df, n, pct, exclude=None):\n    df = df.copy()\n    image_paths = []\n    for b, p in zip(df.bird, df.path):\n        train_paths = []\n        test_paths  = []\n        train_n   = int(len(os.listdir(p))*pct)\n        test_n    = len(os.listdir(p)) - train_n\n        all_paths = os.listdir(p)\n        if pct < 1:\n            if pct == 0:\n                if exclude is not None:\n                    all_paths = [p for p in all_paths if p not in exclude]\n                test_n = min(test_n, len(all_paths), CFG[\"test_max\"])\n            test_paths = random.sample(all_paths, k=test_n)\n        if pct > 0:\n            train_paths = [ap for ap in all_paths if ap not in test_paths]\n            train_paths = random.choices(train_paths, k=CFG[\"n_sample\"][n])\n        test_paths  = [[1, pi[:pi.find(\".ogg\")+4], b, p + pi] for pi in test_paths]\n        train_paths = [[0, pi[:pi.find(\".ogg\")+4], b, p + pi] for pi in train_paths]\n        image_paths += train_paths + test_paths\n        \n    # Make training dataframe\n    df_train = pd.DataFrame(image_paths, columns=[\"is_valid\", \"filename\", \"primary_label\", \"img_path\"])\n    df_train[\"audio_path\"] = CFG['base_path'] + \"train_audio/\" + df_train.primary_label + \"/\" + df_train.filename\n    # Merge with meta data to add secondary_labels\n    df_train = df_train.merge(df_meta, on=[\"primary_label\", \"filename\"])\n    # Trans str to list\n    df_train[\"labels_name\"] = df_train.secondary_labels.map(lambda x: ast.literal_eval(x))\n    df_train[\"labels_name\"] = df_train[[\"primary_label\",\"labels_name\"]].apply(lambda x: [x[0]]+x[1], axis=1)\n    # Trans name to label\n    df_train[\"labels\"]      = df_train.labels_name.apply(lambda x: trans2label(x))\n    return df_train\n\ndef make_train_df_other_birds(df, n):\n    select_num  = df.file_num.min()\n    other_birds = []\n    for b, p in zip(df.bird, df.path):\n        paths = os.listdir(p)\n        train_paths  = random.sample(paths, k=select_num)\n        train_paths  = [[0, pi[:pi.find(\".ogg\")+4], b, p + pi] for pi in train_paths]\n        other_birds += train_paths\n\n    df_other_birds = pd.DataFrame(other_birds, columns=[\"is_valid\", \"filename\", \"primary_label\", \"img_path\"])\n    df_other_birds = df_other_birds.sample(CFG[\"n_sample\"][n]).reset_index(drop=True)\n    df_other_birds[\"audio_path\"]  = CFG['base_path'] + \"train_audio/\" + df_other_birds.primary_label + \"/\" + df_other_birds.filename\n    # Merge with meta data to add secondary_labels\n    df_other_birds = df_other_birds.merge(df_meta, on=[\"primary_label\", \"filename\"])\n    # Trans str to list\n    df_other_birds[\"labels_name\"] = df_other_birds.secondary_labels.map(lambda x: ast.literal_eval(x))\n    df_other_birds[\"labels_name\"] = df_other_birds[[\"primary_label\",\"labels_name\"]].apply(lambda x: [x[0]]+x[1], axis=1)\n    # Trans name to label\n    df_other_birds[\"labels\"]      = df_other_birds.labels_name.apply(lambda x: trans2label(x))\n    return df_other_birds","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:06.230657Z","iopub.execute_input":"2022-05-07T08:01:06.231201Z","iopub.status.idle":"2022-05-07T08:01:06.251234Z","shell.execute_reply.started":"2022-05-07T08:01:06.231164Z","shell.execute_reply":"2022-05-07T08:01:06.250508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"# No. of files\ndf_files_scoredbird_firstlast    = get_files(CFG[\"img_fl_path\"])\ndf_files_no_scoredbird_firstlast = get_files(CFG[\"img_fl_path\"], only_scored_bird=False)\ndf_files_all_audio = get_files(CFG[\"img_all_path\"])\n\n# Get exclusion files\nexclusion_files = get_exclusion_files(df_files_all_audio)\nexclusion_files[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:06.253608Z","iopub.execute_input":"2022-05-07T08:01:06.253873Z","iopub.status.idle":"2022-05-07T08:01:21.744398Z","shell.execute_reply.started":"2022-05-07T08:01:06.25384Z","shell.execute_reply":"2022-05-07T08:01:21.743673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(df_files_scoredbird_firstlast.head(2))\ndisplay(df_files_no_scoredbird_firstlast.head(2))\ndisplay(df_files_all_audio.head(2))\ndf_files_all_audio.file_num.hist(bins=20)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:22.368809Z","iopub.execute_input":"2022-05-07T08:01:22.369262Z","iopub.status.idle":"2022-05-07T08:01:22.646282Z","shell.execute_reply.started":"2022-05-07T08:01:22.369225Z","shell.execute_reply":"2022-05-07T08:01:22.645604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_meta = pd.read_csv(\"../input/birdclef-2022/train_metadata.csv\")\ndf_meta = df_meta[[\"primary_label\",\"secondary_labels\",\"rating\",\"filename\"]]\ndf_meta[\"filename\"] = df_meta.filename.apply(lambda x: x[x.find(\"/\")+1:])\n\nprint(df_meta.shape)\ndf_meta.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:26.415818Z","iopub.execute_input":"2022-05-07T08:01:26.416074Z","iopub.status.idle":"2022-05-07T08:01:26.542538Z","shell.execute_reply.started":"2022-05-07T08:01:26.416045Z","shell.execute_reply":"2022-05-07T08:01:26.541863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b = 0\nn = 0\np = df_files_scoredbird_firstlast.path[b] + os.listdir(df_files_scoredbird_firstlast.path[b])[n]\nprint(get_img(p).shape)\nplt.imshow(get_img(p))","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:30.46084Z","iopub.execute_input":"2022-05-07T08:01:30.461273Z","iopub.status.idle":"2022-05-07T08:01:30.775482Z","shell.execute_reply.started":"2022-05-07T08:01:30.461236Z","shell.execute_reply":"2022-05-07T08:01:30.77479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define model","metadata":{}},{"cell_type":"code","source":"# Save model files for inference\ndownload_path = snapshot_download(repo_id=\"facebook/wav2vec2-base-960h\")\nshutil.move(download_path, \"./wav2vec/\")","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:01:34.519976Z","iopub.execute_input":"2022-05-07T08:01:34.520344Z","iopub.status.idle":"2022-05-07T08:02:01.684043Z","shell.execute_reply.started":"2022-05-07T08:01:34.520306Z","shell.execute_reply":"2022-05-07T08:02:01.683351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataloader","metadata":{}},{"cell_type":"code","source":"class BirdCLEF_Dataset(Dataset):\n    \n    def __init__(self, df, transforms=None, output_label=True, is_train=True):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms   = transforms\n        self.output_label = output_label\n        self.is_train     = is_train\n        self.processor    = Wav2Vec2Processor.from_pretrained(\"./wav2vec/\")\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        img_path = self.df.loc[index].img_path\n        img_num  = int(img_path[-7:-4])  # Extract XXX from XXX.jpg\n        img      = get_img(img_path).copy()\n        waveform, sr = torchaudio.load(self.df.loc[index].audio_path)\n        waveform = waveform[0]\n        if len(waveform) < sr*5:\n            rep      = round(float(sr*5) / len(waveform))\n            waveform = waveform.repeat(int(rep)+1)\n            waveform = waveform[:sr*5]\n        else:\n            if self.is_train:\n                if -1 < img_path.find(\"000.jpg\"):\n                    waveform = waveform[:sr*5]  # First 5 seconds\n                else:\n                    waveform = waveform[-sr*5:] # Last 5 seconds\n            else:\n                sta = sr*5*img_num\n                end = sr*5*(img_num+1)\n                if len(waveform[sta:end]) == sr*5:\n                    waveform = waveform[sta:end]\n                else:\n                    waveform = waveform[-sr*5:]                \n        waveform = self.processor(waveform, sampling_rate=16000, return_tensors=\"pt\").input_values\n        # For BCE loss. The type should be float16 to match with model output\n        #y = np.eye(CFG[\"class_num\"], dtype=np.float16)[self.df.loc[index, \"labels\"][0]]\n        y = np.array([np.eye(CFG[\"class_num\"], dtype=np.float16)[l] for l in self.df.loc[index, \"labels\"]]).sum(0)\n        y = torch.from_numpy(y)\n        if self.transforms:\n            if self.is_train:\n                p = np.random.rand(1)\n                if p < 0.5:\n                    # Horizontal flip\n                    img      = img[:, ::-1]\n                    waveform = waveform.flip(0)\n            img = self.transforms(image=img)['image']\n        if self.output_label:\n            return img, waveform.reshape(-1), y\n        return img, waveform.reshape(-1)\n    \ndef get_train_transforms():\n    return Compose([\n        Resize(CFG['size'], CFG['size'], p=1.0),\n        OneOf([\n            Cutout(max_h_size=5, max_w_size=16),\n            CoarseDropout(max_holes=4),\n            ], p=0.5),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0)], p=1.0)\n\ndef get_valid_transforms():\n    return Compose([\n        Resize(CFG['size'], CFG['size'], p=1.0),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0)], p=1.0)\n\ndef prepare_dataloader(df, custom=True):\n    df = df.copy()\n    if custom:\n        train      = df[df.is_valid==0].reset_index(drop=True).copy()\n        valid      = df[df.is_valid==1].reset_index(drop=True).copy()\n        train_ds   = BirdCLEF_Dataset(train, transforms=get_train_transforms())\n        valid_ds   = BirdCLEF_Dataset(valid, transforms=get_valid_transforms(), is_train=False)\n        dataloader = DataLoaders.from_dsets(train_ds, valid_ds, bs=CFG['batch_size'])\n        if -1 < CFG[\"device\"].find(\"cuda\"):\n            dataloader = dataloader.cuda()\n    else:\n        dataloader = ImageDataLoaders.from_df(\n            df,\n            valid_col='is_valid',\n            seed=CFG[\"seed\"],\n            fn_col='path',\n            label_col=\"label\",\n            y_block=CategoryBlock,\n            bs=CFG['batch_size'],\n            n=CFG[\"n_data\"],\n            shuffle=True,\n            num_workers=CFG['num_workers'],\n            item_tfms=Resize(CFG['size']),\n            batch_tfms=setup_aug_tfms([Flip(), RandomErasing(), AffineCoordTfm()])\n        )\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:02:01.685593Z","iopub.execute_input":"2022-05-07T08:02:01.685788Z","iopub.status.idle":"2022-05-07T08:02:01.710078Z","shell.execute_reply.started":"2022-05-07T08:02:01.685764Z","shell.execute_reply":"2022-05-07T08:02:01.709457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Metrics and loss","metadata":{}},{"cell_type":"code","source":"def rmse(input, target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ndef self_f1_score(input, target):\n    input  = input.cpu().detach().numpy()\n    target = target.cpu().detach().numpy()\n    return f1_score(target, input>0.3, average=\"micro\")\n\n# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/213075\nclass BCEFocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, preds, targets):\n        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n        probas = torch.sigmoid(preds)\n        loss = targets * self.alpha * \\\n            (1. - probas)**self.gamma * bce_loss + \\\n            (1. - targets) * probas**self.gamma * bce_loss\n        loss = loss.mean()\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:02:01.711319Z","iopub.execute_input":"2022-05-07T08:02:01.711909Z","iopub.status.idle":"2022-05-07T08:02:01.72742Z","shell.execute_reply.started":"2022-05-07T08:02:01.711872Z","shell.execute_reply":"2022-05-07T08:02:01.72665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Models","metadata":{}},{"cell_type":"code","source":"class ImageAndAudioModel(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super().__init__()\n        self.img_model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n        self.audio_model = Wav2Vec2ForCTC.from_pretrained(\"./wav2vec/\") #.to(CFG[\"device\"])\n        num_features = self.img_model.num_features\n        self.flatten = nn.Flatten()\n        self.linear1 = nn.Linear(499*32, 1024)\n        self.linear2 = nn.Linear(num_features+1024, 127)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x, w):\n        x1 = self.img_model(x)\n        x2 = self.audio_model(w).logits\n        x2 = self.flatten(x2)\n        x2 = self.linear1(x2)\n        out = torch.cat((x1, x2), 1)\n        out = self.dropout(out)\n        out = self.linear2(out)\n        return out\n\nclass ImageAndAudioModelForScoredBird(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.pre_model = ImageAndAudioModel(CFG[\"model\"], pretrained=False)\n        self.pre_model.load_state_dict(torch.load(CFG['pretrain']))\n        self.linear    = nn.Linear(127, CFG[\"class_num\"])\n\n    def forward(self, x, w):\n        out = self.pre_model(x, w)\n        out = self.linear(out)\n        return out\n    \ndef get_learner(df):\n    dataloader = prepare_dataloader(df)\n    model   = ImageAndAudioModelForScoredBird()\n    learner = Learner(\n        dataloader,\n        model,\n        loss_func=BCEFocalLoss(),\n        metrics=AccumMetric(self_f1_score)).to_fp16()\n    return learner","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:02:01.729306Z","iopub.execute_input":"2022-05-07T08:02:01.729839Z","iopub.status.idle":"2022-05-07T08:02:01.743844Z","shell.execute_reply.started":"2022-05-07T08:02:01.729695Z","shell.execute_reply":"2022-05-07T08:02:01.742989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"for i in range(CFG[\"fold\"]):\n    df_train        = make_train_df(df_files_scoredbird_firstlast, i, 1)\n    df_train_others = make_train_df_other_birds(df_files_no_scoredbird_firstlast, i)\n    df_valid = make_train_df(df_files_all_audio,  i, 0, exclusion_files)\n    df_train = pd.concat([df_train, df_train_others, df_valid]).reset_index(drop=True)\n    print(df_train[df_train.is_valid==0].shape, df_train[df_train.is_valid==1].shape)\n\n    learn = get_learner(df_train)\n    learn.fit_one_cycle(\n        CFG[\"epochs\"],\n        CFG[\"lr\"],\n        cbs=[SaveModelCallback(monitor='self_f1_score',\n                               comp=np.greater),\n             EarlyStoppingCallback(monitor='self_f1_score',\n                                   comp=np.greater,\n                                   patience=CFG['early_stopping'])]\n    )\n    shutil.move(\"./models/model.pth\", f\"./models/{CFG['save_name']}_fold{i}.pth\")\n    \n    del learn\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-07T08:02:01.745449Z","iopub.execute_input":"2022-05-07T08:02:01.74571Z","iopub.status.idle":"2022-05-07T08:02:59.713432Z","shell.execute_reply.started":"2022-05-07T08:02:01.745676Z","shell.execute_reply":"2022-05-07T08:02:59.712Z"},"trusted":true},"execution_count":null,"outputs":[]}]}