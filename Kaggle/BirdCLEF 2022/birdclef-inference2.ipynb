{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa146a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:33:26.298320Z",
     "iopub.status.busy": "2022-05-23T10:33:26.297473Z",
     "iopub.status.idle": "2022-05-23T10:33:55.266062Z",
     "shell.execute_reply": "2022-05-23T10:33:55.265331Z",
     "shell.execute_reply.started": "2022-05-23T01:02:22.388581Z"
    },
    "papermill": {
     "duration": 29.004569,
     "end_time": "2022-05-23T10:33:55.266240",
     "exception": false,
     "start_time": "2022-05-23T10:33:26.261671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/noisereduce-2-0-0/noisereduce-2.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from noisereduce==2.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from noisereduce==2.0.0) (4.62.3)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from noisereduce==2.0.0) (1.7.3)\r\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (from noisereduce==2.0.0) (0.9.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from noisereduce==2.0.0) (1.20.3)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from noisereduce==2.0.0) (3.5.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (1.0.1)\r\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (0.2.2)\r\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (0.10.3.post1)\r\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (0.54.1)\r\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (5.1.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (21.3)\r\n",
      "Requirement already satisfied: audioread>=2.1.5 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (2.1.9)\r\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==2.0.0) (1.6.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==2.0.0) (3.0.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==2.0.0) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==2.0.0) (0.11.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==2.0.0) (8.2.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==2.0.0) (1.3.2)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==2.0.0) (4.28.4)\r\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.45.1->librosa->noisereduce==2.0.0) (0.37.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.45.1->librosa->noisereduce==2.0.0) (59.5.0)\r\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa->noisereduce==2.0.0) (1.4.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa->noisereduce==2.0.0) (2.26.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->noisereduce==2.0.0) (1.16.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->librosa->noisereduce==2.0.0) (3.0.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa->noisereduce==2.0.0) (1.15.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce==2.0.0) (2.21)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce==2.0.0) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce==2.0.0) (3.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce==2.0.0) (2.0.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce==2.0.0) (1.26.7)\r\n",
      "Installing collected packages: noisereduce\r\n",
      "Successfully installed noisereduce-2.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "!pip install ../input/noisereduce-2-0-0/noisereduce-2.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e369cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:33:55.341731Z",
     "iopub.status.busy": "2022-05-23T10:33:55.337786Z",
     "iopub.status.idle": "2022-05-23T10:34:03.036305Z",
     "shell.execute_reply": "2022-05-23T10:34:03.037005Z",
     "shell.execute_reply.started": "2022-05-23T01:02:50.749264Z"
    },
    "papermill": {
     "duration": 7.73843,
     "end_time": "2022-05-23T10:34:03.037232",
     "exception": false,
     "start_time": "2022-05-23T10:33:55.298802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "import torchaudio\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import noisereduce as nr\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from PIL import Image, ImageDraw\n",
    "from glob import glob as glob_file\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.core.display import Video, display\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, StratifiedKFold\n",
    "\n",
    "import timm\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torchvision import models, transforms\n",
    "from fastai.vision.all import *\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2FeatureExtractor\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize,\n",
    "    Flip, HorizontalFlip, VerticalFlip, CenterCrop, RandomResizedCrop,\n",
    "    Rotate, ShiftScaleRotate, RandomRotate90, Transpose,\n",
    "    RGBShift, ChannelShuffle, HueSaturationValue, RandomBrightnessContrast,\n",
    "    Blur, MotionBlur, MedianBlur, GaussNoise, Cutout, CoarseDropout\n",
    ")\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option(\"max_columns\", 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4091dc5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:03.127043Z",
     "iopub.status.busy": "2022-05-23T10:34:03.126239Z",
     "iopub.status.idle": "2022-05-23T10:34:03.146587Z",
     "shell.execute_reply": "2022-05-23T10:34:03.147238Z",
     "shell.execute_reply.started": "2022-05-23T01:26:02.323431Z"
    },
    "papermill": {
     "duration": 0.069154,
     "end_time": "2022-05-23T10:34:03.147457",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.078303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'device': 'cuda:0',\n",
       " 'base_path': '../input/birdclef-2022/',\n",
       " 'img_path': './test_images',\n",
       " 'output_path': './',\n",
       " 'thres_long': -1,\n",
       " 'thres_short': 0.1,\n",
       " 'long_model': ['swin_large_patch4_window7_224',\n",
       "  224,\n",
       "  21,\n",
       "  '../input/birdclef-trained-multi-label-long-models/models/birdclef_swin_long_fold0.pth'],\n",
       " 'classifier': ['swin_large_patch4_window7_224',\n",
       "  224,\n",
       "  22,\n",
       "  '../input/birdclef-trained-multi-class-models-10sec/models/birdclef_swin_multiclass_n300_fold0.pth'],\n",
       " 'binary_model': [['swin_large_patch4_window7_224',\n",
       "   224,\n",
       "   21,\n",
       "   '../input/birdclef-trained-multi-label-models-10sec/models/birdclef_swin_10sec_fold0.pth']],\n",
       " 'wav2vec': '../input/birdclef-trained-multi-class-models-10sec/wav2vec/',\n",
       " 'valid_pct': 0.3,\n",
       " 'batch_size': 12,\n",
       " 'lr': 0.0001,\n",
       " 'tta': 5,\n",
       " 'num_workers': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG = {\n",
    "    \"seed\"        : 42,\n",
    "    'device'      : \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"base_path\"   : \"../input/birdclef-2022/\",\n",
    "    \"img_path\"    : \"./test_images\",\n",
    "    \"output_path\" : './',\n",
    "    \"thres_long\"  : -1,\n",
    "    \"thres_short\" : 0.1,\n",
    "    \"long_model\"  : [\n",
    "        \"swin_large_patch4_window7_224\",\n",
    "        224,\n",
    "        21,\n",
    "        \"../input/birdclef-trained-multi-label-long-models/models/birdclef_swin_long_fold0.pth\"\n",
    "    ],\n",
    "    \"classifier\"  : [\n",
    "        \"swin_large_patch4_window7_224\",\n",
    "        224,\n",
    "        22,\n",
    "        \"../input/birdclef-trained-multi-class-models-10sec/models/birdclef_swin_multiclass_n300_fold0.pth\"\n",
    "    ],\n",
    "    \"binary_model\": [\n",
    "        [\"swin_large_patch4_window7_224\",\n",
    "         224,\n",
    "         21,\n",
    "         \"../input/birdclef-trained-multi-label-models-10sec/models/birdclef_swin_10sec_fold0.pth\"]\n",
    "    ],\n",
    "    \"wav2vec\"     : \"../input/birdclef-trained-multi-class-models-10sec/wav2vec/\",\n",
    "    \"valid_pct\"   : 0.3,\n",
    "    \"batch_size\"  : 12,\n",
    "    \"lr\"          : 1e-4,\n",
    "    \"tta\"         : 5,\n",
    "    \"num_workers\" : 4\n",
    "}\n",
    "\n",
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf723e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:03.238122Z",
     "iopub.status.busy": "2022-05-23T10:34:03.237300Z",
     "iopub.status.idle": "2022-05-23T10:34:03.248017Z",
     "shell.execute_reply": "2022-05-23T10:34:03.251314Z",
     "shell.execute_reply.started": "2022-05-23T01:02:58.356036Z"
    },
    "papermill": {
     "duration": 0.05857,
     "end_time": "2022-05-23T10:34:03.251546",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.192976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "def seed_everything(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d30edd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:03.357171Z",
     "iopub.status.busy": "2022-05-23T10:34:03.356313Z",
     "iopub.status.idle": "2022-05-23T10:34:03.383431Z",
     "shell.execute_reply": "2022-05-23T10:34:03.382708Z",
     "shell.execute_reply.started": "2022-05-23T01:02:58.370097Z"
    },
    "papermill": {
     "duration": 0.080607,
     "end_time": "2022-05-23T10:34:03.383585",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.302978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scored bird names\n",
    "scored_birds = pd.read_json(f\"{CFG['base_path']}scored_birds.json\").values.flatten().tolist()\n",
    "bird2label   = {}\n",
    "for i, b in enumerate(scored_birds):\n",
    "    bird2label[b] = i\n",
    "    \n",
    "# Define labels for other cases\n",
    "label_other_birds = max(bird2label.values()) + 1\n",
    "label_no_birds    = label_other_birds + 1\n",
    "\n",
    "label_other_birds, label_no_birds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abfd69",
   "metadata": {
    "papermill": {
     "duration": 0.043952,
     "end_time": "2022-05-23T10:34:03.469290",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.425338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Spectgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3aa1078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:03.559336Z",
     "iopub.status.busy": "2022-05-23T10:34:03.558568Z",
     "iopub.status.idle": "2022-05-23T10:34:03.581762Z",
     "shell.execute_reply": "2022-05-23T10:34:03.582324Z",
     "shell.execute_reply.started": "2022-05-23T01:02:58.393085Z"
    },
    "papermill": {
     "duration": 0.070934,
     "end_time": "2022-05-23T10:34:03.582524",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.511590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>bird</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_akiapo_5</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_akiapo_10</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_akiapo_15</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            row_id                file_id    bird  end_time\n",
       "0   soundscape_1000170626_akiapo_5  soundscape_1000170626  akiapo         5\n",
       "1  soundscape_1000170626_akiapo_10  soundscape_1000170626  akiapo        10\n",
       "2  soundscape_1000170626_akiapo_15  soundscape_1000170626  akiapo        15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta = pd.read_csv(CFG[\"base_path\"] + \"test.csv\")\n",
    "test_meta.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a068c9e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:03.678738Z",
     "iopub.status.busy": "2022-05-23T10:34:03.677970Z",
     "iopub.status.idle": "2022-05-23T10:34:03.683587Z",
     "shell.execute_reply": "2022-05-23T10:34:03.684572Z",
     "shell.execute_reply.started": "2022-05-23T01:02:58.414424Z"
    },
    "papermill": {
     "duration": 0.059584,
     "end_time": "2022-05-23T10:34:03.684748",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.625164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@torch.no_grad()\n",
    "def create_spectrogram(\n",
    "    fname,\n",
    "    reduce_noise: bool = False,\n",
    "    frame_length: int = 5,\n",
    "    channel: int = 0,\n",
    "    device = \"cpu\"\n",
    ") -> list:\n",
    "    waveform, sample_rate = torchaudio.load(fname)\n",
    "    transform = torchaudio.transforms.Spectrogram(n_fft=1800, win_length=512).to(device)\n",
    "    if reduce_noise:\n",
    "        waveform = torch.tensor(nr.reduce_noise(\n",
    "            y=waveform,\n",
    "            sr=sample_rate,\n",
    "            win_length=transform.win_length,\n",
    "            use_tqdm=False,\n",
    "            n_jobs=2,\n",
    "        ))\n",
    "    nb = int(frame_length * sample_rate)\n",
    "    spectrograms = []\n",
    "    for i in range(ceil(waveform.size()[-1] / nb)):\n",
    "        frame = waveform[channel][i * nb:(i + 1) * nb]\n",
    "        if len(frame) < nb:\n",
    "            if i == 0:\n",
    "                rep = round(float(nb) / len(frame))\n",
    "                frame = frame.repeat(int(rep))\n",
    "            else:\n",
    "                frame = waveform[channel][-nb:]\n",
    "        sg = torch.log(transform(frame.to(device))).cpu()\n",
    "        spectrograms.append(np.nan_to_num(sg.numpy()))\n",
    "    return spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7332b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:03.780119Z",
     "iopub.status.busy": "2022-05-23T10:34:03.779384Z",
     "iopub.status.idle": "2022-05-23T10:34:03.782815Z",
     "shell.execute_reply": "2022-05-23T10:34:03.783986Z",
     "shell.execute_reply.started": "2022-05-23T01:02:58.427165Z"
    },
    "papermill": {
     "duration": 0.056178,
     "end_time": "2022-05-23T10:34:03.784153",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.727975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_extension = \".jpg\"\n",
    "\n",
    "def convert_and_export(\n",
    "    fn,\n",
    "    path_in,\n",
    "    path_out,\n",
    "    reduce_noise = False,\n",
    "    frame_length: int = 5,\n",
    "    device = \"cpu\"\n",
    ") -> list:\n",
    "    path_audio = os.path.join(path_in, fn)\n",
    "    sgs = create_spectrogram(\n",
    "        path_audio,\n",
    "        reduce_noise=reduce_noise,\n",
    "        frame_length=frame_length,\n",
    "        device=device\n",
    "    )\n",
    "    records = []\n",
    "    for i, sg in enumerate(sgs):\n",
    "        path_img = os.path.join(path_out, fn + f\".{i:03}\" + img_extension)\n",
    "        os.makedirs(os.path.dirname(path_img), exist_ok=True)\n",
    "        plt.imsave(path_img, sg, vmin=-70, vmax=20)\n",
    "        records.append({\"img_name\": os.path.basename(path_img), \"end_time\": (i + 1) * frame_length, \"file_id\": os.path.splitext(fn)[0]})\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b926a77f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:03.879661Z",
     "iopub.status.busy": "2022-05-23T10:34:03.878900Z",
     "iopub.status.idle": "2022-05-23T10:34:13.419510Z",
     "shell.execute_reply": "2022-05-23T10:34:13.420493Z",
     "shell.execute_reply.started": "2022-05-23T01:02:58.438294Z"
    },
    "papermill": {
     "duration": 9.593762,
     "end_time": "2022-05-23T10:34:13.420692",
     "exception": false,
     "start_time": "2022-05-23T10:34:03.826930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.17it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.33it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>end_time</th>\n",
       "      <th>file_id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782.ogg.000.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>soundscape_453028782</td>\n",
       "      <td>./test_images_short/soundscape_453028782.ogg.000.jpg</td>\n",
       "      <td>../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782.ogg.001.jpg</td>\n",
       "      <td>20</td>\n",
       "      <td>soundscape_453028782</td>\n",
       "      <td>./test_images_short/soundscape_453028782.ogg.001.jpg</td>\n",
       "      <td>../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782.ogg.002.jpg</td>\n",
       "      <td>30</td>\n",
       "      <td>soundscape_453028782</td>\n",
       "      <td>./test_images_short/soundscape_453028782.ogg.002.jpg</td>\n",
       "      <td>../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782.ogg.003.jpg</td>\n",
       "      <td>40</td>\n",
       "      <td>soundscape_453028782</td>\n",
       "      <td>./test_images_short/soundscape_453028782.ogg.003.jpg</td>\n",
       "      <td>../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782.ogg.004.jpg</td>\n",
       "      <td>50</td>\n",
       "      <td>soundscape_453028782</td>\n",
       "      <td>./test_images_short/soundscape_453028782.ogg.004.jpg</td>\n",
       "      <td>../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           img_name  end_time               file_id  \\\n",
       "0  soundscape_453028782.ogg.000.jpg        10  soundscape_453028782   \n",
       "1  soundscape_453028782.ogg.001.jpg        20  soundscape_453028782   \n",
       "2  soundscape_453028782.ogg.002.jpg        30  soundscape_453028782   \n",
       "3  soundscape_453028782.ogg.003.jpg        40  soundscape_453028782   \n",
       "4  soundscape_453028782.ogg.004.jpg        50  soundscape_453028782   \n",
       "\n",
       "                                               img_path  \\\n",
       "0  ./test_images_short/soundscape_453028782.ogg.000.jpg   \n",
       "1  ./test_images_short/soundscape_453028782.ogg.001.jpg   \n",
       "2  ./test_images_short/soundscape_453028782.ogg.002.jpg   \n",
       "3  ./test_images_short/soundscape_453028782.ogg.003.jpg   \n",
       "4  ./test_images_short/soundscape_453028782.ogg.004.jpg   \n",
       "\n",
       "                                                         audio_path  \n",
       "0  ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg  \n",
       "1  ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg  \n",
       "2  ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg  \n",
       "3  ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg  \n",
       "4  ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_convert_and_export = partial(\n",
    "    convert_and_export,\n",
    "    path_in=CFG[\"base_path\"] + \"test_soundscapes\",\n",
    "    path_out=\"test_images_short\",\n",
    "    reduce_noise=True,\n",
    "    frame_length=10,\n",
    "    device=CFG[\"device\"]\n",
    ")\n",
    "\n",
    "soundscapes = glob.glob(os.path.join(CFG[\"base_path\"], \"test_soundscapes\", \"*.ogg\"))\n",
    "soundscapes = list(map(os.path.basename, soundscapes))\n",
    "converted = []\n",
    "for batch in Parallel(n_jobs=3)(delayed(_convert_and_export)(fn) for fn in tqdm(soundscapes)):\n",
    "    converted += batch\n",
    "    \n",
    "df_test_short = pd.DataFrame(converted)\n",
    "df_test_short[\"img_path\"]   = CFG[\"img_path\"] + \"_short/\" + df_test_short.img_name\n",
    "df_test_short[\"audio_path\"] = CFG[\"base_path\"] + \"test_soundscapes/\" + df_test_short.file_id + \".ogg\"\n",
    "df_test_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b573a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T01:03:13.818531Z",
     "iopub.status.busy": "2022-05-23T01:03:13.817668Z",
     "iopub.status.idle": "2022-05-23T01:03:21.762114Z",
     "shell.execute_reply": "2022-05-23T01:03:21.761438Z",
     "shell.execute_reply.started": "2022-05-23T01:03:13.81848Z"
    },
    "papermill": {
     "duration": 0.03695,
     "end_time": "2022-05-23T10:34:13.500635",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.463685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "_convert_and_export = partial(\n",
    "    convert_and_export,\n",
    "    path_in=CFG[\"base_path\"] + \"test_soundscapes\",\n",
    "    path_out=\"test_images_long\",\n",
    "    reduce_noise=True,\n",
    "    frame_length=60,\n",
    "    device=CFG[\"device\"]\n",
    ")\n",
    "\n",
    "soundscapes = glob.glob(os.path.join(CFG[\"base_path\"], \"test_soundscapes\", \"*.ogg\"))\n",
    "soundscapes = list(map(os.path.basename, soundscapes))\n",
    "converted = []\n",
    "for batch in Parallel(n_jobs=3)(delayed(_convert_and_export)(fn) for fn in tqdm(soundscapes)):\n",
    "    converted += batch\n",
    "    \n",
    "df_test_long = pd.DataFrame(converted)\n",
    "df_test_long[\"img_path\"]   = CFG[\"img_path\"] + \"_long/\" + df_test_long.img_name\n",
    "df_test_long[\"audio_path\"] = CFG[\"base_path\"] + \"test_soundscapes/\" + df_test_long.file_id + \".ogg\"\n",
    "df_test_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea2163",
   "metadata": {
    "papermill": {
     "duration": 0.028227,
     "end_time": "2022-05-23T10:34:13.557409",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.529182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d424990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:13.634902Z",
     "iopub.status.busy": "2022-05-23T10:34:13.634076Z",
     "iopub.status.idle": "2022-05-23T10:34:13.636626Z",
     "shell.execute_reply": "2022-05-23T10:34:13.636041Z",
     "shell.execute_reply.started": "2022-05-23T01:03:31.900377Z"
    },
    "papermill": {
     "duration": 0.051054,
     "end_time": "2022-05-23T10:34:13.636741",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.585687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEF_Dataset(ImageDataLoaders):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        df,\n",
    "        transforms=None,\n",
    "        length=10,\n",
    "        class_num=22,\n",
    "        output_label=True,\n",
    "        get_primary=False,\n",
    "        is_binary=False\n",
    "    ):\n",
    "        super().__init__(device=\"cuda\")\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.processor    = Wav2Vec2Processor.from_pretrained(CFG[\"wav2vec\"])\n",
    "        self.transforms   = transforms\n",
    "        self.length       = length\n",
    "        self.class_num    = class_num\n",
    "        self.output_label = output_label\n",
    "        self.get_primary  = get_primary\n",
    "        self.is_binary    = is_binary\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        img_path = self.df.loc[index].img_path\n",
    "        img      = get_img(img_path).copy()\n",
    "        end_time = self.df.loc[index].end_time\n",
    "        waveform, sr = torchaudio.load(self.df.loc[index].audio_path)\n",
    "        waveform = waveform[0]\n",
    "        if len(waveform) < sr*self.length:\n",
    "            rep      = round(float(sr*self.length) / len(waveform))\n",
    "            waveform = waveform.repeat(int(rep)+1)\n",
    "            waveform = waveform[:sr*self.length]\n",
    "        else:\n",
    "            sta = sr*(end_time-self.length)\n",
    "            end = sr*end_time\n",
    "            if len(waveform[sta:end]) == sr*self.length:\n",
    "                waveform = waveform[sta:end]\n",
    "            else:\n",
    "                waveform = waveform[-sr*self.length:]\n",
    "        if self.length == 10:\n",
    "            waveform = waveform[::2]\n",
    "        elif self.length == 60:\n",
    "            waveform = waveform[::100]\n",
    "        waveform = self.processor(waveform, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        if self.is_binary:\n",
    "            y = torch.from_numpy(np.zeros(self.class_num, dtype=np.float16))\n",
    "        else:\n",
    "            y = torch.from_numpy(np.array([1]))\n",
    "        if self.get_primary:\n",
    "            primary_label = torch.from_numpy(np.array(self.df.loc[index].label))\n",
    "            return img, waveform.reshape(-1), primary_label, y\n",
    "        if self.output_label:\n",
    "            return img, waveform.reshape(-1), y\n",
    "        return img, waveform.reshape(-1)\n",
    "        \n",
    "def get_inference_transforms(size):\n",
    "    return Compose([\n",
    "        Resize(size, size, p=1.0),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0)], p=1.0)\n",
    "\n",
    "def prepare_dataloader(df, size, length, class_num, get_primary=False, is_binary=False):\n",
    "    test = df.copy()\n",
    "    dummy_ds   = BirdCLEF_Dataset(\n",
    "        test,\n",
    "        transforms=get_inference_transforms(size),\n",
    "        length=length,\n",
    "        class_num=class_num,\n",
    "        output_label=True,\n",
    "        get_primary=get_primary,\n",
    "        is_binary=is_binary\n",
    "    )\n",
    "    test_ds    = BirdCLEF_Dataset(\n",
    "        test,\n",
    "        transforms=get_inference_transforms(size),\n",
    "        length=length,\n",
    "        class_num=class_num,\n",
    "        output_label=True,\n",
    "        get_primary=get_primary,\n",
    "        is_binary=is_binary\n",
    "    )\n",
    "    dataloader = DataLoaders.from_dsets(dummy_ds, test_ds, bs=CFG[\"batch_size\"])\n",
    "    if -1 < CFG[\"device\"].find(\"cuda\"):\n",
    "        dataloader = dataloader.cuda()\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47921299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:13.700897Z",
     "iopub.status.busy": "2022-05-23T10:34:13.700235Z",
     "iopub.status.idle": "2022-05-23T10:34:13.703325Z",
     "shell.execute_reply": "2022-05-23T10:34:13.702898Z",
     "shell.execute_reply.started": "2022-05-23T01:03:32.725641Z"
    },
    "papermill": {
     "duration": 0.038565,
     "end_time": "2022-05-23T10:34:13.703460",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.664895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(input, target):\n",
    "    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n",
    "\n",
    "def self_f1_score(input, target):\n",
    "    input  = input.cpu().detach().numpy()\n",
    "    target = target.cpu().detach().numpy()\n",
    "    return f1_score(target, input>0.3, average=\"micro\")\n",
    "\n",
    "class BCEFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n",
    "        probas = torch.sigmoid(preds)\n",
    "        loss = targets * self.alpha * \\\n",
    "            (1. - probas)**self.gamma * bce_loss + \\\n",
    "            (1. - targets) * probas**self.gamma * bce_loss\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "450a2919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:13.778179Z",
     "iopub.status.busy": "2022-05-23T10:34:13.776650Z",
     "iopub.status.idle": "2022-05-23T10:34:13.778800Z",
     "shell.execute_reply": "2022-05-23T10:34:13.779184Z",
     "shell.execute_reply.started": "2022-05-23T01:10:39.119424Z"
    },
    "papermill": {
     "duration": 0.047592,
     "end_time": "2022-05-23T10:34:13.779311",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.731719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageAndAudioModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=False, hidden=499*32, out=127):\n",
    "        super().__init__()\n",
    "        self.img_model   = timm.create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        self.audio_model = Wav2Vec2ForCTC.from_pretrained(CFG[\"wav2vec\"])\n",
    "        num_features = self.img_model.num_features\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(hidden, 1024)\n",
    "        self.linear2 = nn.Linear(num_features+1024, out)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x, w):\n",
    "        x1 = self.img_model(x)\n",
    "        x2 = self.audio_model(w).logits\n",
    "        x2 = self.flatten(x2)\n",
    "        x2 = self.linear1(x2)\n",
    "        x  = torch.cat((x1, x2), 1)\n",
    "        x  = self.dropout(x)\n",
    "        out = self.linear2(x)\n",
    "        return out\n",
    "\n",
    "class ImageAndAudioModelForScoredBird(nn.Module):\n",
    "    def __init__(self, model_name, out=127, class_num=22):\n",
    "        super().__init__()\n",
    "        self.pre_model = ImageAndAudioModel(model_name, pretrained=False)\n",
    "        self.linear    = nn.Linear(out, class_num)\n",
    "\n",
    "    def forward(self, x, w):\n",
    "        x = self.pre_model(x, w)\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "class ImageAndAudioModelForScoredBird_Secondaly(nn.Module):\n",
    "    def __init__(self, model_name, out=127, class_num=22):\n",
    "        super().__init__()\n",
    "        self.pre_model = ImageAndAudioModel(model_name, pretrained=False)\n",
    "        self.linear    = nn.Linear(out+1, class_num)\n",
    "\n",
    "    def forward(self, x, w, p):\n",
    "        x = self.pre_model(x, w)\n",
    "        p = p.view(-1, 1)\n",
    "        x = torch.cat((x, p), 1)\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "        \n",
    "def get_learner(\n",
    "    df,\n",
    "    model_name,\n",
    "    size,\n",
    "    path,\n",
    "    length,\n",
    "    class_num,\n",
    "    get_primary=False,\n",
    "    is_binary=False,\n",
    "    is_long=False\n",
    "):\n",
    "    dataloader = prepare_dataloader(\n",
    "        df,\n",
    "        size,\n",
    "        length,\n",
    "        class_num,\n",
    "        get_primary=get_primary,\n",
    "        is_binary=is_binary\n",
    "    )\n",
    "    if is_long:\n",
    "        model  = ImageAndAudioModel(model_name, hidden=59*32, out=class_num)\n",
    "        loss   = BCEFocalLoss()\n",
    "        metric = AccumMetric(self_f1_score)\n",
    "    else:\n",
    "        if get_primary:\n",
    "            model  = ImageAndAudioModelForScoredBird_Secondaly(model_name, class_num=class_num)\n",
    "            loss   = BCEWithLogitsLossFlat()\n",
    "            metric = rmse\n",
    "        else:\n",
    "            #model  = ImageAndAudioModelForScoredBird(model_name, class_num=class_num)\n",
    "            #loss   = CrossEntropyLossFlat()\n",
    "            #metric = F1Score(average='micro')\n",
    "            model  = ImageAndAudioModel(model_name, out=class_num)\n",
    "            loss   = BCEFocalLoss()\n",
    "            metric = AccumMetric(self_f1_score)\n",
    "\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    learner = Learner(\n",
    "        dataloader,\n",
    "        model,\n",
    "        loss_func=loss,\n",
    "        metrics=metric).to_fp16()\n",
    "    return learner, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6b332",
   "metadata": {
    "papermill": {
     "duration": 0.02917,
     "end_time": "2022-05-23T10:34:13.836918",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.807748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference\n",
    "Inference to identify a primary label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78bec2e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:13.899017Z",
     "iopub.status.busy": "2022-05-23T10:34:13.898390Z",
     "iopub.status.idle": "2022-05-23T10:34:13.901188Z",
     "shell.execute_reply": "2022-05-23T10:34:13.900776Z",
     "shell.execute_reply.started": "2022-05-23T01:03:46.450391Z"
    },
    "papermill": {
     "duration": 0.034666,
     "end_time": "2022-05-23T10:34:13.901302",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.866636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_name = CFG[\"classifier\"][0]\n",
    "#size       = CFG[\"classifier\"][1]\n",
    "#class_num  = CFG[\"classifier\"][2]\n",
    "#path       = CFG[\"classifier\"][3]\n",
    "#learn, data_loader = get_learner(df_test_short, model_name, size, path, 10, class_num, get_primary=False)\n",
    "#res, _ = learn.get_preds()\n",
    "#res    = res.detach().numpy()\n",
    "\n",
    "#del learn, data_loader\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1882920b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:13.961503Z",
     "iopub.status.busy": "2022-05-23T10:34:13.960664Z",
     "iopub.status.idle": "2022-05-23T10:34:13.962989Z",
     "shell.execute_reply": "2022-05-23T10:34:13.962499Z",
     "shell.execute_reply.started": "2022-05-23T01:03:48.996081Z"
    },
    "papermill": {
     "duration": 0.033563,
     "end_time": "2022-05-23T10:34:13.963090",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.929527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add predicted primary label\n",
    "#df_test_short[\"label\"] = np.argmax(res,1)\n",
    "#df_test_short.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6af125",
   "metadata": {
    "papermill": {
     "duration": 0.028384,
     "end_time": "2022-05-23T10:34:14.019917",
     "exception": false,
     "start_time": "2022-05-23T10:34:13.991533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Inference to identify secondaly labels with long audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08684a75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T01:08:26.607225Z",
     "iopub.status.busy": "2022-05-23T01:08:26.606967Z",
     "iopub.status.idle": "2022-05-23T01:08:47.233454Z",
     "shell.execute_reply": "2022-05-23T01:08:47.232714Z",
     "shell.execute_reply.started": "2022-05-23T01:08:26.607199Z"
    },
    "papermill": {
     "duration": 0.02806,
     "end_time": "2022-05-23T10:34:14.077076",
     "exception": false,
     "start_time": "2022-05-23T10:34:14.049016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "model_name = CFG[\"long_model\"][0]\n",
    "size       = CFG[\"long_model\"][1]\n",
    "class_num  = CFG[\"long_model\"][2]\n",
    "path       = CFG[\"long_model\"][3]\n",
    "learn, data_loader = get_learner(df_test_long, model_name, size, path, 60, class_num, is_long=True, is_binary=True)\n",
    "res, _ = learn.get_preds()\n",
    "res    = torch.sigmoid(res).detach().numpy()\n",
    "\n",
    "del learn, data_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8106a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T01:08:56.605563Z",
     "iopub.status.busy": "2022-05-23T01:08:56.605303Z",
     "iopub.status.idle": "2022-05-23T01:08:56.635058Z",
     "shell.execute_reply": "2022-05-23T01:08:56.634242Z",
     "shell.execute_reply.started": "2022-05-23T01:08:56.605533Z"
    },
    "papermill": {
     "duration": 0.028255,
     "end_time": "2022-05-23T10:34:14.133892",
     "exception": false,
     "start_time": "2022-05-23T10:34:14.105637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Add predicted primary label\n",
    "#df_long_labeled = pd.DataFrame(res, columns=scored_birds + [\"others\"])\n",
    "df_long_labeled = pd.DataFrame(res, columns=scored_birds)\n",
    "df_test_long = df_test_long.join(df_long_labeled)\n",
    "df_test_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20105d",
   "metadata": {
    "papermill": {
     "duration": 0.028043,
     "end_time": "2022-05-23T10:34:14.190035",
     "exception": false,
     "start_time": "2022-05-23T10:34:14.161992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Inference to identify secondaly labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b69017b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:14.252912Z",
     "iopub.status.busy": "2022-05-23T10:34:14.252198Z",
     "iopub.status.idle": "2022-05-23T10:34:49.368719Z",
     "shell.execute_reply": "2022-05-23T10:34:49.368208Z",
     "shell.execute_reply.started": "2022-05-23T01:16:40.064663Z"
    },
    "papermill": {
     "duration": 35.150362,
     "end_time": "2022-05-23T10:34:49.368847",
     "exception": false,
     "start_time": "2022-05-23T10:34:14.218485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/birdclef-trained-multi-label-models-10sec/models/birdclef_swin_10sec_fold0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at ../input/birdclef-trained-multi-class-models-10sec/wav2vec/ and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_res = []\n",
    "for (model_name, size, class_num, path) in CFG[\"binary_model\"]:\n",
    "    print(path)\n",
    "    learn, data_loader = get_learner(df_test_short, model_name, size, path, 10, class_num, get_primary=False, is_binary=True)\n",
    "    res, _ = learn.get_preds()\n",
    "    res    = torch.sigmoid(res).detach().numpy()\n",
    "    all_res.append(res)\n",
    "    \n",
    "    del learn, data_loader\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f698c307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:49.434549Z",
     "iopub.status.busy": "2022-05-23T10:34:49.433803Z",
     "iopub.status.idle": "2022-05-23T10:34:49.435830Z",
     "shell.execute_reply": "2022-05-23T10:34:49.436200Z",
     "shell.execute_reply.started": "2022-05-23T01:20:32.744815Z"
    },
    "papermill": {
     "duration": 0.036373,
     "end_time": "2022-05-23T10:34:49.436326",
     "exception": false,
     "start_time": "2022-05-23T10:34:49.399953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensemble (simple blending)\n",
    "res = np.array(all_res).mean(0)\n",
    "#res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89634337",
   "metadata": {
    "papermill": {
     "duration": 0.029987,
     "end_time": "2022-05-23T10:34:49.496411",
     "exception": false,
     "start_time": "2022-05-23T10:34:49.466424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d064bb7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:49.564564Z",
     "iopub.status.busy": "2022-05-23T10:34:49.564003Z",
     "iopub.status.idle": "2022-05-23T10:34:49.567621Z",
     "shell.execute_reply": "2022-05-23T10:34:49.567175Z",
     "shell.execute_reply.started": "2022-05-23T01:17:02.003422Z"
    },
    "papermill": {
     "duration": 0.041538,
     "end_time": "2022-05-23T10:34:49.567729",
     "exception": false,
     "start_time": "2022-05-23T10:34:49.526191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_processing(df):\n",
    "    df = df.copy()\n",
    "    df.end_time = df.end_time.astype(int)\n",
    "    \n",
    "    submission_post = pd.DataFrame()\n",
    "    for f in df.file_name.unique():\n",
    "        df_f = df[df.file_name==f]\n",
    "        for b in df.bird_name.unique():\n",
    "            df_post = df_f[df_f.bird_name==b].copy()\n",
    "            df_post = df_post.sort_values(\"end_time\").reset_index(drop=True)\n",
    "            # Replace to True*3 or False*3\n",
    "            target_str = str(list(df_post.target))\n",
    "            target_str = target_str.replace(\"True, False, True\",  \"True, True, True\")\n",
    "            #target_str = target_str.replace(\"False, True, False\", \"False, False, False\")\n",
    "            # Change type from str to bool\n",
    "            replaced_target = target_str[1:-1].split(\",\")\n",
    "            replaced_target = [True if rt.replace(\" \",\"\")==\"True\" else False for rt in replaced_target]\n",
    "            df_post.target  = replaced_target\n",
    "            submission_post = submission_post.append(df_post)\n",
    "            \n",
    "    submission_post.end_time = submission_post.end_time.astype(str)\n",
    "    return submission_post.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8cda5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:49.631596Z",
     "iopub.status.busy": "2022-05-23T10:34:49.631043Z",
     "iopub.status.idle": "2022-05-23T10:34:49.637277Z",
     "shell.execute_reply": "2022-05-23T10:34:49.636881Z",
     "shell.execute_reply.started": "2022-05-23T01:17:04.821061Z"
    },
    "papermill": {
     "duration": 0.039825,
     "end_time": "2022-05-23T10:34:49.637417",
     "exception": false,
     "start_time": "2022-05-23T10:34:49.597592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scored_birds = pd.read_json(f\"{CFG['base_path']}scored_birds.json\").values.flatten().tolist()\n",
    "label2bird = {}\n",
    "for i, bird in enumerate(scored_birds):\n",
    "    label2bird[i] = bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe596f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:49.728485Z",
     "iopub.status.busy": "2022-05-23T10:34:49.727865Z",
     "iopub.status.idle": "2022-05-23T10:34:49.739606Z",
     "shell.execute_reply": "2022-05-23T10:34:49.740180Z",
     "shell.execute_reply.started": "2022-05-23T01:26:59.536332Z"
    },
    "papermill": {
     "duration": 0.072513,
     "end_time": "2022-05-23T10:34:49.740334",
     "exception": false,
     "start_time": "2022-05-23T10:34:49.667821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782_aniani_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782_apapan_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782_barpet_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782_crehon_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          row_id  target\n",
       "0  soundscape_453028782_akiapo_5   False\n",
       "1  soundscape_453028782_aniani_5   False\n",
       "2  soundscape_453028782_apapan_5    True\n",
       "3  soundscape_453028782_barpet_5   False\n",
       "4  soundscape_453028782_crehon_5   False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "for fi, et, r in zip(df_test_short.file_id, df_test_short.end_time, res):\n",
    "    #r = r[0]\n",
    "    #long_res = df_test_long[(df_test_long.file_id==fi)&(int(et)<=df_test_long.end_time)].head(1)\n",
    "    #bird_candidates_long  = np.where(np.array(long_res.iloc[:, 5:]) > CFG['thres_long'])[1]\n",
    "    #bird_candidates_short = np.where(r > CFG['thres_short'])[0]\n",
    "    #bird_candidates = [b for b in bird_candidates_short if b in bird_candidates_long]\n",
    "    bird_candidates = list(np.where(r > CFG['thres_short'])[0])\n",
    "    bird_label = [True if label in bird_candidates else False for label, bird in label2bird.items()]\n",
    "\n",
    "    df_submit_a  = pd.DataFrame({\"file_name\": fi,\n",
    "                                 \"end_time\" : et-5,\n",
    "                                 \"bird_name\": label2bird.values(),\n",
    "                                 \"target\"   : bird_label})\n",
    "    df_submit_b  = pd.DataFrame({\"file_name\": fi,\n",
    "                                 \"end_time\" : et,\n",
    "                                 \"bird_name\": label2bird.values(),\n",
    "                                 \"target\"   : bird_label})\n",
    "\n",
    "    df_submit  = pd.concat([df_submit_a, df_submit_b])\n",
    "    submission = submission.append(df_submit)\n",
    "    \n",
    "submission = submission.reset_index(drop=True)\n",
    "#submission = post_processing(submission)\n",
    "submission[\"row_id\"] = submission.file_name + \"_\" + submission.bird_name + \"_\" + submission.end_time.astype(str)\n",
    "submission = submission[[\"row_id\", \"target\"]]\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6a74132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:49.811018Z",
     "iopub.status.busy": "2022-05-23T10:34:49.810221Z",
     "iopub.status.idle": "2022-05-23T10:34:50.510000Z",
     "shell.execute_reply": "2022-05-23T10:34:50.509206Z",
     "shell.execute_reply.started": "2022-05-21T15:21:32.509922Z"
    },
    "papermill": {
     "duration": 0.737232,
     "end_time": "2022-05-23T10:34:50.510129",
     "exception": false,
     "start_time": "2022-05-23T10:34:49.772897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf ./test_images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2899b096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T10:34:50.577117Z",
     "iopub.status.busy": "2022-05-23T10:34:50.574394Z",
     "iopub.status.idle": "2022-05-23T10:34:50.583280Z",
     "shell.execute_reply": "2022-05-23T10:34:50.582869Z",
     "shell.execute_reply.started": "2022-05-21T15:21:37.754703Z"
    },
    "papermill": {
     "duration": 0.042161,
     "end_time": "2022-05-23T10:34:50.583415",
     "exception": false,
     "start_time": "2022-05-23T10:34:50.541254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 95.420934,
   "end_time": "2022-05-23T10:34:53.348612",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-23T10:33:17.927678",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
