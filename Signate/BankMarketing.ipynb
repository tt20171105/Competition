{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import LinearSVC, libsvm, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# 自作の説明変数を作成する関数\n",
    "def create_explain_variable(df):\n",
    "    df_add_var = copy.deepcopy(df)\n",
    "    # キャンペーンの丸め\n",
    "    df_add_var.loc[20 < df_add_var.campaign, \"campaign\"] = 21\n",
    "    # duration の対数変換\n",
    "    df_add_var.loc[df_add_var.duration==0, \"duration\"] = 1e-7\n",
    "    df_add_var.duration = df_add_var.duration.apply(lambda x: np.log(x))\n",
    "    # 月+日\n",
    "    dict_month = {\"apr\":4,\"may\":5,\"jun\":6,\"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12,\"jan\":1,\"feb\":2,\"mar\":3}\n",
    "    df_add_var.month = df_add_var.month.apply(lambda x: dict_month[x]).astype(str)\n",
    "    df_add_var[\"md\"] = (df_add_var.month + df_add_var.day.apply(lambda x: \"%02d\" % x)).astype(int)\n",
    "    df_add_var.month = df_add_var.month.astype(int)\n",
    "    # 月＋日を365日に変換\n",
    "    end_days = [132,229,332,431,532,631,732,832,931,1032,1131,1232]\n",
    "    all_days, ch_days = [], {}\n",
    "    for idx, d in enumerate(end_days):\n",
    "        all_days += list(np.arange((idx+1)*100+1,d))\n",
    "    for idx, d in enumerate(all_days):\n",
    "        ch_days[d] = idx+1\n",
    "    df_add_var[\"md_num\"]   = df_add_var.md.apply(lambda x: ch_days[x])\n",
    "    # 7で割った余りを曜日として扱う\n",
    "    df_add_var[\"md_num_r\"] = df_add_var.md_num.apply(lambda x: x % 7)\n",
    "    # 21歳から働き始めたとみなして、平均年間貯蓄額を算出（21歳以下、学生は0とみなす）\n",
    "    df_add_var[\"mean_balance\"] = df_add_var.balance / (df_add_var.age - 21)\n",
    "    df_add_var.loc[(df_add_var.age <= 21)|(df_add_var.job==\"student\"), \"mean_balance\"] = 0\n",
    "    # 平均接触回数\n",
    "    df_add_var[\"mean_meet_num\"] = df_add_var.previous / df_add_var.pdays\n",
    "    df_add_var.loc[df_add_var.pdays==-1, \"mean_meet_num\"] = 0\n",
    "    return df_add_var\n",
    "    \n",
    "def add_col_high_rate(df_train, df_test):\n",
    "    # 可能性の高そうな職業などについている人に点数をつける\n",
    "    def calc_high_rate(df, col, threshold=0.12):\n",
    "        y_cnt  = df.groupby(col, as_index=False).y.count()\n",
    "        y_sum  = df.groupby(col, as_index=False).y.sum()\n",
    "        y_rate = pd.merge(y_sum, y_cnt, on=col, suffixes=(\"_sum\",\"_cnt\"))\n",
    "        y_rate[\"rate\"] = y_rate.y_sum / y_rate.y_cnt\n",
    "        return list(y_rate.query(\"@threshold < rate\")[col])\n",
    "    dict_high_rate = {}\n",
    "    dict_high_rate[\"job\"]       = calc_high_rate(df_train, \"job\")\n",
    "    dict_high_rate[\"marital\"]   = calc_high_rate(df_train, \"marital\")\n",
    "    dict_high_rate[\"education\"] = calc_high_rate(df_train, \"education\")\n",
    "    dict_high_rate[\"poutcome\"]  = [\"success\"]\n",
    "    df_train[\"high_rate\"] = 0\n",
    "    df_test[\"high_rate\"]  = 0\n",
    "    for col, vals in dict_high_rate.items():\n",
    "        df_train.loc[df_train[col].isin(vals), \"high_rate\"] = df_train.high_rate + 2\n",
    "        df_test.loc[df_test[col].isin(vals),   \"high_rate\"] = df_test.high_rate + 2\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# カテゴリデータのダミー変数化\n",
    "def dummies(df, cols):\n",
    "    df_droped  = copy.deepcopy(df.drop(cols, axis=1)).reset_index(drop=True)\n",
    "    df_dummies = df.reset_index(drop=True)\n",
    "    df_dummies = pd.get_dummies(df_dummies[cols], drop_first=True)\n",
    "    return pd.merge(df_droped, df_dummies, left_index=True, right_index=True)\n",
    "\n",
    "# 数値データの標準化\n",
    "def standardization(df, cols, df_test=None):\n",
    "    mean   = df[cols].mean()\n",
    "    std    = df[cols].std()\n",
    "    df_std = copy.deepcopy(df)\n",
    "    df_std[cols] = df_std[cols].apply(lambda x: (x - mean[x.name]) / std[x.name])\n",
    "    df_test_std  = copy.deepcopy(df_test)\n",
    "    if df_test is not None:\n",
    "        df_test_std[cols] = df_test_std[cols].apply(lambda x: (x - mean[x.name]) / std[x.name])\n",
    "    return df_std, df_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "path = \"../../../../study/bank/motodata/\"\n",
    "df_train = pd.read_csv(path + \"train.csv\")\n",
    "df_test  = pd.read_csv(path + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# 外れ値データを削除（全員のモデルを足すときは実行していない）\n",
    "dict_del = {\"previous\":[275],\n",
    "            \"balance\" :[-6847,102127]}\n",
    "for col, vals in dict_del.items():\n",
    "    for val in vals:\n",
    "        del_idx = df_train[df_train[col]==val].index\n",
    "        df_train.drop(del_idx, inplace=True)\n",
    "df_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# 自作変数\n",
    "df_train_add_var = create_explain_variable(df_train)\n",
    "df_test_add_var  = create_explain_variable(df_test)\n",
    "df_train_add_var, df_test_add_var = add_col_high_rate(df_train_add_var, df_test_add_var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# 不要な列を削除\n",
    "drop_cols = [\"id\",\"month\",\"md\"]\n",
    "df_train_add_var.drop(drop_cols, axis=1, inplace=True)\n",
    "df_test_add_var.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "std_cols = df_train_add_var.select_dtypes(include=[\"int\",\"float\"]).columns\n",
    "std_cols = std_cols.drop(\"y\")\n",
    "df_train_add_var, df_test_add_var = standardization(df_train_add_var, std_cols, df_test_add_var)\n",
    "# ダミー変数化\n",
    "dummies_cols = df_train_add_var.select_dtypes(include=\"object\").columns\n",
    "df_dummies   = pd.concat([df_train_add_var, df_test_add_var])\n",
    "df_dummies   = dummies(df_dummies, dummies_cols)\n",
    "df_train_add_var, df_test_add_var = df_dummies[df_dummies.y.notnull()], df_dummies[df_dummies.y.isnull()]\n",
    "df_train_add_var.y = df_train_add_var.y.astype(int)\n",
    "df_test_add_var.drop(\"y\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train_add_var.head())\n",
    "display(df_test_add_var.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.ProfileReport(df_train_add_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# スタッキング\n",
    "class stacking():\n",
    "    \n",
    "    def __init__(self, train, test, metric, y_col=\"y\", seed=15):\n",
    "        self.seed  = seed\n",
    "        self.y_col = y_col\n",
    "        self.train,       self.test,       self.metric       = train, test, metric\n",
    "        self.stack_train, self.stack_test, self.stack_metric = [],    [],   []\n",
    "        \n",
    "    def _append_df(self, original, append):\n",
    "        return original.append(append, ignore_index=True)\n",
    "    \n",
    "    def _stack(self, train, test, metric):\n",
    "        self.stack_train.append(train)\n",
    "        self.stack_test.append(test)\n",
    "        self.stack_metric.append(metric)\n",
    "    \n",
    "    def calc_proba(self, proba):\n",
    "        return 1 - proba[:,0]\n",
    "    \n",
    "    def fit(self, clf, cv=4, name=\"clf\"):\n",
    "        statime = datetime.now()\n",
    "        r_train, r_metric = pd.DataFrame(), pd.DataFrame()\n",
    "        # train\n",
    "        x, y    = self.train.drop(self.y_col, axis=1), self.train[self.y_col]\n",
    "        skf     = StratifiedKFold(n_splits=cv, random_state=self.seed)\n",
    "        for k, (train, valid) in enumerate(skf.split(x, y)):\n",
    "            clf.fit(x.iloc[train,:], y[train])\n",
    "            train_pred, valid_pred = clf.predict_proba(x.iloc[train,:]), clf.predict_proba(x.iloc[valid,:])\n",
    "            train_pred, valid_pred = self.calc_proba(train_pred),        self.calc_proba(valid_pred)\n",
    "            result = pd.DataFrame({\"k\"           : [k+1],\n",
    "                                   \"train_\"+name : self.metric(y[train], train_pred),\n",
    "                                   \"valid_\"+name : self.metric(y[valid], valid_pred)})\n",
    "            v_pred = pd.DataFrame({\"idx\" : valid,\n",
    "                                   name  : valid_pred,\n",
    "                                   \"y\"   : y[valid]})\n",
    "            r_train  = self._append_df(r_train, v_pred)\n",
    "            r_metric = self._append_df(r_metric, result)\n",
    "        # test\n",
    "        clf.fit(x, y)\n",
    "        all_pred, test_pred = clf.predict_proba(x),      clf.predict_proba(self.test)\n",
    "        all_pred, test_pred = self.calc_proba(all_pred), self.calc_proba(test_pred)\n",
    "        result   = pd.DataFrame({\"k\"           : [\"all\"],\n",
    "                                 \"train_\"+name : self.metric(y, all_pred)})\n",
    "        t_pred   = pd.DataFrame({\"idx\" : df_test.index,\n",
    "                                 name  : test_pred})\n",
    "        r_metric = self._append_df(r_metric, result)\n",
    "        self._stack(r_train, t_pred, r_metric)\n",
    "        print(\"%s training end. time:%s\" % (name, datetime.now()-statime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# クロスバリデーション k=4 でスタッキング（ハイパーパラメータはGridSearchで決定）\n",
    "seed=15\n",
    "\n",
    "names       = [\"gb1\",\"gb2\",\"gb3\",\"gb4\",\"gb5\",\"gb6\",\"gb7\",\"ab\",\"rf\",\"et\"]\n",
    "classifiers = [xgb.XGBClassifier(learning_rate=0.01, max_depth=6, min_child_weight=4, gamma=3, n_estimators=1000, random_state=seed),\n",
    "               xgb.XGBClassifier(learning_rate=0.01, max_depth=5, min_child_weight=4, gamma=3, n_estimators=1000, random_state=seed),\n",
    "               xgb.XGBClassifier(learning_rate=0.01, max_depth=7, min_child_weight=4, gamma=3, n_estimators=1000, random_state=seed),\n",
    "               xgb.XGBClassifier(learning_rate=0.01, max_depth=6, min_child_weight=3, gamma=3, n_estimators=1000, random_state=seed),\n",
    "               xgb.XGBClassifier(learning_rate=0.01, max_depth=6, min_child_weight=5, gamma=3, n_estimators=1000, random_state=seed),\n",
    "               xgb.XGBClassifier(learning_rate=0.01, max_depth=6, min_child_weight=4, gamma=3, n_estimators=2000, random_state=seed),\n",
    "               xgb.XGBClassifier(learning_rate=0.02, max_depth=6, min_child_weight=4, gamma=3, n_estimators=1000, random_state=seed),\n",
    "               AdaBoostClassifier(learning_rate=0.1, n_estimators=3000, random_state=seed),\n",
    "               RandomForestClassifier(max_depth=24, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, n_jobs=-1, random_state=seed),\n",
    "               ExtraTreesClassifier(max_depth=24, min_samples_leaf=1, n_estimators=500, n_jobs=-1, random_state=seed)]\n",
    "\n",
    "s = stacking(df_train_add_var, df_test_add_var, roc_auc_score)\n",
    "for idx, clf in enumerate(classifiers):\n",
    "    s.fit(clf, name=names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 各モデルのAUC\n",
    "#  xgb : 勾配ブースティング\n",
    "#  ab  : アダブースト\n",
    "#  rf  : ランダムフォレスト\n",
    "#  et  : Extra-trees\n",
    "pd.concat(s.stack_metric, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "df_train_stack = functools.reduce(lambda x, y: pd.merge(x, y, on =[\"idx\",\"y\"]), s.stack_train)\n",
    "df_test_stack  = functools.reduce(lambda x, y: pd.merge(x, y, on =\"idx\"),       s.stack_test)\n",
    "print(\"train shape :\", df_train_stack.shape)\n",
    "print(\"test  shape :\", df_test_stack.shape)\n",
    "df_train_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x    = df_train_stack.drop([\"idx\",\"y\"], axis=1)\n",
    "y    = df_train_stack.y\n",
    "test = df_test_stack.drop(\"idx\", axis=1)\n",
    "# meta model（ハイパーパラメータはGridSearchで決定）\n",
    "classifier = xgb.XGBClassifier(gamma=10, learning_rate=0.1, max_depth=8, min_child_weight=10, n_estimators=1000, random_state=seed)\n",
    "classifier.fit(x, y)\n",
    "train_pred = s.calc_proba(classifier.predict_proba(x))\n",
    "print(\"train auc:\", roc_auc_score(y, train_pred))\n",
    "test_pred  = s.calc_proba(classifier.predict_proba(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({\"idx\"    : np.arange(1, df_test_stack.shape[0]+1),\n",
    "                          \"result\" : test_pred})\n",
    "path = \"../../../../study/bank/submit/\"\n",
    "df_result.to_csv(path + \"result_20180909_4.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# cross validation\n",
    "seed  = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#勾配ブースティング\n",
    "classifier = xgb.XGBClassifier(random_state=seed)\n",
    "parameters = {'n_estimators'     : [500,1000],\n",
    "              'learning_rate'    : [0.1,0.3,0.5], \n",
    "              'max_depth'        : [6,8,10],\n",
    "              'min_child_weight' : [4,6,10],\n",
    "              'gamma'            : [0,3,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#extra trees\n",
    "classifier = ExtraTreesClassifier(random_state=seed)\n",
    "parameters = {'n_estimators'     : [500, 1000],\n",
    "              'max_depth'        : [24],\n",
    "              'min_samples_leaf' : [1, 3, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#ランダムフォレスト\n",
    "classifier = RandomForestClassifier(random_state=seed)\n",
    "parameters = {'n_estimators'     : [1000],\n",
    "              'max_depth'        : [24],\n",
    "              'min_samples_leaf' : [2,5,6,10],\n",
    "              'min_samples_split': [2,10,15,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#k最近傍法\n",
    "classifier = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':[62,63,64,65,66,67,68,69,70],\n",
    "              \"leaf_size\"  :[1],\n",
    "              \"p\"          :[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "classifier = SVC(random_state=seed)\n",
    "parameters = {'C'    :np.logspace(-4, 4, 3),\n",
    "              'gamma':np.logspace(-4, 4, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#アダブースト\n",
    "classifier = AdaBoostClassifier(random_state=seed)\n",
    "parameters = {'n_estimators'    :[3000,5000],\n",
    "              'learning_rate'   :[0.1,0.2,0.3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#ロジスティック回帰\n",
    "classifier = LogisticRegression(random_state=seed)\n",
    "parameters = {'C' : [0.1,1,10,20,30,40,50,60,70,80,90,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x = df_train_add_var.drop(\"y\", axis=1)\n",
    "y = df_train_add_var.y\n",
    "train_X, test_X, train_y, test_y = train_test_split(x, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "cv = GridSearchCV(classifier, parameters, cv=4, scoring=\"roc_auc\", verbose=10, n_jobs=-1)\n",
    "cv.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x = df_train_stack.drop([\"idx\",\"y\"], axis=1)\n",
    "y = df_train_stack.y\n",
    "train_X, test_X, train_y, test_y = train_test_split(x, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "cv = GridSearchCV(classifier, parameters, cv=4, scoring=\"roc_auc\", verbose=10, n_jobs=-1)\n",
    "cv.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = calc_proba(cv.predict_proba(test_X))\n",
    "print(\"best model auc:\", roc_auc_score(test_y, pred))\n",
    "cv.best_estimator_.get_params"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
